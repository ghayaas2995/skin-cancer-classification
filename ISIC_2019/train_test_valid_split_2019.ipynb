{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISIC_2019: Train, Test, Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from skimage import io\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "# pip install -U albumentations --user\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Directories to place the training, testing and validation images after performing train_test_split:\n",
    "for clas in ['mel', 'nv', 'bcc', 'ak', 'bkl', 'df', 'vasc', 'scc']:\n",
    "    os.makedirs(f'Data/train_70%/{clas}')\n",
    "    os.makedirs(f'Data/Processed_Data/test/{clas}')\n",
    "    os.makedirs(f'Data/Processed_Data/valid/{clas}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the raw data from each class of the \"train\" folder:\n",
    "\n",
    "dataset_path = \"Data/train/\" \n",
    "\n",
    "ak_images = sorted(glob(os.path.join(dataset_path+ \"ak\", \"*.jpg\")))\n",
    "bcc_images = sorted(glob(os.path.join(dataset_path+ \"bcc\", \"*.jpg\")))\n",
    "bkl_images = sorted(glob(os.path.join(dataset_path+ \"bkl\", \"*.jpg\")))\n",
    "df_images = sorted(glob(os.path.join(dataset_path+ \"df\", \"*.jpg\")))\n",
    "mel_images = sorted(glob(os.path.join(dataset_path+ \"mel\", \"*.jpg\")))\n",
    "nv_images = sorted(glob(os.path.join(dataset_path+ \"nv\", \"*.jpg\")))\n",
    "scc_images = sorted(glob(os.path.join(dataset_path+ \"scc\", \"*.jpg\")))\n",
    "vasc_images = sorted(glob(os.path.join(dataset_path+ \"vasc\", \"*.jpg\")))\n",
    "\n",
    "# Normalise the path of the data downloaded above\n",
    "\n",
    "ak_images = [os.path.normpath(i) for i in ak_images]\n",
    "bcc_images = [os.path.normpath(i) for i in bcc_images]\n",
    "bkl_images = [os.path.normpath(i) for i in bkl_images]\n",
    "df_images = [os.path.normpath(i) for i in df_images]\n",
    "mel_images = [os.path.normpath(i) for i in mel_images]\n",
    "nv_images = [os.path.normpath(i) for i in nv_images]\n",
    "scc_images = [os.path.normpath(i) for i in scc_images]\n",
    "vasc_images = [os.path.normpath(i) for i in vasc_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data\\\\train\\\\ak\\\\ISIC_0024468.jpg',\n",
       " 'Data\\\\train\\\\ak\\\\ISIC_0024470.jpg',\n",
       " 'Data\\\\train\\\\ak\\\\ISIC_0024511.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ak_images[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to shuffle the input images to maintain randomness of the shuffle. X refers to images path\n",
    "# The random state has been set to 42 so that we get the same shuffling result when reproduced\n",
    "from sklearn.utils import shuffle\n",
    "def shuffling(X):\n",
    "    X= shuffle(X, random_state=42)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak_images = shuffling(ak_images)\n",
    "bcc_images = shuffling(bcc_images)\n",
    "bkl_images = shuffling(bkl_images)\n",
    "df_images = shuffling(df_images)\n",
    "mel_images = shuffling(mel_images)\n",
    "nv_images = shuffling(nv_images)\n",
    "scc_images = shuffling(scc_images)\n",
    "vasc_images = shuffling(vasc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data\\\\train\\\\ak\\\\ISIC_0059843.jpg',\n",
       " 'Data\\\\train\\\\ak\\\\ISIC_0061582.jpg',\n",
       " 'Data\\\\train\\\\ak\\\\ISIC_0028820.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for successful shuffling\n",
    "ak_images[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to split all the image classes into train, test and valid:\n",
    "# the split will be done as following: 70% of each class to train, 15% to test and 15% to validation\n",
    "\n",
    "def train_test_valid_split(images):\n",
    "    images_train = images[: int(np.round(len(images)*0.7))]\n",
    "    images_test = images[int(np.round(len(images)*0.7)): int(np.round(len(images)*0.7))+int(np.round(len(images)*0.15))]\n",
    "    images_valid = images[int(np.round(len(images)*0.7))+int(np.round(len(images)*0.15)) : ]\n",
    "    return images_train, images_test, images_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the train, test and validation split on each class of images\n",
    "ak_train, ak_test, ak_valid = train_test_valid_split(ak_images)\n",
    "bcc_train, bcc_test, bcc_valid = train_test_valid_split(bcc_images)\n",
    "bkl_train, bkl_test, bkl_valid = train_test_valid_split(bkl_images)\n",
    "df_train, df_test, df_valid = train_test_valid_split(df_images)\n",
    "mel_train, mel_test, mel_valid = train_test_valid_split(mel_images)\n",
    "nv_train, nv_test, nv_valid = train_test_valid_split(nv_images)\n",
    "scc_train, scc_test, scc_valid = train_test_valid_split(scc_images)\n",
    "vasc_train, vasc_test, vasc_valid = train_test_valid_split(vasc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to read the images from the paths and saves in the specified save path folder:\n",
    "\n",
    "def read_save(images, save_path):\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        save_images = [x] # save original image\n",
    "\n",
    "        for i in save_images:\n",
    "            tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and save all the training data:\n",
    "\n",
    "save_path = \"Data/train_70%/\"\n",
    "\n",
    "read_save(ak_train, save_path=save_path+\"ak\")\n",
    "read_save(bcc_train, save_path=save_path+\"bcc\")\n",
    "read_save(bkl_train, save_path=save_path+\"bkl\")\n",
    "read_save(df_train, save_path=save_path+\"df\")\n",
    "read_save(mel_train, save_path=save_path+\"mel\")\n",
    "read_save(nv_train, save_path=save_path+\"nv\")\n",
    "read_save(scc_train, save_path=save_path+\"scc\")\n",
    "read_save(vasc_train, save_path=save_path+\"vasc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and save all the testing data:\n",
    "\n",
    "save_path = \"Data/Processed_Data/test\"\n",
    "\n",
    "read_save(ak_test, save_path=save_path+\"ak\")\n",
    "read_save(bcc_test, save_path=save_path+\"bcc\")\n",
    "read_save(bkl_test, save_path=save_path+\"bkl\")\n",
    "read_save(df_test, save_path=save_path+\"df\")\n",
    "read_save(mel_test, save_path=save_path+\"mel\")\n",
    "read_save(nv_test, save_path=save_path+\"nv\")\n",
    "read_save(scc_test, save_path=save_path+\"scc\")\n",
    "read_save(vasc_test, save_path=save_path+\"vasc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and save all the validation data:\n",
    "\n",
    "save_path = \"Data/Processed_Data/valid\"\n",
    "\n",
    "read_save(ak_valid, save_path=save_path+\"ak\")\n",
    "read_save(bcc_valid, save_path=save_path+\"bcc\")\n",
    "read_save(bkl_valid, save_path=save_path+\"bkl\")\n",
    "read_save(df_valid, save_path=save_path+\"df\")\n",
    "read_save(mel_valid, save_path=save_path+\"mel\")\n",
    "read_save(nv_valid, save_path=save_path+\"nv\")\n",
    "read_save(scc_valid, save_path=save_path+\"scc\")\n",
    "read_save(vasc_valid, save_path=save_path+\"vasc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f44f79be4d0dc56bf7df116bc850954564c4c4f443100900ede2fae667342428"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
