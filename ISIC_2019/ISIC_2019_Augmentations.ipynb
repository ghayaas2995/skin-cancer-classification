{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISIC_2019: Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from skimage import io\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "# pip install -U albumentations --user\n",
    "import albumentations\n",
    "from albumentations import CenterCrop, RandomRotate90, GridDistortion, HorizontalFlip, VerticalFlip, Transpose, RandomBrightness, RandomContrast, MotionBlur, MedianBlur, GaussianBlur, GaussNoise, OpticalDistortion, ElasticTransform, CLAHE, HueSaturationValue, ShiftScaleRotate, Cutout, Rotate\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating directories to place the augmented images:\n",
    "\n",
    "for clas in ['mel', 'nv', 'bcc', 'ak', 'bkl', 'df', 'vasc', 'scc']:\n",
    "    os.makedirs(f'Data/train_augmented/train_{clas}_aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to shuffle the input images. X refers to images path\n",
    "from sklearn.utils import shuffle\n",
    "def shuffling(X):\n",
    "    X= shuffle(X, random_state=42)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class AK Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations to apply to match the training size of the biggest class:\n",
    "# Biggest class NV, size = 12875. Training input of 70% = 0.7x12875 = 9012\n",
    "\n",
    "# Therefore target training size range of the class AK = (8700, 9300)\n",
    "\n",
    "# initial number of images in AK - 606\n",
    "# 1st augmentation - shift scale rotate - 1212\n",
    "# 2nd augmentation - horizontal flip - 2424\n",
    "# 3rd augmentation - vertical flip - 4848\n",
    "# 4th augmentation - Center crop (on selected images to match the target range)\n",
    "\n",
    "# Note: In this augmentation process, all images are resized to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ak class images (606 images)\n",
    "dataset_path = \"Data/train_70%/ak\"\n",
    "\n",
    "ak_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "ak_images = [os.path.normpath(i) for i in ak_images]\n",
    "len(ak_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define shift scale rotate augmentation:\n",
    "# Randomly apply affine transforms: translate, scale and rotate the input.\n",
    "def shiftscalerotate(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = ShiftScaleRotate(p=1.0, rotate_limit=(-30,30))\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x, x1] # save original image and the augmented image\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 1st augmentation of shift scale rotate with a rotation range of -30 to +30 degrees\n",
    "save_path = \"Data/train_augmented/train_ak_aug\"\n",
    "shiftscalerotate(ak_images,save_path=save_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd transformation - horizontal flip: Flip the input horizontally around the y-axis.\n",
    "\n",
    "def horizontalflip(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = HorizontalFlip(always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1] # make sure only x1. If x is given in 2nd augmentation onwards, then duplicate images will be saved\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{1}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the first augmentation process and applying horizontal flip to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_ak_aug\"\n",
    "\n",
    "ak_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "ak_images = [os.path.normpath(i) for i in ak_images]\n",
    "len(ak_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 2nd augmentation - Horizontal flip\n",
    "horizontalflip(ak_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd transformation - Vertical flip: Flip the input vertically around the x-axis.\n",
    "\n",
    "def verticalflip(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = VerticalFlip(always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{2}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the second augmentation process and applying vertical flip to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_ak_aug\"\n",
    "\n",
    "ak_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "ak_images = [os.path.normpath(i) for i in ak_images]\n",
    "len(ak_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 3rd augmentation - Vertical flip\n",
    "verticalflip(ak_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 9012\n",
    "available = 4848\n",
    "f\"We are short of {target-available} images to reach our target size of {target} images. Therefore select and augment {target-available} number of images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 4164 images from the third augmentation process and applying centre crop to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_ak_aug\"\n",
    "\n",
    "ak_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "ak_images = [os.path.normpath(i) for i in ak_images]\n",
    "len(ak_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and take only required number of images to perform next augmentation:\n",
    "ak_images_shuf = shuffling(ak_images)\n",
    "ak_selected = ak_images_shuf[0:target-available]\n",
    "len(ak_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 10 paths of ak_selected to verify augmentations in the directory later\n",
    "ak_selected[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centre crop: cropping the centre square portion of the images of h x w =175*175\n",
    "\n",
    "def center_crop(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = CenterCrop(always_apply=True, height=175, width=175, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{3}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# applying 4th augmentation: centre crop\n",
    "center_crop(ak_selected,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class BCC Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations to apply to match the training size of the biggest class:\n",
    "# Biggest class NV, size = 12875. Training input of 70% = 0.7x12875 = 9012\n",
    "\n",
    "# Therefore target training size range of the class BCC = (8700, 9300)\n",
    "\n",
    "# Patch like images. Applying rotations and horizontal flip.\n",
    "\n",
    "# initial number of images in BCC - 2326\n",
    "# 1st augmentation - shift scale rotate - 4652\n",
    "# 2nd augmentation - horizontal flip (on selected images to match the target range)\n",
    "\n",
    "# Note: In this augmentation process, all images are resized to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the bcc class images (2326 images)\n",
    "dataset_path = \"Data/train_70%/bcc\"\n",
    "\n",
    "bcc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "bcc_images = [os.path.normpath(i) for i in bcc_images]\n",
    "len(bcc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define shift scale rotate augmentation:\n",
    "# Randomly apply affine transforms: translate, scale and rotate the input.\n",
    "def shiftscalerotate(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.ShiftScaleRotate(p=1.0, rotate_limit=(-40,40))\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x, x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 1st augmentation of shift scale rotate with a rotation range of -40 to +40 degrees\n",
    "save_path = \"Data/train_augmented/train_bcc_aug\"\n",
    "shiftscalerotate(bcc_images,save_path=save_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 9012\n",
    "available = 4652\n",
    "f\"We are short of {target-available} images to reach our target size of {target} images. Therefore select and augment {target-available} number of images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 2366 images from the above augmentation process and applying Horizontal flip to them:\n",
    "dataset_path = \"Data/train_augmented/train_bcc_aug\"\n",
    "\n",
    "bcc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "bcc_images = [os.path.normpath(i) for i in bcc_images]\n",
    "len(bcc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and take only required number of images to perform next augmentation:\n",
    "bcc_images_shuf = shuffling(bcc_images)\n",
    "bcc_selected = bcc_images_shuf[0:target-available]\n",
    "len(bcc_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 10 paths of bcc_selected to verify augmentations in the directory later\n",
    "bcc_selected[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd transformation - horizontal flip: Flip the input horizontally around the y-axis.\n",
    "\n",
    "def horizontalflip(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.HorizontalFlip(always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{1}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 2nd augmentation - Horizontal flip\n",
    "horizontalflip(bcc_selected,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class BKL Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations to apply to match the training size of the biggest class:\n",
    "# Biggest class NV, size = 12875. Training input of 70% = 0.7x12875 = 9012\n",
    "\n",
    "# Therefore target training size range of the class BKL = (8700, 9300)\n",
    "\n",
    "# In this class, the lesions are mostly circular, placed at centre position\n",
    "# many images have lesions marked with circular ink marks.\n",
    "\n",
    "# initial number of images in BKL - 1836\n",
    "# 1st augmentation - Centre crop - 3672\n",
    "# 2nd augmentation - Rotation - 7344\n",
    "# 3rd augmentation - Horizontal flip - (on selected images to match the target range). \n",
    "# As the lesions are circular or spherical, applying a rotation range of -45 to +45 degrees\n",
    "\n",
    "# Note: In this augmentation process, all images are resized to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this first augmentation, Random crop as well as centre crop was applied and observed.\n",
    "# Based on manual observation, Centre crop was found to be a better cropping option becauase random cropping \n",
    "# often cropped off the important portion of lesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the bkl class images (1836 images)\n",
    "dataset_path = \"Data/train_70%/bkl\"\n",
    "\n",
    "bkl_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "bkl_images = [os.path.normpath(i) for i in bkl_images]\n",
    "len(bkl_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define crop augmentation:\n",
    "# The input image has been resized to 256*256 before applying center crop\n",
    "\n",
    "def center_crop(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # resizing the input image before applying augmentation\n",
    "        x = cv2.resize(x, (W,H))\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.CenterCrop(p=1.0, height=100, width=100, always_apply=True)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x, x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the first cropping augmentation\n",
    "save_path = \"Data/train_augmented/train_bkl_aug\"\n",
    "center_crop(bkl_images,save_path=save_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the above augmentation process and applying shift scale rotate to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_bkl_aug\"\n",
    "\n",
    "bkl_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "bkl_images = [os.path.normpath(i) for i in bkl_images]\n",
    "len(bkl_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define shift scale rotate augmentation:\n",
    "# Randomly apply affine transforms: translate, scale and rotate the input.\n",
    "\n",
    "def shiftscalerotate(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.ShiftScaleRotate(p=1.0, rotate_limit=(-45,45))\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{1}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 2nd augmentation: Shift scale\n",
    "shiftscalerotate(bkl_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 9012\n",
    "available = 7344\n",
    "f\"We are short of {target-available} images to reach our target size of {target} images. Therefore select and augment {target-available} number of images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 1668 images from the above augmentation process and applying horizontal flip to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_bkl_aug\"\n",
    "\n",
    "bkl_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "bkl_images = [os.path.normpath(i) for i in bkl_images]\n",
    "len(bkl_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and take only required number of images to perform next augmentation:\n",
    "bkl_images_shuf = shuffling(bkl_images)\n",
    "bkl_selected = bkl_images_shuf[0:target-available]\n",
    "len(bkl_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 10 paths of bkl_selected to verify augmentations in the directory later\n",
    "bkl_selected[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd transformation - horizontal flip: Flip the input horizontally around the y-axis.\n",
    "\n",
    "def horizontalflip(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.HorizontalFlip(always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{2}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 3rd augmentation: Horizontal flip\n",
    "horizontalflip(bkl_selected,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class DF Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations to apply to match the training size of the biggest class:\n",
    "# Biggest class NV, size = 12875. Training input of 70% = 0.7x12875 = 9012\n",
    "\n",
    "# Therefore target training size range of the class DF = (8700, 9300)\n",
    "\n",
    "# The lesions are mostly placed at the centre. centre crop would be a good augmentation option for this class\n",
    "# The lesions are mostly patch like irregular shaped. rotations and flips could produce good quality unique images\n",
    "\n",
    "# initial number of images in DF - 167\n",
    "# 1st augmentation - Shift scale rotate (shift and rotate) +30 degrees  - 334\n",
    "# 2nd augmentation - Center crop - 668\n",
    "# 3rd augmentation - rotate (without shifting) 45 degrees - 1336\n",
    "# 4th augmentation - Horizontal flip - 2672\n",
    "# 5th augmentation - vertical flip - 5344\n",
    "# 6th augmentation - shear shift - (on selected images to match the target range)\n",
    "\n",
    "# Note: In this augmentation process, all images are resized to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the df class images (167 images)\n",
    "dataset_path = \"Data/train_70%/df\"\n",
    "\n",
    "df_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "df_images = [os.path.normpath(i) for i in df_images]\n",
    "len(df_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define shift scale rotate augmentation: (shift and rotate +30 degrees)\n",
    "# Randomly apply affine transforms: translate, scale and rotate the input.\n",
    "def shiftscalerotate(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.ShiftScaleRotate(p=1.0, rotate_limit=(30))\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x, x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 1st augmentation of shift scale rotate with a rotation range of -30 to +30 degrees\n",
    "save_path = \"Data/train_augmented/train_df_aug\"\n",
    "shiftscalerotate(df_images,save_path=save_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd transformation - Center crop\n",
    "\n",
    "def center_crop(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        x = cv2.resize(x, (W,H))\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.CenterCrop(125,125, always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]   # make sure only x1. If x is given in 2nd augmentation onwards, then duplicate images will be saved\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{1}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the first augmentation process and applying centercrop to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_df_aug\"\n",
    "\n",
    "df_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "df_images = [os.path.normpath(i) for i in df_images]\n",
    "len(df_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 2nd augmentation - Center crop\n",
    "center_crop(df_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd transformation - Rotate without shear shifting (40 degrees)\n",
    "\n",
    "def rotate(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.Rotate(limit =40, always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{2}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the second augmentation process and applying rotation to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_df_aug\"\n",
    "\n",
    "df_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "df_images = [os.path.normpath(i) for i in df_images]\n",
    "len(df_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 3rd augmentation - Rotation\n",
    "rotate(df_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th augmentation - Horizontal flip\n",
    "\n",
    "def horizontalflip(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.HorizontalFlip(always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{3}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the third augmentation process and applying horizontal flip to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_df_aug\"\n",
    "\n",
    "df_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "df_images = [os.path.normpath(i) for i in df_images]\n",
    "len(df_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 4th augmentation - Horizontal flip\n",
    "horizontalflip(df_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th augmentation - vertical flip\n",
    "\n",
    "def verticalflip(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.VerticalFlip(always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{4}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the fourth augmentation process and applying vertical flip to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_df_aug\"\n",
    "\n",
    "df_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "df_images = [os.path.normpath(i) for i in df_images]\n",
    "len(df_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 5th augmentation - Vertical flip\n",
    "verticalflip(df_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 9012\n",
    "available = 5344\n",
    "f\"We are short of {target-available} images to reach our target size of {target} images. Therefore select and augment {target-available} number of images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 5344 images from the fifth augmentation process and applying shear shift to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_df_aug\"\n",
    "\n",
    "df_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "df_images = [os.path.normpath(i) for i in df_images]\n",
    "len(df_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and take only required number of images to perform shear shift augmentation:\n",
    "df_images_shuf = shuffling(df_images)\n",
    "df_selected = df_images_shuf[0:target-available]\n",
    "len(df_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 10 paths of df_selected to verify augmentations in the directory later\n",
    "df_selected[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftscale(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.ShiftScaleRotate(shift_limit= 0.3, scale_limit=0.2,\n",
    "            always_apply=True, rotate_limit=0, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{5}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 6th augmentation: shift scale\n",
    "shiftscale(df_selected,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class MEL Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations to apply to match the training size of the biggest class:\n",
    "# Biggest class NV, size = 12875. Training input of 70% = 0.7x12875 = 9012\n",
    "\n",
    "# Therefore target training size range of the class MEL = (8700, 9300)\n",
    "\n",
    "# we have enough quantity of images with various sizes and shapes in this class. Most lesions are patch like\n",
    "\n",
    "# initial number of images in MEL - 3165\n",
    "# 1st augmentation - shift scale rotate - 6330\n",
    "# Just apply random shiting and random rotation in the range 0 to 40 degrees\n",
    "# 2nd augmentation - Horizontal flip (on selected images)\n",
    "\n",
    "# Note: In this augmentation process, all images are resized to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mel class images (3165 images)\n",
    "dataset_path = \"Data/train_70%/mel\"\n",
    "\n",
    "mel_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "mel_images = [os.path.normpath(i) for i in mel_images]\n",
    "len(mel_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define shift scale rotate augmentation:\n",
    "# Randomly apply affine transforms: translate, scale and rotate the input.\n",
    "def shiftscalerotate(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.ShiftScaleRotate(shift_limit=0.25, scale_limit=0.2, p=1.0, rotate_limit=40)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x, x1] # save original image and the augmented image\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 1st augmentation of shift scale rotate with a rotation range of 45 degrees\n",
    "save_path = \"Data/train_augmented/train_mel_aug\"\n",
    "shiftscalerotate(mel_images,save_path=save_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 9012\n",
    "available = 6330\n",
    "f\"We are short of {target-available} images to reach our target size of {target} images. Therefore select and augment {target-available} number of images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 2682 images from the above augmentation process and applying horizontal flip to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_mel_aug\"\n",
    "\n",
    "mel_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "mel_images = [os.path.normpath(i) for i in mel_images]\n",
    "len(mel_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and take only required number of images to perform next augmentation:\n",
    "mel_images_shuf = shuffling(mel_images)\n",
    "mel_selected = mel_images_shuf[0:target-available]\n",
    "len(mel_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 10 paths of bkl_selected to verify augmentations in the directory later\n",
    "mel_selected[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd transformation - horizontal flip: Flip the input horizontally around the y-axis.\n",
    "\n",
    "def horizontalflip(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.HorizontalFlip(always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{1}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 2nd augmentation: Horizontal flip\n",
    "horizontalflip(mel_selected,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class SCC Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations to apply to match the training size of the biggest class:\n",
    "# Biggest class NV, size = 12875. Training input of 70% = 0.7x12875 = 9012\n",
    "\n",
    "# Therefore target training size range of the class SCC = (8700, 9300)\n",
    "\n",
    "# The lesions are patch like, irregular shape, spread across the dimension of the image.\n",
    "\n",
    "# initial number of images in SCC - 439\n",
    "# 1st augmentation - horizontal flip - 878\n",
    "# 2nd augmentation - vertical flip - 1756\n",
    "# 3rd augmentation - shear shift rotate - 3512\n",
    "# 4th augmentation - Center crop - 7024\n",
    "# 5th augmentation - Rotate without shear shift 20 degrees (on selected images to match the target range)\n",
    "\n",
    "# Note: In this augmentation process, all images are resized to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the scc class images (439 images)\n",
    "dataset_path = \"Data/train_70%/scc\"\n",
    "\n",
    "scc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "scc_images = [os.path.normpath(i) for i in scc_images]\n",
    "len(scc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st transformation - horizontal flip: Flip the input horizontally around the y-axis.\n",
    "\n",
    "def horizontalflip(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug =albumentations.HorizontalFlip(always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x, x1] \n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 1st augmentation - Horizontal flip\n",
    "save_path = \"Data/train_augmented/train_scc_aug\"\n",
    "horizontalflip(scc_images,save_path=save_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd transformation - Vertical flip: Flip the input vertically around the x-axis.\n",
    "\n",
    "def verticalflip(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug =albumentations.VerticalFlip(always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{1}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the first augmentation process and applying vertical flip to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_scc_aug\"\n",
    "\n",
    "scc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "scc_images = [os.path.normpath(i) for i in scc_images]\n",
    "len(scc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 2nd augmentation - Vertical flip\n",
    "verticalflip(scc_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying 3rd augmentation: shift scale rotate augmentation:\n",
    "# Randomly apply affine transforms: translate, scale and rotate the input.\n",
    "def shiftscalerotate(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug =albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.15, p=1.0, rotate_limit=(-35,35))\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{2}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the second augmentation process and applying shift scale rotate to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_scc_aug\"\n",
    "\n",
    "scc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "scc_images = [os.path.normpath(i) for i in scc_images]\n",
    "len(scc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 3rd augmentation of shift scale rotate with a rotation range of -35 to +35 degrees\n",
    "save_path = \"Data/train_augmented/train_scc_aug\"\n",
    "shiftscalerotate(scc_images,save_path=save_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centre crop: cropping the centre square portion of the images of h x w =175*175\n",
    "\n",
    "def center_crop(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug =albumentations.CenterCrop(always_apply=True, height=175, width=175, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{3}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the third augmentation process and applying centre crop to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_scc_aug\"\n",
    "\n",
    "scc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "scc_images = [os.path.normpath(i) for i in scc_images]\n",
    "len(scc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 4th augmentation: centre crop\n",
    "center_crop(scc_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 9012\n",
    "available = 7021\n",
    "f\"We are short of {target-available} images to reach our target size of {target} images. Therefore select and augment {target-available} number of images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the fourth augmentation process and applying rotation to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_scc_aug\"\n",
    "\n",
    "scc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "scc_images = [os.path.normpath(i) for i in scc_images]\n",
    "len(scc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and take only required number of images to perform next augmentation:\n",
    "scc_images_shuf = shuffling(scc_images)\n",
    "scc_selected = scc_images_shuf[0:target-available]\n",
    "len(scc_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 10 paths of ak_selected to verify augmentations in the directory later\n",
    "scc_selected[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th transformation - Rotate without shear shifting (20 degrees)\n",
    "\n",
    "def rotate(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.Rotate(limit =20, always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{4}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 5th augmentation - Rotation\n",
    "rotate(scc_selected,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class VASC Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations to apply to match the training size of the biggest class:\n",
    "# Biggest class NV, size = 12875. Training input of 70% = 0.7x12875 = 9012\n",
    "\n",
    "# Therefore target training size range of the class AK = (8700, 9300)\n",
    "\n",
    "# The lesions in this class are similar to the class DF.\n",
    "# The lesions are mostly placed at the centre, small in size. centre crop would be a good augmentation option for this class\n",
    "# The lesions are mostly patch like irregular shaped. rotations and flips could produce good quality unique images\n",
    "# Applying all similar augmentations like the class DF on this class vasc\n",
    "\n",
    "# initial number of images in vasc - 177\n",
    "# 1st augmentation - Shift scale rotate (shift and rotate) +30 degrees  - 354\n",
    "# 2nd augmentation - Center crop - 708\n",
    "# 3rd augmentation - rotate (without shifting) 45 degrees - 1416\n",
    "# 4th augmentation - Horizontal flip - 2832\n",
    "# 5th augmentation - vertical flip - 5664\n",
    "# 6th augmentation - shear shift - (on selected images to match the target range)\n",
    "\n",
    "# Note: In this augmentation process, all images are resized to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the vasc class images (177 images)\n",
    "dataset_path = \"Data/train_70%/vasc\"\n",
    "\n",
    "vasc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "vasc_images = [os.path.normpath(i) for i in vasc_images]\n",
    "len(vasc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define shift scale rotate augmentation: (shift and rotate +30 degrees)\n",
    "# Randomly apply affine transforms: translate, scale and rotate the input.\n",
    "def shiftscalerotate(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.ShiftScaleRotate(p=1.0, rotate_limit=(30))\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x, x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 1st augmentation of shift scale rotate with a rotation range of -30 to +30 degrees\n",
    "save_path = \"Data/train_augmented/train_vasc_aug\"\n",
    "shiftscalerotate(vasc_images,save_path=save_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd transformation - Center crop.\n",
    "\n",
    "def center_crop(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        x = cv2.resize(x, (W,H))\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.CenterCrop(125,125, always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]   # make sure only x1. If x is given in 2nd augmentation onwards, then duplicate images will be saved\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{1}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the first augmentation process and applying centercrop to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_vasc_aug\"\n",
    "\n",
    "vasc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "vasc_images = [os.path.normpath(i) for i in vasc_images]\n",
    "len(vasc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 2nd augmentation - Center crop\n",
    "center_crop(vasc_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd transformation - Rotate without shear shifting (40 degrees)\n",
    "\n",
    "def rotate(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.Rotate(limit =40, always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{2}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the second augmentation process and applying rotation to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_vasc_aug\"\n",
    "\n",
    "vasc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "vasc_images = [os.path.normpath(i) for i in vasc_images]\n",
    "len(vasc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 3rd augmentation - Rotation\n",
    "rotate(vasc_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th augmentation - Horizontal flip\n",
    "\n",
    "def horizontalflip(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.HorizontalFlip(always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{3}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the third augmentation process and applying horizontal flip to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_vasc_aug\"\n",
    "\n",
    "vasc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "vasc_images = [os.path.normpath(i) for i in vasc_images]\n",
    "len(vasc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 4th augmentation - Horizontal flip\n",
    "horizontalflip(vasc_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th augmentation - vertical flip\n",
    "\n",
    "def verticalflip(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.VerticalFlip(always_apply=True, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{4}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images from the fourth augmentation process and applying vertical flip to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_vasc_aug\"\n",
    "\n",
    "vasc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "vasc_images = [os.path.normpath(i) for i in vasc_images]\n",
    "len(vasc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 5th augmentation - Vertical flip\n",
    "verticalflip(vasc_images,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 9012\n",
    "available = 5664\n",
    "f\"We are short of {target-available} images to reach our target size of {target} images. Therefore select and augment {target-available} number of images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 1364 images from the fifth augmentation process and applying shear shift to all of them:\n",
    "dataset_path = \"Data/train_augmented/train_vasc_aug\"\n",
    "\n",
    "vasc_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "vasc_images = [os.path.normpath(i) for i in vasc_images]\n",
    "len(vasc_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and take only required number of images to perform next augmentation:\n",
    "vasc_images_shuf = shuffling(vasc_images)\n",
    "vasc_selected = vasc_images_shuf[0:target-available]\n",
    "len(vasc_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view first 10 paths of vasc_selected to verify augmentations in the directory later\n",
    "vasc_selected[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift and Scale without rotation\n",
    "\n",
    "def shiftscale(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.ShiftScaleRotate(shift_limit= 0.3, scale_limit=0.2,\n",
    "            always_apply=True, rotate_limit=0, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1]\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{5}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 6th augmentation: Shift scale\n",
    "shiftscale(vasc_selected,save_path=dataset_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class NV Augentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All 9012 images have been selected from the \"train_70%\" directory and resized to 256x256 resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the nv class images\n",
    "dataset_path = \"Data/train/nv\"\n",
    "\n",
    "nv_images = sorted(glob(os.path.join(dataset_path, \"*.jpg\")))\n",
    "nv_images = [os.path.normpath(i) for i in nv_images]\n",
    "len(nv_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(images, save_path, augment = True):\n",
    "    H = 256\n",
    "    W = 256\n",
    "\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = albumentations.Resize(H,W, p=1.0)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "\n",
    "            save_images = [x1] # save the augmented image\n",
    "\n",
    "        # If the augment paramter is set to False, The function only saves the original image \n",
    "        else:\n",
    "            save_images = [x]\n",
    "        \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            #i = cv2.resize(i, (W,H))\n",
    "\n",
    "            tmp_img_name = f\"{image_name}_{idx}.{image_extn}\"\n",
    "            \n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying 256*256 resize\n",
    "save_path = \"Data/train_augmented/train_nv_aug\"\n",
    "resize(nv_images,save_path=save_path, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f44f79be4d0dc56bf7df116bc850954564c4c4f443100900ede2fae667342428"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
