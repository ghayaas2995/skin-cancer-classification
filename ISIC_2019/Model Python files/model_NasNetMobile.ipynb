{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#!pip install tensorflow_hub\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import shutil\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorboard\n",
    "import os\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In transfer learning, we do not need the last kayer of the model as it was trained for 1000 outputs.\n",
    "# for this, set the parameter include_top = False. This means that we will use only the model architecture\n",
    "# and do not need the last output layer from this architecture\n",
    "\n",
    "# We also do not want the weights from imagenet training as we will perform the training for our own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_ak_aug', 'train_bcc_aug', 'train_bkl_aug', 'train_df_aug', 'train_mel_aug', 'train_nv_aug', 'train_scc_aug', 'train_vasc_aug']\n",
      "Types of classes labels found:  8\n"
     ]
    }
   ],
   "source": [
    "dataset = 'Data/Processed_Data/train'\n",
    "dataset_path = os.listdir(dataset)\n",
    "\n",
    "print (dataset_path)  #what kinds of classes are in this dataset\n",
    "\n",
    "print(\"Types of classes labels found: \", len(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "# create a directory to save the files\n",
    "create_dir(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57680 images belonging to 8 classes.\n",
      "Found 14416 images belonging to 8 classes.\n",
      "Found 3799 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# load the augmented data from the local data directory:\n",
    "\n",
    "train_dir = \"Data/Processed_Data/train\"\n",
    "test_dir = \"Data/Processed_Data/test\"\n",
    "valid_dir = \"Data/Processed_Data/valid_processed\"\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255, validation_split=0.2, data_format=\"channels_last\", dtype=tf.float32) # The imported data will br normalized here.\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255, data_format=\"channels_last\", dtype=tf.float32)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    shuffle = True,\n",
    "    seed=123,subset = 'training') # set as training data\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    shuffle = True,\n",
    "    seed=123,subset = 'validation') # set as validation data\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    shuffle = True,\n",
    "    seed=123,) # set as testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nasnet model\n",
    "model = Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/nasnet_mobile/feature_vector/5\",\n",
    "               trainable=True, arguments=dict(batch_norm_momentum=0.997)),\n",
    "    layers.Dense(8, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.build([None, img_height, img_width, 3])  # Batch input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1056)              4269716   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 8456      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,278,172\n",
      "Trainable params: 4,241,434\n",
      "Non-trainable params: 36,738\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "    keras.metrics.Accuracy(name= \"accuracy\"),\n",
    "    keras.metrics.Precision(name = \"precision\"),\n",
    "    keras.metrics.Recall(name = 'recall'),\n",
    "    keras.metrics.AUC(name = 'auc'),\n",
    "]\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=METRICS,)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1802/1802 [==============================] - 1421s 747ms/step - loss: 0.9242 - accuracy: 5.4208e-05 - precision: 0.8333 - recall: 0.7512 - auc: 0.9779 - val_loss: 2.1613 - val_accuracy: 0.0014 - val_precision: 0.6208 - val_recall: 0.5810 - val_auc: 0.8849\n",
      "Epoch 2/30\n",
      "1802/1802 [==============================] - 1345s 747ms/step - loss: 0.6796 - accuracy: 3.9030e-04 - precision: 0.8943 - recall: 0.8499 - auc: 0.9904 - val_loss: 2.3130 - val_accuracy: 0.0019 - val_precision: 0.5803 - val_recall: 0.5340 - val_auc: 0.8555\n",
      "Epoch 3/30\n",
      "1802/1802 [==============================] - 1361s 755ms/step - loss: 0.5807 - accuracy: 7.4157e-04 - precision: 0.9108 - recall: 0.8758 - auc: 0.9930 - val_loss: 2.0663 - val_accuracy: 0.0023 - val_precision: 0.6726 - val_recall: 0.6410 - val_auc: 0.8888\n",
      "Epoch 4/30\n",
      "1802/1802 [==============================] - 1337s 742ms/step - loss: 0.5182 - accuracy: 0.0011 - precision: 0.9218 - recall: 0.8932 - auc: 0.9945 - val_loss: 1.8477 - val_accuracy: 8.3333e-04 - val_precision: 0.6424 - val_recall: 0.5979 - val_auc: 0.8956\n",
      "Epoch 5/30\n",
      "1802/1802 [==============================] - 1337s 742ms/step - loss: 0.4836 - accuracy: 0.0018 - precision: 0.9291 - recall: 0.9057 - auc: 0.9953 - val_loss: 1.6609 - val_accuracy: 0.0072 - val_precision: 0.6543 - val_recall: 0.6033 - val_auc: 0.9035\n",
      "Epoch 6/30\n",
      "1802/1802 [==============================] - 1346s 747ms/step - loss: 0.4528 - accuracy: 0.0026 - precision: 0.9346 - recall: 0.9142 - auc: 0.9962 - val_loss: 2.4367 - val_accuracy: 0.0134 - val_precision: 0.6085 - val_recall: 0.5907 - val_auc: 0.8745\n",
      "Epoch 7/30\n",
      "1802/1802 [==============================] - 1352s 750ms/step - loss: 0.4358 - accuracy: 0.0019 - precision: 0.9385 - recall: 0.9201 - auc: 0.9966 - val_loss: 1.6122 - val_accuracy: 0.0020 - val_precision: 0.7260 - val_recall: 0.6978 - val_auc: 0.9182\n",
      "Epoch 8/30\n",
      "1802/1802 [==============================] - 1355s 752ms/step - loss: 0.4182 - accuracy: 0.0024 - precision: 0.9427 - recall: 0.9270 - auc: 0.9969 - val_loss: 2.9231 - val_accuracy: 0.0151 - val_precision: 0.6147 - val_recall: 0.5969 - val_auc: 0.8491\n",
      "Epoch 9/30\n",
      "1802/1802 [==============================] - 1363s 757ms/step - loss: 0.4061 - accuracy: 0.0044 - precision: 0.9455 - recall: 0.9313 - auc: 0.9973 - val_loss: 1.9147 - val_accuracy: 0.0043 - val_precision: 0.6657 - val_recall: 0.6452 - val_auc: 0.8935\n",
      "Epoch 10/30\n",
      "1802/1802 [==============================] - 1345s 746ms/step - loss: 0.3907 - accuracy: 0.0046 - precision: 0.9497 - recall: 0.9376 - auc: 0.9976 - val_loss: 2.4925 - val_accuracy: 0.0110 - val_precision: 0.6492 - val_recall: 0.6274 - val_auc: 0.8693\n",
      "Epoch 11/30\n",
      "1802/1802 [==============================] - 1355s 752ms/step - loss: 0.3856 - accuracy: 0.0047 - precision: 0.9512 - recall: 0.9398 - auc: 0.9977 - val_loss: 1.8582 - val_accuracy: 0.0028 - val_precision: 0.6722 - val_recall: 0.6474 - val_auc: 0.8984\n",
      "Epoch 12/30\n",
      "1802/1802 [==============================] - 1336s 741ms/step - loss: 0.3687 - accuracy: 0.0039 - precision: 0.9560 - recall: 0.9461 - auc: 0.9980 - val_loss: 3.1084 - val_accuracy: 0.0012 - val_precision: 0.6159 - val_recall: 0.5975 - val_auc: 0.8465\n",
      "Epoch 13/30\n",
      "1802/1802 [==============================] - 1350s 749ms/step - loss: 0.3644 - accuracy: 0.0047 - precision: 0.9571 - recall: 0.9482 - auc: 0.9980 - val_loss: 2.4516 - val_accuracy: 0.0089 - val_precision: 0.6314 - val_recall: 0.6144 - val_auc: 0.8727\n",
      "Epoch 14/30\n",
      "1802/1802 [==============================] - 1341s 744ms/step - loss: 0.3543 - accuracy: 0.0050 - precision: 0.9604 - recall: 0.9523 - auc: 0.9984 - val_loss: 1.9071 - val_accuracy: 0.0076 - val_precision: 0.6707 - val_recall: 0.6388 - val_auc: 0.8937\n",
      "Epoch 15/30\n",
      "1802/1802 [==============================] - 1345s 747ms/step - loss: 0.3482 - accuracy: 0.0065 - precision: 0.9607 - recall: 0.9540 - auc: 0.9984 - val_loss: 1.8825 - val_accuracy: 0.0062 - val_precision: 0.6889 - val_recall: 0.6670 - val_auc: 0.8983\n",
      "Epoch 16/30\n",
      "1802/1802 [==============================] - 1351s 750ms/step - loss: 0.3392 - accuracy: 0.0054 - precision: 0.9638 - recall: 0.9574 - auc: 0.9985 - val_loss: 2.3556 - val_accuracy: 0.0138 - val_precision: 0.6746 - val_recall: 0.6577 - val_auc: 0.8881\n",
      "Epoch 17/30\n",
      "1802/1802 [==============================] - 1360s 755ms/step - loss: 0.3376 - accuracy: 0.0056 - precision: 0.9638 - recall: 0.9580 - auc: 0.9985 - val_loss: 2.4592 - val_accuracy: 0.0056 - val_precision: 0.6197 - val_recall: 0.6062 - val_auc: 0.8635\n",
      "Epoch 18/30\n",
      "1802/1802 [==============================] - 1341s 744ms/step - loss: 0.3316 - accuracy: 0.0070 - precision: 0.9658 - recall: 0.9603 - auc: 0.9986 - val_loss: 2.1408 - val_accuracy: 0.0083 - val_precision: 0.6727 - val_recall: 0.6643 - val_auc: 0.8850\n",
      "Epoch 19/30\n",
      "1802/1802 [==============================] - 1342s 745ms/step - loss: 0.3226 - accuracy: 0.0070 - precision: 0.9683 - recall: 0.9631 - auc: 0.9988 - val_loss: 2.1182 - val_accuracy: 0.0062 - val_precision: 0.6983 - val_recall: 0.6812 - val_auc: 0.8875\n",
      "Epoch 20/30\n",
      "1802/1802 [==============================] - 1336s 741ms/step - loss: 0.3250 - accuracy: 0.0074 - precision: 0.9670 - recall: 0.9623 - auc: 0.9987 - val_loss: 2.4410 - val_accuracy: 0.0109 - val_precision: 0.6445 - val_recall: 0.6290 - val_auc: 0.8708\n",
      "Epoch 21/30\n",
      "1802/1802 [==============================] - 1336s 742ms/step - loss: 0.3143 - accuracy: 0.0082 - precision: 0.9700 - recall: 0.9657 - auc: 0.9988 - val_loss: 6.0552 - val_accuracy: 0.0194 - val_precision: 0.6421 - val_recall: 0.6279 - val_auc: 0.8684\n",
      "Epoch 22/30\n",
      "1802/1802 [==============================] - 1326s 736ms/step - loss: 0.3172 - accuracy: 0.0070 - precision: 0.9690 - recall: 0.9647 - auc: 0.9988 - val_loss: 2.5024 - val_accuracy: 0.0080 - val_precision: 0.6769 - val_recall: 0.6633 - val_auc: 0.8756\n",
      "Epoch 23/30\n",
      "1802/1802 [==============================] - 1340s 744ms/step - loss: 0.3112 - accuracy: 0.0079 - precision: 0.9710 - recall: 0.9662 - auc: 0.9988 - val_loss: 2.5094 - val_accuracy: 0.0073 - val_precision: 0.6567 - val_recall: 0.6424 - val_auc: 0.8733\n",
      "Epoch 24/30\n",
      "1802/1802 [==============================] - 1333s 740ms/step - loss: 0.3064 - accuracy: 0.0079 - precision: 0.9712 - recall: 0.9672 - auc: 0.9990 - val_loss: 2.4889 - val_accuracy: 0.0041 - val_precision: 0.6570 - val_recall: 0.6425 - val_auc: 0.8773\n",
      "Epoch 25/30\n",
      "1802/1802 [==============================] - 1327s 737ms/step - loss: 0.3000 - accuracy: 0.0079 - precision: 0.9727 - recall: 0.9693 - auc: 0.9992 - val_loss: 2.1288 - val_accuracy: 0.0061 - val_precision: 0.6587 - val_recall: 0.6471 - val_auc: 0.8853\n",
      "Epoch 26/30\n",
      "1802/1802 [==============================] - 1332s 739ms/step - loss: 0.3009 - accuracy: 0.0108 - precision: 0.9727 - recall: 0.9691 - auc: 0.9990 - val_loss: 2.5048 - val_accuracy: 0.0175 - val_precision: 0.6552 - val_recall: 0.6425 - val_auc: 0.8715\n",
      "Epoch 27/30\n",
      "1802/1802 [==============================] - 1325s 735ms/step - loss: 0.2999 - accuracy: 0.0110 - precision: 0.9732 - recall: 0.9695 - auc: 0.9989 - val_loss: 2.7031 - val_accuracy: 0.0190 - val_precision: 0.6446 - val_recall: 0.6333 - val_auc: 0.8654\n",
      "Epoch 28/30\n",
      "1802/1802 [==============================] - 1329s 737ms/step - loss: 0.2934 - accuracy: 0.0103 - precision: 0.9746 - recall: 0.9711 - auc: 0.9991 - val_loss: 2.1326 - val_accuracy: 0.0103 - val_precision: 0.6866 - val_recall: 0.6724 - val_auc: 0.8892\n",
      "Epoch 29/30\n",
      "1802/1802 [==============================] - 1329s 738ms/step - loss: 0.2921 - accuracy: 0.0107 - precision: 0.9740 - recall: 0.9709 - auc: 0.9991 - val_loss: 2.5362 - val_accuracy: 0.0149 - val_precision: 0.6197 - val_recall: 0.6075 - val_auc: 0.8606\n",
      "Epoch 30/30\n",
      "1802/1802 [==============================] - 1336s 741ms/step - loss: 0.2906 - accuracy: 0.0093 - precision: 0.9747 - recall: 0.9713 - auc: 0.9991 - val_loss: 2.6806 - val_accuracy: 0.0133 - val_precision: 0.6455 - val_recall: 0.6348 - val_auc: 0.8606\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "    train_generator,\n",
    "    epochs = 30,\n",
    "    steps_per_epoch=train_generator.samples//batch_size,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=validation_generator.samples//batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"models/model_Nasnet_30.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(\"models/model_Nasnet_30.h5\",custom_objects={'KerasLayer':hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GHAYAAS\\AppData\\Local\\Temp/ipykernel_17544/2098712288.py:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  Y_pred = model.predict_generator(test_generator, test_generator.samples // batch_size+1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 40   0   0  36   8  21  23   2]\n",
      " [118   5   0 145  29 100  95   6]\n",
      " [ 84   4   1 118  24  77  84   2]\n",
      " [  9   0   1  12   6   5   3   0]\n",
      " [160   4   0 198  37 131 145   3]\n",
      " [433  12   5 550 126 414 378  13]\n",
      " [ 24   1   0  28   4  18  19   0]\n",
      " [  8   0   0  11   3  11   5   0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ak       0.05      0.31      0.08       130\n",
      "         bcc       0.19      0.01      0.02       498\n",
      "         bkl       0.14      0.00      0.00       394\n",
      "          df       0.01      0.33      0.02        36\n",
      "         mel       0.16      0.05      0.08       678\n",
      "          nv       0.53      0.21      0.31      1931\n",
      "         scc       0.03      0.20      0.04        94\n",
      "        vasc       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.14      3799\n",
      "   macro avg       0.14      0.14      0.07      3799\n",
      "weighted avg       0.34      0.14      0.18      3799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(test_generator, test_generator.samples // batch_size+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['ak', 'bcc', 'bkl', 'df', 'mel','nv', 'scc', 'vasc']\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13898394314293236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(test_generator.classes, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14058756116877513\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "print(balanced_accuracy_score(test_generator.classes, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f44f79be4d0dc56bf7df116bc850954564c4c4f443100900ede2fae667342428"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
