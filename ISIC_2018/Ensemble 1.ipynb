{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243cc7af",
   "metadata": {},
   "source": [
    "# Ensemble of Base Model : Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b90d05",
   "metadata": {},
   "source": [
    "## Approach\n",
    "- Create a List of Base Models\n",
    "- Take all the Preprocessed Images from each Class\n",
    "- Split Training data into Train and Validation with 0.7 traim-test ratio\n",
    "- Perform this splitting for each model in a loop with a different random state so that shuffling of images is different for each model.\n",
    "- Perform Augmentation on each class of training data splitted above \n",
    "- Train the models on augmented data validating on 30% validation data\n",
    "- Once all models in list are trained, use max voting to find predction of validation image set\n",
    "\n",
    "Before running make sure there is no augmented & test folder in the directory of notebook since it is created in this file itself. If it exists delete them. A caveat here is that if you wish to run Model_1_2_3_4.ipynb file again, you need to run Preprocessing Notebook again to form required folders.\n",
    "\n",
    "Also, if required change the path seperator to run code smoothly on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1405c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "# For missing libraries\n",
    "# pip install -U package_name --user\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from functools import partial\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import io\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import albumentations\n",
    "from albumentations import ShiftScaleRotate, HorizontalFlip, VerticalFlip, RandomBrightnessContrast\n",
    "import warnings\n",
    "import shutil\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1184fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Augmentation Functions\n",
    "# Shifting, Scaling & Rotations\n",
    "def shiftscalerotate(images, save_path,\n",
    "                     augment = True,\n",
    "                     resize = [256,256],\n",
    "                     random=1.0,\n",
    "                     rotation=0,\n",
    "                     shift=0,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     always=True,\n",
    "                     call=1):\n",
    "    H, W = resize\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = ShiftScaleRotate(p=random, rotate_limit=(-30,30), interpolation=interpolation,\n",
    "                                  always_apply=always)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "            save_images = [x, x1] # save original image and the augmented image\n",
    "        # If the augment paramter is set to False, The function only saves the original image and mask to the defined save_path\n",
    "        else:\n",
    "            save_images = [x] \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "            if idx == 0:\n",
    "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            else:\n",
    "                aug_ext = '_ssr'*call\n",
    "                tmp_img_name = f\"{image_name}{aug_ext}.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)\n",
    "            idx +=1\n",
    "# Horizontal Flipping\n",
    "def horizontalflip(images, save_path,\n",
    "                   augment = True,\n",
    "                   resize = [256,256],\n",
    "                   random=1.0,\n",
    "                   always=True):\n",
    "    H, W = resize\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        if augment ==True:\n",
    "            aug = HorizontalFlip(always_apply=always, p=random)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "            save_images = [x, x1] # make sure only x1. If x is given in 2nd augmentation onwards, then duplicate images will be saved\n",
    "        # If the augment paramter is set to False, The function only saves the original image and mask to the defined save_path\n",
    "        else:\n",
    "            save_images = [x]\n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "            if idx == 0:\n",
    "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            else:\n",
    "                tmp_img_name = f\"{image_name}_hf.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)\n",
    "            idx +=1\n",
    "#vertical flipping\n",
    "def verticalflip(images,\n",
    "                 save_path,\n",
    "                 augment = True,\n",
    "                 resize=[256,256],\n",
    "                 random=1.0,\n",
    "                 always=True):\n",
    "    H, W = resize\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "        # Now that we have the names, we have to read the image\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        if augment ==True:\n",
    "            aug = VerticalFlip(always_apply=always, p=random)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "            save_images = [x, x1]\n",
    "        # If the augment paramter is set to False, The function only saves the original image and mask to the defined save_path\n",
    "        else:\n",
    "            save_images = [x]\n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "            if idx == 0:\n",
    "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            else:\n",
    "                tmp_img_name = f\"{image_name}_vf.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)\n",
    "            idx +=1\n",
    "def brightness_contrast(images,\n",
    "                        save_path,\n",
    "                        augment = True,\n",
    "                        resize=[256,256],\n",
    "                        random=1.0,\n",
    "                        brightness=0.2, \n",
    "                        contrast=0.2,\n",
    "                        by_max=False,\n",
    "                        always=True):\n",
    "    H, W = resize\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "        # Now that we have the names, we have to read the image\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        if augment ==True:\n",
    "            aug = RandomBrightnessContrast(brightness_limit=brightness,\n",
    "                                           contrast_limit=contrast,\n",
    "                                           brightness_by_max=by_max,\n",
    "                                           always_apply=always,\n",
    "                                           p=random)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "            save_images = [x, x1]\n",
    "        # If the augment paramter is set to False, The function only saves the original image and mask to the defined save_path\n",
    "        else:\n",
    "            save_images = [x]\n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "            if idx == 0:\n",
    "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            else:\n",
    "                tmp_img_name = f\"{image_name}_bc.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "951a8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ensemble of 10 models\n",
    "n = 10\n",
    "ensemble = [0]* n\n",
    "def shuffling_tt(X, rs):\n",
    "    X= shuffle(X, random_state=rs)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d9c66a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create & Complie Ensemble\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu',\n",
    "                        padding=\"SAME\")\n",
    "for k in range(n):\n",
    "    ensemble[k] = keras.models.Sequential([\n",
    "                    DefaultConv2D(filters=16, input_shape=[128, 128, 3]),\n",
    "                    keras.layers.MaxPooling2D(pool_size=2),\n",
    "                    DefaultConv2D(filters=32),\n",
    "                    keras.layers.MaxPooling2D(pool_size=2),\n",
    "                    DefaultConv2D(filters=64),\n",
    "                    keras.layers.MaxPooling2D(pool_size=2),\n",
    "                    keras.layers.Dropout(0.5),\n",
    "                    keras.layers.Flatten(),\n",
    "                    keras.layers.Dense(units=7, activation='softmax'),\n",
    "                    ])\n",
    "    ensemble[k].compile(loss='categorical_crossentropy',\n",
    "                        optimizer='adam',\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58451053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Augmentation Functions for each class\n",
    "def shuffling(X):\n",
    "    X= shuffle(X, random_state=42)\n",
    "    return X\n",
    "out_path = 'augmented/'\n",
    "# Performing Augmentations Class-Wise\n",
    "# AKIEC\n",
    "def augment_akiec(image_data):\n",
    "    out_data = out_path+'akiec'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST)\n",
    "    ssr_images = glob('augmented/akiec/*')\n",
    "    horizontalflip(ssr_images, out_data,\n",
    "                       augment = True,\n",
    "                       resize = [128,128],\n",
    "                       random=1.0)\n",
    "    hf_images = glob('augmented/akiec/*')\n",
    "    verticalflip(hf_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    df_images = glob('augmented/akiec/*')\n",
    "    brightness_contrast(df_images,\n",
    "                            out_data,\n",
    "                            augment = True,\n",
    "                            resize=[128,128],\n",
    "                            random=1.0,\n",
    "                            brightness=0.2, \n",
    "                            contrast=0.2,\n",
    "                            by_max=False)\n",
    "    # Selecting remaining images by shuffling all and selecting required\n",
    "    bc_images = glob('augmented/akiec/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    bc_images_shuf = shuffling(bc_images)\n",
    "    target = 4693\n",
    "    available = len(bc_images)\n",
    "    bc_selected = bc_images_shuf[0:target-available]\n",
    "    shiftscalerotate(bc_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=0,\n",
    "                     shift=0,\n",
    "                     scale=0.3,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "    # DF\n",
    "def augment_df(image_data):\n",
    "    out_data = out_path+'df'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    ssr_images = glob('augmented/df/*')\n",
    "    horizontalflip(ssr_images, out_data,\n",
    "                       augment = True,\n",
    "                       resize = [128,128],\n",
    "                       random=1.0)\n",
    "    hf_images = glob('augmented/df/*')\n",
    "    verticalflip(hf_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    df_images = glob('augmented/df/*')\n",
    "    brightness_contrast(df_images,\n",
    "                            out_data,\n",
    "                            augment = True,\n",
    "                            resize=[128,128],\n",
    "                            random=1.0,\n",
    "                            brightness=0.2, \n",
    "                            contrast=0.2,\n",
    "                            by_max=False)\n",
    "    bc_images = glob('augmented/df/*')\n",
    "    shiftscalerotate(bc_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "    r_images = glob('augmented/df/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=3)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------\n",
    "# VASC\n",
    "def augment_vasc(image_data):\n",
    "    out_data = out_path+'vasc'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    ssr_images = glob('augmented/vasc/*')\n",
    "    horizontalflip(ssr_images, out_data,\n",
    "                       augment = True,\n",
    "                       resize = [128,128],\n",
    "                       random=1.0)\n",
    "    hf_images = glob('augmented/vasc/*')\n",
    "    verticalflip(hf_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    df_images = glob('augmented/vasc/*')\n",
    "    brightness_contrast(df_images,\n",
    "                            out_data,\n",
    "                            augment = True,\n",
    "                            resize=[128,128],\n",
    "                            random=1.0,\n",
    "                            brightness=0.2, \n",
    "                            contrast=0.2,\n",
    "                            by_max=False)\n",
    "    bc_images = glob('augmented/vasc/*')\n",
    "    shiftscalerotate(bc_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "    r_images = glob('augmented/vasc/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=3)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "# BCC\n",
    "def augment_bcc(image_data):\n",
    "    out_data = out_path+'bcc'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    ssr_images = glob('augmented/bcc/*')\n",
    "    horizontalflip(ssr_images, out_data,\n",
    "                       augment = True,\n",
    "                       resize = [128,128],\n",
    "                       random=1.0)\n",
    "    hf_images = glob('augmented/bcc/*')\n",
    "    verticalflip(hf_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    r_images = glob('augmented/bcc/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "# BKL\n",
    "def augment_bkl(image_data):\n",
    "    out_data = out_path+'bkl'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    ssr_images = glob('augmented/bkl/*')\n",
    "    verticalflip(ssr_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    r_images = glob('augmented/bkl/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------\n",
    "# MEL\n",
    "def augment_mel(image_data):\n",
    "    out_data = out_path+'mel'\n",
    "    verticalflip(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    vf_images = glob('augmented/mel/*')\n",
    "    brightness_contrast(vf_images,\n",
    "                            out_data,\n",
    "                            augment = True,\n",
    "                            resize=[128,128],\n",
    "                            random=1.0,\n",
    "                            brightness=0.2, \n",
    "                            contrast=0.2,\n",
    "                            by_max=False)\n",
    "    r_images = glob('augmented/mel/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------\n",
    "# NV\n",
    "# Selecting remaining images by shuffling all and selecting required\n",
    "def augment_nv(image_data):\n",
    "    for image in image_data:\n",
    "        shutil.copyfile(image, f'augmented/nv/{image.split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29e68d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 202.22it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1508.56it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1417.45it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1127.79it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1045.37it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:02<00:00, 163.06it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1136.29it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:01<00:00, 1307.22it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1193.79it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:04<00:00, 171.01it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:01<00:00, 1243.30it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1063.90it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 188.28it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1245.10it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1224.96it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1145.74it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:01<00:00, 1180.74it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1142.32it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 217.33it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1085.19it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1133.69it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 574.35it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1321.75it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1387.32it/s]\n",
      "100%|████████████████████████████████████████| 792/792 [00:00<00:00, 972.39it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1185.10it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1199.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32740 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 21:42:10.704341: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-09 21:42:11.179158: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3555 - accuracy: 0.4698"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 21:43:27.668469: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 92s 173ms/step - loss: 1.3555 - accuracy: 0.4698 - val_loss: 1.2582 - val_accuracy: 0.5387\n",
      "Epoch 2/20\n",
      "511/511 [==============================] - 84s 165ms/step - loss: 1.0801 - accuracy: 0.5896 - val_loss: 1.2133 - val_accuracy: 0.5727\n",
      "Epoch 3/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.9639 - accuracy: 0.6381 - val_loss: 0.9390 - val_accuracy: 0.6505\n",
      "Epoch 4/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.8820 - accuracy: 0.6714 - val_loss: 0.8743 - val_accuracy: 0.6726\n",
      "Epoch 5/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.8151 - accuracy: 0.6950 - val_loss: 0.9593 - val_accuracy: 0.6389\n",
      "Epoch 6/20\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.7527 - accuracy: 0.7207 - val_loss: 0.9576 - val_accuracy: 0.6658\n",
      "Epoch 7/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.7140 - accuracy: 0.7337 - val_loss: 0.8647 - val_accuracy: 0.6824\n",
      "Epoch 8/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.6828 - accuracy: 0.7450 - val_loss: 0.8865 - val_accuracy: 0.6749\n",
      "Epoch 9/20\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.6378 - accuracy: 0.7637 - val_loss: 0.8326 - val_accuracy: 0.7041\n",
      "Epoch 10/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.6158 - accuracy: 0.7708 - val_loss: 0.9072 - val_accuracy: 0.6760\n",
      "Epoch 11/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5825 - accuracy: 0.7847 - val_loss: 0.8654 - val_accuracy: 0.7055\n",
      "Epoch 12/20\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.5519 - accuracy: 0.7942 - val_loss: 0.9845 - val_accuracy: 0.6559\n",
      "Epoch 13/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5341 - accuracy: 0.8007 - val_loss: 0.9045 - val_accuracy: 0.6736\n",
      "Epoch 14/20\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.5130 - accuracy: 0.8108 - val_loss: 0.9479 - val_accuracy: 0.6817\n",
      "Epoch 15/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.4925 - accuracy: 0.8181 - val_loss: 0.8638 - val_accuracy: 0.7171\n",
      "Epoch 16/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.4865 - accuracy: 0.8186 - val_loss: 0.8603 - val_accuracy: 0.7204\n",
      "Epoch 17/20\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4590 - accuracy: 0.8280 - val_loss: 0.8746 - val_accuracy: 0.7164\n",
      "Epoch 18/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4476 - accuracy: 0.8352 - val_loss: 0.9103 - val_accuracy: 0.7041\n",
      "Epoch 19/20\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4314 - accuracy: 0.8420 - val_loss: 0.8136 - val_accuracy: 0.7510\n",
      "Epoch 20/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.4205 - accuracy: 0.8456 - val_loss: 1.2260 - val_accuracy: 0.6315\n",
      "CNN Model 1: Epochs=20, Training accuracy=0.84561, Validation accuracy=0.75102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 204.30it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1568.16it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1181.28it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1350.48it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1486.91it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 217.79it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1631.89it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1638.54it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1468.21it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 209.54it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1636.13it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1471.33it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 220.33it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1612.01it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1661.64it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1493.42it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1508.28it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1501.87it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 244.50it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1287.82it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1413.68it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 613.28it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1654.52it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1684.86it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1542.09it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1567.59it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1524.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32747 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 22:01:07.014078: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3718 - accuracy: 0.4553"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 22:01:46.458386: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 52s 102ms/step - loss: 1.3718 - accuracy: 0.4553 - val_loss: 0.9832 - val_accuracy: 0.6097\n",
      "Epoch 2/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 1.1158 - accuracy: 0.5735 - val_loss: 0.9909 - val_accuracy: 0.6264\n",
      "Epoch 3/20\n",
      "511/511 [==============================] - 55s 108ms/step - loss: 0.9992 - accuracy: 0.6223 - val_loss: 0.8793 - val_accuracy: 0.6709\n",
      "Epoch 4/20\n",
      "511/511 [==============================] - 53s 105ms/step - loss: 0.9248 - accuracy: 0.6556 - val_loss: 0.8601 - val_accuracy: 0.6603\n",
      "Epoch 5/20\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.8704 - accuracy: 0.6757 - val_loss: 1.0034 - val_accuracy: 0.6433\n",
      "Epoch 6/20\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.8124 - accuracy: 0.6971 - val_loss: 0.7976 - val_accuracy: 0.7062\n",
      "Epoch 7/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.7668 - accuracy: 0.7187 - val_loss: 0.9291 - val_accuracy: 0.6372\n",
      "Epoch 8/20\n",
      "511/511 [==============================] - 58s 113ms/step - loss: 0.7302 - accuracy: 0.7308 - val_loss: 1.0117 - val_accuracy: 0.6291\n",
      "Epoch 9/20\n",
      "511/511 [==============================] - 58s 113ms/step - loss: 0.6920 - accuracy: 0.7449 - val_loss: 0.9261 - val_accuracy: 0.6736\n",
      "Epoch 10/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.6610 - accuracy: 0.7537 - val_loss: 0.8994 - val_accuracy: 0.6861\n",
      "Epoch 11/20\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.6302 - accuracy: 0.7646 - val_loss: 0.9286 - val_accuracy: 0.6712\n",
      "Epoch 12/20\n",
      "511/511 [==============================] - 56s 110ms/step - loss: 0.6075 - accuracy: 0.7769 - val_loss: 0.9217 - val_accuracy: 0.6532\n",
      "Epoch 13/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.5838 - accuracy: 0.7863 - val_loss: 0.9253 - val_accuracy: 0.6790\n",
      "Epoch 14/20\n",
      "511/511 [==============================] - 60s 118ms/step - loss: 0.5574 - accuracy: 0.7966 - val_loss: 0.9655 - val_accuracy: 0.6481\n",
      "Epoch 15/20\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.5327 - accuracy: 0.8027 - val_loss: 0.8187 - val_accuracy: 0.7130\n",
      "Epoch 16/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.5190 - accuracy: 0.8100 - val_loss: 0.8955 - val_accuracy: 0.6967\n",
      "Epoch 17/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.4998 - accuracy: 0.8164 - val_loss: 0.8674 - val_accuracy: 0.7086\n",
      "Epoch 18/20\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.4860 - accuracy: 0.8198 - val_loss: 0.8348 - val_accuracy: 0.7255\n",
      "Epoch 19/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.4732 - accuracy: 0.8245 - val_loss: 0.7832 - val_accuracy: 0.7347\n",
      "Epoch 20/20\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.4591 - accuracy: 0.8291 - val_loss: 0.8449 - val_accuracy: 0.7184\n",
      "CNN Model 2: Epochs=20, Training accuracy=0.82905, Validation accuracy=0.73471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 200.36it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1529.25it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1385.41it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1430.84it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1467.45it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 215.12it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1490.86it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1622.01it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1481.65it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 204.71it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1626.77it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1487.15it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 206.03it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1471.57it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1395.02it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1436.76it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1515.47it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1430.17it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 249.73it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1504.50it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1535.45it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 601.24it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1739.76it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1748.48it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1573.78it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1467.18it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1480.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32748 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 22:19:31.567655: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3611 - accuracy: 0.4625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 22:20:12.581688: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 54s 105ms/step - loss: 1.3611 - accuracy: 0.4625 - val_loss: 1.0959 - val_accuracy: 0.5771\n",
      "Epoch 2/20\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 1.1030 - accuracy: 0.5765 - val_loss: 1.1120 - val_accuracy: 0.5713\n",
      "Epoch 3/20\n",
      "511/511 [==============================] - 58s 113ms/step - loss: 0.9995 - accuracy: 0.6178 - val_loss: 1.0351 - val_accuracy: 0.6213\n",
      "Epoch 4/20\n",
      "511/511 [==============================] - 55s 108ms/step - loss: 0.9230 - accuracy: 0.6512 - val_loss: 0.9944 - val_accuracy: 0.6359\n",
      "Epoch 5/20\n",
      "511/511 [==============================] - 56s 109ms/step - loss: 0.8395 - accuracy: 0.6833 - val_loss: 0.8751 - val_accuracy: 0.6872\n",
      "Epoch 6/20\n",
      "511/511 [==============================] - 55s 107ms/step - loss: 0.7883 - accuracy: 0.7042 - val_loss: 0.9275 - val_accuracy: 0.6637\n",
      "Epoch 7/20\n",
      "511/511 [==============================] - 55s 108ms/step - loss: 0.7525 - accuracy: 0.7193 - val_loss: 0.9060 - val_accuracy: 0.6824\n",
      "Epoch 8/20\n",
      "511/511 [==============================] - 58s 113ms/step - loss: 0.7084 - accuracy: 0.7344 - val_loss: 0.8167 - val_accuracy: 0.7215\n",
      "Epoch 9/20\n",
      "511/511 [==============================] - 56s 110ms/step - loss: 0.6784 - accuracy: 0.7452 - val_loss: 0.9634 - val_accuracy: 0.6569\n",
      "Epoch 10/20\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.6612 - accuracy: 0.7528 - val_loss: 0.8922 - val_accuracy: 0.6831\n",
      "Epoch 11/20\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.6217 - accuracy: 0.7683 - val_loss: 0.8464 - val_accuracy: 0.7113\n",
      "Epoch 12/20\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.6095 - accuracy: 0.7730 - val_loss: 0.9849 - val_accuracy: 0.6491\n",
      "Epoch 13/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5791 - accuracy: 0.7862 - val_loss: 0.8621 - val_accuracy: 0.7249\n",
      "Epoch 14/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5612 - accuracy: 0.7930 - val_loss: 0.9654 - val_accuracy: 0.6613\n",
      "Epoch 15/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5409 - accuracy: 0.8007 - val_loss: 0.8904 - val_accuracy: 0.7058\n",
      "Epoch 16/20\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.5410 - accuracy: 0.8005 - val_loss: 1.0283 - val_accuracy: 0.6590\n",
      "Epoch 17/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5034 - accuracy: 0.8119 - val_loss: 0.9006 - val_accuracy: 0.7215\n",
      "Epoch 18/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.4884 - accuracy: 0.8197 - val_loss: 0.8715 - val_accuracy: 0.7418\n",
      "Epoch 19/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.4801 - accuracy: 0.8210 - val_loss: 0.9218 - val_accuracy: 0.7018\n",
      "Epoch 20/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.4704 - accuracy: 0.8267 - val_loss: 0.8446 - val_accuracy: 0.7493\n",
      "CNN Model 3: Epochs=20, Training accuracy=0.82670, Validation accuracy=0.74932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 201.99it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1175.50it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1620.36it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1452.36it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1455.28it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 211.12it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1431.42it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1658.83it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1500.81it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 208.71it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1609.03it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1515.78it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 231.01it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1670.93it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1657.75it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1515.76it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1501.54it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1528.90it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 250.94it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1506.99it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1299.12it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 647.37it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1702.12it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1735.50it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1571.52it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1381.60it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1575.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32743 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 22:37:54.008487: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3454 - accuracy: 0.4659"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 22:38:34.289406: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 53s 104ms/step - loss: 1.3454 - accuracy: 0.4659 - val_loss: 1.1053 - val_accuracy: 0.5910\n",
      "Epoch 2/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 1.0976 - accuracy: 0.5812 - val_loss: 1.0970 - val_accuracy: 0.5829\n",
      "Epoch 3/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.9890 - accuracy: 0.6253 - val_loss: 1.0408 - val_accuracy: 0.6114\n",
      "Epoch 4/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.8996 - accuracy: 0.6621 - val_loss: 1.0230 - val_accuracy: 0.6162\n",
      "Epoch 5/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.8478 - accuracy: 0.6796 - val_loss: 0.7598 - val_accuracy: 0.7181\n",
      "Epoch 6/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.7911 - accuracy: 0.7008 - val_loss: 0.8420 - val_accuracy: 0.6885\n",
      "Epoch 7/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.7519 - accuracy: 0.7152 - val_loss: 0.8856 - val_accuracy: 0.6783\n",
      "Epoch 8/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.7236 - accuracy: 0.7282 - val_loss: 1.0196 - val_accuracy: 0.6423\n",
      "Epoch 9/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.6918 - accuracy: 0.7411 - val_loss: 0.8636 - val_accuracy: 0.7031\n",
      "Epoch 10/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.6544 - accuracy: 0.7527 - val_loss: 0.8437 - val_accuracy: 0.6953\n",
      "Epoch 11/20\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.6283 - accuracy: 0.7650 - val_loss: 0.9107 - val_accuracy: 0.6906\n",
      "Epoch 12/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6124 - accuracy: 0.7717 - val_loss: 0.8566 - val_accuracy: 0.6933\n",
      "Epoch 13/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5815 - accuracy: 0.7816 - val_loss: 0.8811 - val_accuracy: 0.7106\n",
      "Epoch 14/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5622 - accuracy: 0.7896 - val_loss: 0.9103 - val_accuracy: 0.7014\n",
      "Epoch 15/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.5436 - accuracy: 0.7972 - val_loss: 0.7933 - val_accuracy: 0.7337\n",
      "Epoch 16/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5249 - accuracy: 0.8006 - val_loss: 0.8273 - val_accuracy: 0.7249\n",
      "Epoch 17/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5012 - accuracy: 0.8149 - val_loss: 0.9096 - val_accuracy: 0.7106\n",
      "Epoch 18/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4897 - accuracy: 0.8194 - val_loss: 0.9998 - val_accuracy: 0.6933\n",
      "Epoch 19/20\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.4826 - accuracy: 0.8214 - val_loss: 0.8208 - val_accuracy: 0.7544\n",
      "Epoch 20/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4612 - accuracy: 0.8288 - val_loss: 0.8590 - val_accuracy: 0.7279\n",
      "CNN Model 4: Epochs=20, Training accuracy=0.82879, Validation accuracy=0.75442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 196.08it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1521.07it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1375.06it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1224.94it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1435.11it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 210.67it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1434.38it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1484.65it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1534.02it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 213.54it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1622.01it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1456.73it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 188.84it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1605.69it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1648.52it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1501.44it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1524.19it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1516.96it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 249.40it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1394.77it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1515.22it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 629.91it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1729.44it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1741.69it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1567.97it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1550.69it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1517.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32746 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 22:55:22.487044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3877 - accuracy: 0.4444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 22:56:00.914349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 51s 100ms/step - loss: 1.3877 - accuracy: 0.4444 - val_loss: 1.2088 - val_accuracy: 0.5540\n",
      "Epoch 2/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 1.1280 - accuracy: 0.5673 - val_loss: 1.0138 - val_accuracy: 0.6148\n",
      "Epoch 3/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 1.0090 - accuracy: 0.6175 - val_loss: 0.9836 - val_accuracy: 0.6298\n",
      "Epoch 4/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.9205 - accuracy: 0.6522 - val_loss: 0.8913 - val_accuracy: 0.6719\n",
      "Epoch 5/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.8603 - accuracy: 0.6746 - val_loss: 0.9673 - val_accuracy: 0.6433\n",
      "Epoch 6/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.7964 - accuracy: 0.6996 - val_loss: 0.8411 - val_accuracy: 0.6895\n",
      "Epoch 7/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.7553 - accuracy: 0.7152 - val_loss: 0.8608 - val_accuracy: 0.6787\n",
      "Epoch 8/20\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.7153 - accuracy: 0.7328 - val_loss: 0.8214 - val_accuracy: 0.6994\n",
      "Epoch 9/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6772 - accuracy: 0.7471 - val_loss: 0.8485 - val_accuracy: 0.6933\n",
      "Epoch 10/20\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.6492 - accuracy: 0.7584 - val_loss: 0.8477 - val_accuracy: 0.6970\n",
      "Epoch 11/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6174 - accuracy: 0.7707 - val_loss: 0.8519 - val_accuracy: 0.6967\n",
      "Epoch 12/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.5983 - accuracy: 0.7762 - val_loss: 0.8915 - val_accuracy: 0.6933\n",
      "Epoch 13/20\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.5724 - accuracy: 0.7855 - val_loss: 0.9473 - val_accuracy: 0.6817\n",
      "Epoch 14/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.5546 - accuracy: 0.7927 - val_loss: 1.0100 - val_accuracy: 0.6651\n",
      "Epoch 15/20\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.5348 - accuracy: 0.8007 - val_loss: 0.8747 - val_accuracy: 0.7123\n",
      "Epoch 16/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5240 - accuracy: 0.8036 - val_loss: 0.9280 - val_accuracy: 0.6736\n",
      "Epoch 17/20\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4870 - accuracy: 0.8184 - val_loss: 0.8272 - val_accuracy: 0.7255\n",
      "Epoch 18/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.4823 - accuracy: 0.8241 - val_loss: 0.9108 - val_accuracy: 0.6984\n",
      "Epoch 19/20\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4724 - accuracy: 0.8236 - val_loss: 0.8378 - val_accuracy: 0.7184\n",
      "Epoch 20/20\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4500 - accuracy: 0.8325 - val_loss: 0.8678 - val_accuracy: 0.7269\n",
      "CNN Model 5: Epochs=20, Training accuracy=0.83251, Validation accuracy=0.72690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 181.27it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1598.47it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1593.02it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1442.30it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1382.97it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 203.24it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1616.30it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1599.31it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1493.28it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 208.53it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1659.02it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1515.46it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 207.28it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1645.34it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1663.99it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1506.07it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1492.72it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1522.73it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 243.35it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1523.21it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1539.00it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 574.97it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1717.91it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1744.15it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1571.95it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1558.03it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1585.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32747 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 23:12:51.295196: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3791 - accuracy: 0.4537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 23:13:30.760295: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 52s 102ms/step - loss: 1.3791 - accuracy: 0.4537 - val_loss: 1.0491 - val_accuracy: 0.5832\n",
      "Epoch 2/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 1.1212 - accuracy: 0.5711 - val_loss: 1.1163 - val_accuracy: 0.5842\n",
      "Epoch 3/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 1.0130 - accuracy: 0.6139 - val_loss: 0.9292 - val_accuracy: 0.6464\n",
      "Epoch 4/20\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.9238 - accuracy: 0.6498 - val_loss: 0.9918 - val_accuracy: 0.6257\n",
      "Epoch 5/20\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.8610 - accuracy: 0.6755 - val_loss: 0.9397 - val_accuracy: 0.6478\n",
      "Epoch 6/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.7965 - accuracy: 0.7013 - val_loss: 0.8397 - val_accuracy: 0.6919\n",
      "Epoch 7/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.7424 - accuracy: 0.7210 - val_loss: 0.9242 - val_accuracy: 0.6586\n",
      "Epoch 8/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.7125 - accuracy: 0.7338 - val_loss: 0.8609 - val_accuracy: 0.6821\n",
      "Epoch 9/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.6736 - accuracy: 0.7470 - val_loss: 0.9577 - val_accuracy: 0.6556\n",
      "Epoch 10/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.6374 - accuracy: 0.7634 - val_loss: 0.8507 - val_accuracy: 0.6940\n",
      "Epoch 11/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.6241 - accuracy: 0.7690 - val_loss: 0.9064 - val_accuracy: 0.6892\n",
      "Epoch 12/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.5857 - accuracy: 0.7826 - val_loss: 0.9187 - val_accuracy: 0.6800\n",
      "Epoch 13/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.5692 - accuracy: 0.7902 - val_loss: 0.8148 - val_accuracy: 0.7177\n",
      "Epoch 14/20\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.5592 - accuracy: 0.7936 - val_loss: 0.7646 - val_accuracy: 0.7340\n",
      "Epoch 15/20\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.5330 - accuracy: 0.8042 - val_loss: 0.8708 - val_accuracy: 0.6902\n",
      "Epoch 16/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5124 - accuracy: 0.8113 - val_loss: 0.8815 - val_accuracy: 0.7058\n",
      "Epoch 17/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5022 - accuracy: 0.8144 - val_loss: 0.8638 - val_accuracy: 0.7201\n",
      "Epoch 18/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4939 - accuracy: 0.8161 - val_loss: 0.8981 - val_accuracy: 0.7055\n",
      "Epoch 19/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4666 - accuracy: 0.8283 - val_loss: 0.8374 - val_accuracy: 0.7262\n",
      "Epoch 20/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4541 - accuracy: 0.8328 - val_loss: 0.9170 - val_accuracy: 0.7079\n",
      "CNN Model 6: Epochs=20, Training accuracy=0.83276, Validation accuracy=0.73404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 195.61it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1606.11it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1617.99it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1450.05it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1248.69it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 211.98it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1422.94it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1626.46it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1401.04it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 209.85it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1623.30it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1507.59it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 218.52it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1625.19it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1634.11it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1538.49it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1462.03it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1499.50it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 245.77it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1458.22it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1484.51it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 570.94it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1517.74it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1730.90it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1455.30it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:00<00:00, 1589.90it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1581.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32737 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 23:30:25.202142: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.4047 - accuracy: 0.4394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 23:31:02.785607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 51s 98ms/step - loss: 1.4047 - accuracy: 0.4394 - val_loss: 1.0729 - val_accuracy: 0.5934\n",
      "Epoch 2/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 1.1353 - accuracy: 0.5621 - val_loss: 0.9161 - val_accuracy: 0.6685\n",
      "Epoch 3/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 1.0221 - accuracy: 0.6077 - val_loss: 0.9544 - val_accuracy: 0.6355\n",
      "Epoch 4/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.9298 - accuracy: 0.6489 - val_loss: 0.8060 - val_accuracy: 0.7024\n",
      "Epoch 5/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.8550 - accuracy: 0.6794 - val_loss: 0.8828 - val_accuracy: 0.6617\n",
      "Epoch 6/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.7933 - accuracy: 0.7060 - val_loss: 0.7346 - val_accuracy: 0.7374\n",
      "Epoch 7/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.7389 - accuracy: 0.7234 - val_loss: 0.7950 - val_accuracy: 0.7011\n",
      "Epoch 8/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.7071 - accuracy: 0.7363 - val_loss: 0.9574 - val_accuracy: 0.6566\n",
      "Epoch 9/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6674 - accuracy: 0.7539 - val_loss: 0.8837 - val_accuracy: 0.6753\n",
      "Epoch 10/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6373 - accuracy: 0.7649 - val_loss: 0.8315 - val_accuracy: 0.7018\n",
      "Epoch 11/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6085 - accuracy: 0.7751 - val_loss: 0.7028 - val_accuracy: 0.7476\n",
      "Epoch 12/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5768 - accuracy: 0.7875 - val_loss: 0.7469 - val_accuracy: 0.7272\n",
      "Epoch 13/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.5575 - accuracy: 0.7946 - val_loss: 0.7709 - val_accuracy: 0.7364\n",
      "Epoch 14/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.5355 - accuracy: 0.8003 - val_loss: 0.8755 - val_accuracy: 0.6858\n",
      "Epoch 15/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5138 - accuracy: 0.8112 - val_loss: 0.8127 - val_accuracy: 0.7191\n",
      "Epoch 16/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4968 - accuracy: 0.8149 - val_loss: 0.7662 - val_accuracy: 0.7585\n",
      "Epoch 17/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4764 - accuracy: 0.8247 - val_loss: 0.7769 - val_accuracy: 0.7425\n",
      "Epoch 18/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.4692 - accuracy: 0.8266 - val_loss: 0.8484 - val_accuracy: 0.7208\n",
      "Epoch 19/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4614 - accuracy: 0.8303 - val_loss: 0.7447 - val_accuracy: 0.7514\n",
      "Epoch 20/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4350 - accuracy: 0.8412 - val_loss: 0.7979 - val_accuracy: 0.7452\n",
      "CNN Model 7: Epochs=20, Training accuracy=0.84125, Validation accuracy=0.75849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 199.37it/s]\n",
      "100%|████████████████████████████████████████| 456/456 [00:00<00:00, 998.70it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1559.90it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1422.39it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1483.59it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 218.02it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1638.90it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1646.15it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1472.85it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 207.44it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1632.16it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1479.03it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 209.53it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1691.26it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1669.10it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1502.29it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1503.99it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1419.73it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 247.81it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1325.48it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1369.75it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 581.00it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1367.40it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1513.82it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1583.72it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:00<00:00, 1609.97it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1594.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32738 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 23:47:38.386572: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3747 - accuracy: 0.4631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 23:48:14.414599: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 49s 96ms/step - loss: 1.3747 - accuracy: 0.4631 - val_loss: 1.1538 - val_accuracy: 0.5513\n",
      "Epoch 2/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 1.0856 - accuracy: 0.5864 - val_loss: 0.9610 - val_accuracy: 0.6386\n",
      "Epoch 3/20\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.9724 - accuracy: 0.6335 - val_loss: 0.8445 - val_accuracy: 0.6810\n",
      "Epoch 4/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.8897 - accuracy: 0.6651 - val_loss: 1.0141 - val_accuracy: 0.6243\n",
      "Epoch 5/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.8315 - accuracy: 0.6887 - val_loss: 0.9150 - val_accuracy: 0.6444\n",
      "Epoch 6/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.7714 - accuracy: 0.7120 - val_loss: 0.8324 - val_accuracy: 0.6974\n",
      "Epoch 7/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.7304 - accuracy: 0.7301 - val_loss: 0.8202 - val_accuracy: 0.7082\n",
      "Epoch 8/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.6956 - accuracy: 0.7422 - val_loss: 0.9090 - val_accuracy: 0.6678\n",
      "Epoch 9/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.6574 - accuracy: 0.7545 - val_loss: 0.7427 - val_accuracy: 0.7320\n",
      "Epoch 10/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6217 - accuracy: 0.7713 - val_loss: 0.7430 - val_accuracy: 0.7303\n",
      "Epoch 11/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6061 - accuracy: 0.7742 - val_loss: 0.8416 - val_accuracy: 0.7079\n",
      "Epoch 12/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5875 - accuracy: 0.7840 - val_loss: 0.8004 - val_accuracy: 0.7143\n",
      "Epoch 13/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.5615 - accuracy: 0.7930 - val_loss: 0.8586 - val_accuracy: 0.6926\n",
      "Epoch 14/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.5418 - accuracy: 0.8009 - val_loss: 0.9875 - val_accuracy: 0.6692\n",
      "Epoch 15/20\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.5158 - accuracy: 0.8096 - val_loss: 0.8857 - val_accuracy: 0.6929\n",
      "Epoch 16/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.5090 - accuracy: 0.8108 - val_loss: 0.7697 - val_accuracy: 0.7385\n",
      "Epoch 17/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.4867 - accuracy: 0.8175 - val_loss: 0.7814 - val_accuracy: 0.7388\n",
      "Epoch 18/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.4755 - accuracy: 0.8254 - val_loss: 0.8963 - val_accuracy: 0.7001\n",
      "Epoch 19/20\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.4673 - accuracy: 0.8278 - val_loss: 1.0355 - val_accuracy: 0.6512\n",
      "Epoch 20/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.4404 - accuracy: 0.8374 - val_loss: 0.8496 - val_accuracy: 0.7303\n",
      "CNN Model 8: Epochs=20, Training accuracy=0.83736, Validation accuracy=0.73879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 198.34it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1518.86it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1639.60it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1482.18it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1483.42it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 212.55it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1568.25it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:01<00:00, 1322.31it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1500.10it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 205.33it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1629.62it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1511.01it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 219.95it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1647.17it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1656.60it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1494.49it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1523.91it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1493.23it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 243.25it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1490.64it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1495.69it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 685.86it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1677.98it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1720.58it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1575.05it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1560.05it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1455.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32737 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 00:04:50.672689: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3801 - accuracy: 0.4512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 00:05:29.272815: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 52s 101ms/step - loss: 1.3801 - accuracy: 0.4512 - val_loss: 1.0425 - val_accuracy: 0.6077\n",
      "Epoch 2/20\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 1.1295 - accuracy: 0.5628 - val_loss: 1.1841 - val_accuracy: 0.5530\n",
      "Epoch 3/20\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 1.0210 - accuracy: 0.6107 - val_loss: 1.1154 - val_accuracy: 0.5910\n",
      "Epoch 4/20\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.9309 - accuracy: 0.6477 - val_loss: 0.9080 - val_accuracy: 0.6579\n",
      "Epoch 5/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.8578 - accuracy: 0.6773 - val_loss: 0.9498 - val_accuracy: 0.6437\n",
      "Epoch 6/20\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.7954 - accuracy: 0.7028 - val_loss: 0.8880 - val_accuracy: 0.6675\n",
      "Epoch 7/20\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.7551 - accuracy: 0.7167 - val_loss: 0.8718 - val_accuracy: 0.6763\n",
      "Epoch 8/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.7152 - accuracy: 0.7305 - val_loss: 0.8476 - val_accuracy: 0.7001\n",
      "Epoch 9/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.6818 - accuracy: 0.7456 - val_loss: 0.8729 - val_accuracy: 0.6980\n",
      "Epoch 10/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6524 - accuracy: 0.7562 - val_loss: 0.9140 - val_accuracy: 0.6844\n",
      "Epoch 11/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6329 - accuracy: 0.7644 - val_loss: 0.9726 - val_accuracy: 0.6705\n",
      "Epoch 12/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6132 - accuracy: 0.7701 - val_loss: 0.8717 - val_accuracy: 0.6916\n",
      "Epoch 13/20\n",
      "511/511 [==============================] - 49s 97ms/step - loss: 0.5905 - accuracy: 0.7803 - val_loss: 0.8751 - val_accuracy: 0.7089\n",
      "Epoch 14/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.5680 - accuracy: 0.7883 - val_loss: 0.8881 - val_accuracy: 0.6909\n",
      "Epoch 15/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5409 - accuracy: 0.7986 - val_loss: 0.8600 - val_accuracy: 0.7089\n",
      "Epoch 16/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.5302 - accuracy: 0.8029 - val_loss: 0.8558 - val_accuracy: 0.7109\n",
      "Epoch 17/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.5156 - accuracy: 0.8068 - val_loss: 0.8116 - val_accuracy: 0.7266\n",
      "Epoch 18/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5006 - accuracy: 0.8120 - val_loss: 0.8348 - val_accuracy: 0.7120\n",
      "Epoch 19/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4849 - accuracy: 0.8198 - val_loss: 0.9397 - val_accuracy: 0.6974\n",
      "Epoch 20/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4724 - accuracy: 0.8222 - val_loss: 1.1866 - val_accuracy: 0.6240\n",
      "CNN Model 9: Epochs=20, Training accuracy=0.82224, Validation accuracy=0.72656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 188.90it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1140.12it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1528.41it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1339.95it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1412.25it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 212.90it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1613.53it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1594.19it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1526.46it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 214.66it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1593.09it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1495.42it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 219.06it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1617.10it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1644.96it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1491.21it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1505.53it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1480.08it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 248.30it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1419.70it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1288.26it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 622.90it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1709.11it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1583.30it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1563.01it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:00<00:00, 1591.29it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1576.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32740 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 00:21:59.279199: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3626 - accuracy: 0.4614"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 00:22:35.785597: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 50s 97ms/step - loss: 1.3626 - accuracy: 0.4614 - val_loss: 1.1187 - val_accuracy: 0.5615\n",
      "Epoch 2/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 1.1020 - accuracy: 0.5721 - val_loss: 1.2554 - val_accuracy: 0.5625\n",
      "Epoch 3/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.9986 - accuracy: 0.6122 - val_loss: 1.0759 - val_accuracy: 0.6036\n",
      "Epoch 4/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.9292 - accuracy: 0.6427 - val_loss: 1.0176 - val_accuracy: 0.6172\n",
      "Epoch 5/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.8550 - accuracy: 0.6755 - val_loss: 0.9867 - val_accuracy: 0.6467\n",
      "Epoch 6/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.8009 - accuracy: 0.6969 - val_loss: 0.8880 - val_accuracy: 0.6919\n",
      "Epoch 7/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.7627 - accuracy: 0.7130 - val_loss: 0.9687 - val_accuracy: 0.6583\n",
      "Epoch 8/20\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.7194 - accuracy: 0.7306 - val_loss: 0.8050 - val_accuracy: 0.7235\n",
      "Epoch 9/20\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.7026 - accuracy: 0.7325 - val_loss: 1.0216 - val_accuracy: 0.6495\n",
      "Epoch 10/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6540 - accuracy: 0.7531 - val_loss: 1.0116 - val_accuracy: 0.6593\n",
      "Epoch 11/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6268 - accuracy: 0.7648 - val_loss: 0.7887 - val_accuracy: 0.7401\n",
      "Epoch 12/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6043 - accuracy: 0.7732 - val_loss: 0.9593 - val_accuracy: 0.6709\n",
      "Epoch 13/20\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.5831 - accuracy: 0.7815 - val_loss: 0.8624 - val_accuracy: 0.7266\n",
      "Epoch 14/20\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5661 - accuracy: 0.7898 - val_loss: 0.8979 - val_accuracy: 0.7086\n",
      "Epoch 15/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5455 - accuracy: 0.7960 - val_loss: 0.8315 - val_accuracy: 0.7368\n",
      "Epoch 16/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5261 - accuracy: 0.8030 - val_loss: 0.8700 - val_accuracy: 0.7259\n",
      "Epoch 17/20\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.5098 - accuracy: 0.8107 - val_loss: 0.9477 - val_accuracy: 0.7069\n",
      "Epoch 18/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4972 - accuracy: 0.8143 - val_loss: 0.9340 - val_accuracy: 0.7031\n",
      "Epoch 19/20\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4916 - accuracy: 0.8172 - val_loss: 0.8364 - val_accuracy: 0.7364\n",
      "Epoch 20/20\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.4712 - accuracy: 0.8258 - val_loss: 0.9944 - val_accuracy: 0.6899\n",
      "CNN Model 10: Epochs=20, Training accuracy=0.82577, Validation accuracy=0.74015\n"
     ]
    }
   ],
   "source": [
    "# Augment, Split and Train\n",
    "classes = ['akiec','bcc','bkl','df','nv','mel','vasc']\n",
    "\n",
    "TRAIN_DIR = 'Processed_Data/train'\n",
    "model_train = [0] * n\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "for j in range(n):\n",
    "    # Train test Split\n",
    "    rs = np.random.randint(100,150)*(j+1)\n",
    "    for clas in classes:\n",
    "        os.makedirs(f'augmented/{clas}')\n",
    "    for cl in classes:\n",
    "        r_images = glob(f'{TRAIN_DIR}/{cl}/*')\n",
    "        r_images_shuf = shuffling_tt(r_images,rs)\n",
    "        train = int(0.7*len(r_images))\n",
    "        r_train = r_images_shuf[0:train]\n",
    "        r_test = r_images_shuf[train:]\n",
    "        if cl == 'akiec':\n",
    "            augment_akiec(r_train)\n",
    "        elif cl == 'bcc':\n",
    "            augment_bcc(r_train)\n",
    "        elif cl == 'bkl':\n",
    "            augment_bkl(r_train)\n",
    "        elif cl == 'df':\n",
    "            augment_df(r_train)\n",
    "        elif cl == 'mel':\n",
    "            augment_mel(r_train)\n",
    "        elif cl == 'vasc':\n",
    "            augment_vasc(r_train)\n",
    "        else:\n",
    "            augment_nv(r_train)\n",
    "        if not os.path.isdir(f'test/{cl}'):\n",
    "            os.makedirs(f'test/{cl}')\n",
    "        for image in r_test:\n",
    "            shutil.copyfile(image, f'test/{cl}/{image.split(\"/\")[-1]}')\n",
    "    # Model Training\n",
    "\n",
    "    train_dir = 'augmented'\n",
    "    test_dir = 'test'\n",
    "    datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical') # set as training data\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    model_train[j] = ensemble[j].fit_generator(train_generator,\n",
    "                                               steps_per_epoch=train_generator.samples//batch_size,\n",
    "                                               validation_steps=validation_generator.samples//batch_size,\n",
    "                                               validation_data = validation_generator,\n",
    "                                               epochs = epochs)\n",
    "    print(\"CNN Model {0:d}: Epochs={1:d}, Training accuracy={2:.5f}, Validation accuracy={3:.5f}\".\n",
    "          format(j+1,epochs,\n",
    "                 max(model_train[j].history['accuracy']),\n",
    "                 max(model_train[j].history['val_accuracy']) ))\n",
    "    if j!=9:\n",
    "        shutil.rmtree('augmented')\n",
    "        shutil.rmtree('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fa01003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "#Result\n",
    "results = np.zeros( (validation_generator.samples,7) ) \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a907fea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3006 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generating Generator of Validation data again\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b2a17c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 00:46:11.490332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-10 00:46:24.065643: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-10 00:46:36.683811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-10 00:46:49.315208: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-10 00:47:02.053324: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-10 00:47:14.849829: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-10 00:47:27.603474: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-10 00:47:40.537109: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-10 00:47:53.300561: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Get result from each model of ensemble\n",
    "for j in range(n):\n",
    "    results = results + ensemble[j].predict_generator(validation_generator,\n",
    "                                                      validation_generator.samples // batch_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0be87b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 6, 6, 6])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform Max voting\n",
    "results = np.argmax(results,axis = 1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "383d917a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[  85    1    1    0    0   12    0]\n",
      " [   1  133    2    0    0   17    0]\n",
      " [   1    3  213    0    4  109    0]\n",
      " [   1    0    0   22    1   11    0]\n",
      " [   2    2    5    0  224  101    0]\n",
      " [   1    2    9    4    3 1993    0]\n",
      " [   0    0    0    0    0    0   43]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.93      0.86      0.89        99\n",
      "         bcc       0.94      0.87      0.90       153\n",
      "         bkl       0.93      0.65      0.76       330\n",
      "          df       0.85      0.63      0.72        35\n",
      "         mel       0.97      0.67      0.79       334\n",
      "          nv       0.89      0.99      0.94      2012\n",
      "        vasc       1.00      1.00      1.00        43\n",
      "\n",
      "    accuracy                           0.90      3006\n",
      "   macro avg       0.93      0.81      0.86      3006\n",
      "weighted avg       0.91      0.90      0.90      3006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, results))\n",
    "print('Classification Report')\n",
    "target_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "print(classification_report(validation_generator.classes, results, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37dfe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9a21248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 15:39:17.204751: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Ensemble1_model0/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble1_model1/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble1_model2/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble1_model3/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble1_model4/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble1_model5/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble1_model6/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble1_model7/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble1_model8/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble1_model9/assets\n"
     ]
    }
   ],
   "source": [
    "# Sving Model in Keras Default Format\n",
    "for k in range(n):\n",
    "    ensemble[k].save(f'Ensemble1_model{k}')\n",
    "# # Saving Model in H5 Format\n",
    "for k in range(n):\n",
    "    ensemble[k].save(f'Ensemble1_model{k}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5cc7fd",
   "metadata": {},
   "source": [
    "## Loading Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e13a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Load the model\n",
    "# It can be used to reconstruct the model identically.\n",
    "# reconstructed_ensemble = [0]*n\n",
    "# for k in range(n):\n",
    "#     reconstructed_ensemble[k] = keras.models.load_model(f\"Saved Models/Ensemble1/Ensemble1_model{k}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
