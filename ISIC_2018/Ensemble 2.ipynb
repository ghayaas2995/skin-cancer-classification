{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92264f85",
   "metadata": {},
   "source": [
    "# Ensemble of Modified Base Model : Model 6\n",
    "(Dropout 25%, 1 extra CNN Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b90d05",
   "metadata": {},
   "source": [
    "## Approach\n",
    "- Create a List of Base Models\n",
    "- Take all the Preprocessed Images from each Class\n",
    "- Split Training data into Train and Validation with 0.7 traim-test ratio\n",
    "- Perform this splitting for each model in a loop with a different random state so that shuffling of images is different for each model.\n",
    "- Perform Augmentation on each class of training data splitted above \n",
    "- Train the models on augmented data validating on 30% validation data\n",
    "- Once all models in list are trained, use max voting to find predction of validation image set\n",
    "\n",
    "Before running make sure there is no augmented & test folder in the directory of notebook since it is created in this file itself. If it exists delete them. A caveat here is that if you wish to run Model_1_2_3_4.ipynb file again, you need to run Preprocessing Notebook again to form required folders.\n",
    "\n",
    "Also, if required change the path seperator to run code smoothly on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1405c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "# For missing libraries\n",
    "# pip install -U package_name --user\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from functools import partial\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import io\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import albumentations\n",
    "from albumentations import ShiftScaleRotate, HorizontalFlip, VerticalFlip, RandomBrightnessContrast\n",
    "import warnings\n",
    "import shutil\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "266d7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Augmentation functions\n",
    "# Shifting, Scaling & Rotations\n",
    "def shiftscalerotate(images, save_path,\n",
    "                     augment = True,\n",
    "                     resize = [256,256],\n",
    "                     random=1.0,\n",
    "                     rotation=0,\n",
    "                     shift=0,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     always=True,\n",
    "                     call=1):\n",
    "    H, W = resize\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = ShiftScaleRotate(p=random, rotate_limit=(-30,30), interpolation=interpolation,\n",
    "                                  always_apply=always)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "            save_images = [x, x1] # save original image and the augmented image\n",
    "        # If the augment paramter is set to False, The function only saves the original image and mask to the defined save_path\n",
    "        else:\n",
    "            save_images = [x] \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "            if idx == 0:\n",
    "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            else:\n",
    "                aug_ext = '_ssr'*call\n",
    "                tmp_img_name = f\"{image_name}{aug_ext}.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)\n",
    "            idx +=1\n",
    "# Horizontal Flipping\n",
    "def horizontalflip(images, save_path,\n",
    "                   augment = True,\n",
    "                   resize = [256,256],\n",
    "                   random=1.0,\n",
    "                   always=True):\n",
    "    H, W = resize\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        if augment ==True:\n",
    "            aug = HorizontalFlip(always_apply=always, p=random)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "            save_images = [x, x1] # make sure only x1. If x is given in 2nd augmentation onwards, then duplicate images will be saved\n",
    "        # If the augment paramter is set to False, The function only saves the original image and mask to the defined save_path\n",
    "        else:\n",
    "            save_images = [x]\n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "            if idx == 0:\n",
    "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            else:\n",
    "                tmp_img_name = f\"{image_name}_hf.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)\n",
    "            idx +=1\n",
    "#vertical flipping\n",
    "def verticalflip(images,\n",
    "                 save_path,\n",
    "                 augment = True,\n",
    "                 resize=[256,256],\n",
    "                 random=1.0,\n",
    "                 always=True):\n",
    "    H, W = resize\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "        # Now that we have the names, we have to read the image\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        if augment ==True:\n",
    "            aug = VerticalFlip(always_apply=always, p=random)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "            save_images = [x, x1]\n",
    "        # If the augment paramter is set to False, The function only saves the original image and mask to the defined save_path\n",
    "        else:\n",
    "            save_images = [x]\n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "            if idx == 0:\n",
    "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            else:\n",
    "                tmp_img_name = f\"{image_name}_vf.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)\n",
    "            idx +=1\n",
    "def brightness_contrast(images,\n",
    "                        save_path,\n",
    "                        augment = True,\n",
    "                        resize=[256,256],\n",
    "                        random=1.0,\n",
    "                        brightness=0.2, \n",
    "                        contrast=0.2,\n",
    "                        by_max=False,\n",
    "                        always=True):\n",
    "    H, W = resize\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "        # Now that we have the names, we have to read the image\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        if augment ==True:\n",
    "            aug = RandomBrightnessContrast(brightness_limit=brightness,\n",
    "                                           contrast_limit=contrast,\n",
    "                                           brightness_by_max=by_max,\n",
    "                                           always_apply=always,\n",
    "                                           p=random)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "            save_images = [x, x1]\n",
    "        # If the augment paramter is set to False, The function only saves the original image and mask to the defined save_path\n",
    "        else:\n",
    "            save_images = [x]\n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "            if idx == 0:\n",
    "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            else:\n",
    "                tmp_img_name = f\"{image_name}_bc.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4fd727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ensemble of 10 models\n",
    "n = 10\n",
    "ensemble = [0]* n\n",
    "def shuffling_tt(X, rs):\n",
    "    X= shuffle(X, random_state=rs)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9d83d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create & Complie Ensemble\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu',\n",
    "                        padding=\"SAME\")\n",
    "for k in range(n):\n",
    "    ensemble[k] = keras.models.Sequential([\n",
    "                    DefaultConv2D(filters=16, input_shape=[128, 128, 3]),\n",
    "                    keras.layers.AveragePooling2D(pool_size=2),\n",
    "                    DefaultConv2D(filters=32),\n",
    "                    keras.layers.MaxPooling2D(pool_size=2),\n",
    "                    DefaultConv2D(filters=64),\n",
    "                    keras.layers.MaxPooling2D(pool_size=2),\n",
    "                    DefaultConv2D(filters=128),\n",
    "                    keras.layers.MaxPooling2D(pool_size=2),\n",
    "                    keras.layers.Dropout(0.25),\n",
    "                    keras.layers.Flatten(),\n",
    "                    keras.layers.Dense(units=7, activation='softmax'),\n",
    "                    ])\n",
    "    ensemble[k].compile(loss='categorical_crossentropy',\n",
    "                        optimizer='adam',\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bef81fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 128, 128, 16)      448       \n",
      "                                                                 \n",
      " average_pooling2d_10 (Avera  (None, 64, 64, 16)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 64, 64, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 32, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 7)                 57351     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154,791\n",
      "Trainable params: 154,791\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ensemble[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "886831b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Augmentation functions for each class\n",
    "def shuffling(X):\n",
    "    X= shuffle(X, random_state=42)\n",
    "    return X\n",
    "out_path = 'augmented/'\n",
    "# Performing Augmentations Class-Wise\n",
    "# AKIEC\n",
    "def augment_akiec(image_data):\n",
    "    out_data = out_path+'akiec'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST)\n",
    "    ssr_images = glob('augmented/akiec/*')\n",
    "    horizontalflip(ssr_images, out_data,\n",
    "                       augment = True,\n",
    "                       resize = [128,128],\n",
    "                       random=1.0)\n",
    "    hf_images = glob('augmented/akiec/*')\n",
    "    verticalflip(hf_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    df_images = glob('augmented/akiec/*')\n",
    "    brightness_contrast(df_images,\n",
    "                            out_data,\n",
    "                            augment = True,\n",
    "                            resize=[128,128],\n",
    "                            random=1.0,\n",
    "                            brightness=0.2, \n",
    "                            contrast=0.2,\n",
    "                            by_max=False)\n",
    "    # Selecting remaining images by shuffling all and selecting required\n",
    "    bc_images = glob('augmented/akiec/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    bc_images_shuf = shuffling(bc_images)\n",
    "    target = 4693\n",
    "    available = len(bc_images)\n",
    "    bc_selected = bc_images_shuf[0:target-available]\n",
    "    shiftscalerotate(bc_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=0,\n",
    "                     shift=0,\n",
    "                     scale=0.3,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "    # DF\n",
    "def augment_df(image_data):\n",
    "    out_data = out_path+'df'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    ssr_images = glob('augmented/df/*')\n",
    "    horizontalflip(ssr_images, out_data,\n",
    "                       augment = True,\n",
    "                       resize = [128,128],\n",
    "                       random=1.0)\n",
    "    hf_images = glob('augmented/df/*')\n",
    "    verticalflip(hf_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    df_images = glob('augmented/df/*')\n",
    "    brightness_contrast(df_images,\n",
    "                            out_data,\n",
    "                            augment = True,\n",
    "                            resize=[128,128],\n",
    "                            random=1.0,\n",
    "                            brightness=0.2, \n",
    "                            contrast=0.2,\n",
    "                            by_max=False)\n",
    "    bc_images = glob('augmented/df/*')\n",
    "    shiftscalerotate(bc_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "    r_images = glob('augmented/df/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=3)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------\n",
    "# VASC\n",
    "def augment_vasc(image_data):\n",
    "    out_data = out_path+'vasc'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    ssr_images = glob('augmented/vasc/*')\n",
    "    horizontalflip(ssr_images, out_data,\n",
    "                       augment = True,\n",
    "                       resize = [128,128],\n",
    "                       random=1.0)\n",
    "    hf_images = glob('augmented/vasc/*')\n",
    "    verticalflip(hf_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    df_images = glob('augmented/vasc/*')\n",
    "    brightness_contrast(df_images,\n",
    "                            out_data,\n",
    "                            augment = True,\n",
    "                            resize=[128,128],\n",
    "                            random=1.0,\n",
    "                            brightness=0.2, \n",
    "                            contrast=0.2,\n",
    "                            by_max=False)\n",
    "    bc_images = glob('augmented/vasc/*')\n",
    "    shiftscalerotate(bc_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "    r_images = glob('augmented/vasc/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=3)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "# BCC\n",
    "def augment_bcc(image_data):\n",
    "    out_data = out_path+'bcc'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    ssr_images = glob('augmented/bcc/*')\n",
    "    horizontalflip(ssr_images, out_data,\n",
    "                       augment = True,\n",
    "                       resize = [128,128],\n",
    "                       random=1.0)\n",
    "    hf_images = glob('augmented/bcc/*')\n",
    "    verticalflip(hf_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    r_images = glob('augmented/bcc/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "# BKL\n",
    "def augment_bkl(image_data):\n",
    "    out_data = out_path+'bkl'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    ssr_images = glob('augmented/bkl/*')\n",
    "    verticalflip(ssr_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    r_images = glob('augmented/bkl/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------\n",
    "# MEL\n",
    "def augment_mel(image_data):\n",
    "    out_data = out_path+'mel'\n",
    "    verticalflip(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    vf_images = glob('augmented/mel/*')\n",
    "    brightness_contrast(vf_images,\n",
    "                            out_data,\n",
    "                            augment = True,\n",
    "                            resize=[128,128],\n",
    "                            random=1.0,\n",
    "                            brightness=0.2, \n",
    "                            contrast=0.2,\n",
    "                            by_max=False)\n",
    "    r_images = glob('augmented/mel/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------\n",
    "# NV\n",
    "# Selecting remaining images by shuffling all and selecting required\n",
    "def augment_nv(image_data):\n",
    "    for image in image_data:\n",
    "        shutil.copyfile(image, f'augmented/nv/{image.split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f7c1973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 205.97it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1520.51it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1561.87it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1407.46it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1425.41it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 206.87it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1595.70it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1622.51it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1457.34it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 212.86it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:01<00:00, 1441.89it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1372.03it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 188.03it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1498.16it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1528.67it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1468.11it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1533.01it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1520.01it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 247.86it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1463.58it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1403.58it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 667.92it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1544.65it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1690.72it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1516.17it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1558.24it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1493.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32723 images belonging to 7 classes.\n",
      "Found 5071 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 21:42:38.850769: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-10 21:42:39.096068: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3453 - accuracy: 0.4620"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 21:43:16.617396: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 60s 114ms/step - loss: 1.3453 - accuracy: 0.4620 - val_loss: 1.1188 - val_accuracy: 0.5708\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 59s 115ms/step - loss: 1.0239 - accuracy: 0.6100 - val_loss: 1.0456 - val_accuracy: 0.6092\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 58s 114ms/step - loss: 0.8892 - accuracy: 0.6641 - val_loss: 0.8688 - val_accuracy: 0.6671\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 56s 110ms/step - loss: 0.7829 - accuracy: 0.7076 - val_loss: 0.7265 - val_accuracy: 0.7284\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 56s 110ms/step - loss: 0.7051 - accuracy: 0.7364 - val_loss: 0.7875 - val_accuracy: 0.6932\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 56s 110ms/step - loss: 0.6402 - accuracy: 0.7609 - val_loss: 0.7877 - val_accuracy: 0.7095\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.5864 - accuracy: 0.7814 - val_loss: 0.6996 - val_accuracy: 0.7441\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.5241 - accuracy: 0.8044 - val_loss: 0.6777 - val_accuracy: 0.7443\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.4799 - accuracy: 0.8221 - val_loss: 0.6868 - val_accuracy: 0.7589\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.4440 - accuracy: 0.8335 - val_loss: 0.6371 - val_accuracy: 0.7771\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 56s 110ms/step - loss: 0.4054 - accuracy: 0.8486 - val_loss: 0.7601 - val_accuracy: 0.7478\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.3798 - accuracy: 0.8583 - val_loss: 0.6692 - val_accuracy: 0.7809\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 56s 110ms/step - loss: 0.3536 - accuracy: 0.8693 - val_loss: 0.6468 - val_accuracy: 0.7856\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 56s 110ms/step - loss: 0.3327 - accuracy: 0.8788 - val_loss: 0.5834 - val_accuracy: 0.8097\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 56s 110ms/step - loss: 0.3085 - accuracy: 0.8861 - val_loss: 0.6263 - val_accuracy: 0.8099\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.2900 - accuracy: 0.8916 - val_loss: 0.6732 - val_accuracy: 0.7886\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.2697 - accuracy: 0.9000 - val_loss: 0.6198 - val_accuracy: 0.8153\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.2643 - accuracy: 0.9037 - val_loss: 0.6158 - val_accuracy: 0.8210\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.2425 - accuracy: 0.9111 - val_loss: 0.7248 - val_accuracy: 0.7872\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 56s 110ms/step - loss: 0.2306 - accuracy: 0.9148 - val_loss: 0.6407 - val_accuracy: 0.8218\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.2157 - accuracy: 0.9209 - val_loss: 0.6252 - val_accuracy: 0.8364\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.2143 - accuracy: 0.9221 - val_loss: 0.7549 - val_accuracy: 0.7979\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 57s 112ms/step - loss: 0.1973 - accuracy: 0.9268 - val_loss: 0.6612 - val_accuracy: 0.8333\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.1921 - accuracy: 0.9285 - val_loss: 0.6770 - val_accuracy: 0.8311\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.1834 - accuracy: 0.9319 - val_loss: 0.7072 - val_accuracy: 0.8232\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.1807 - accuracy: 0.9322 - val_loss: 0.7366 - val_accuracy: 0.8202\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.1677 - accuracy: 0.9393 - val_loss: 0.7156 - val_accuracy: 0.8370\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.1659 - accuracy: 0.9420 - val_loss: 0.7878 - val_accuracy: 0.8141\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.1607 - accuracy: 0.9412 - val_loss: 0.7291 - val_accuracy: 0.8335\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.1463 - accuracy: 0.9470 - val_loss: 0.7508 - val_accuracy: 0.8311\n",
      "CNN Model 1: Epochs=30, Training accuracy=0.94697, Validation accuracy=0.83703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 199.80it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1275.14it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1516.90it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1441.28it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1453.82it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 215.59it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1625.27it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1592.18it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1515.45it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 210.50it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1637.24it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1455.47it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 215.84it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1552.45it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1623.39it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1494.27it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1401.89it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1482.95it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 249.60it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1303.04it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1464.87it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 576.67it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1267.97it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1592.99it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1424.01it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:00<00:00, 1602.86it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1574.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32734 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 22:11:39.992699: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3245 - accuracy: 0.4770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 22:12:15.586139: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 49s 94ms/step - loss: 1.3245 - accuracy: 0.4770 - val_loss: 1.2005 - val_accuracy: 0.5550\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 1.0303 - accuracy: 0.6074 - val_loss: 1.1060 - val_accuracy: 0.5754\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.8896 - accuracy: 0.6613 - val_loss: 0.9403 - val_accuracy: 0.6338\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.7824 - accuracy: 0.7086 - val_loss: 1.0338 - val_accuracy: 0.6111\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.7091 - accuracy: 0.7355 - val_loss: 0.8367 - val_accuracy: 0.6817\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.6400 - accuracy: 0.7608 - val_loss: 0.8212 - val_accuracy: 0.6933\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.5861 - accuracy: 0.7822 - val_loss: 0.8410 - val_accuracy: 0.7021\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.5338 - accuracy: 0.8002 - val_loss: 0.8586 - val_accuracy: 0.6878\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.4903 - accuracy: 0.8166 - val_loss: 0.8857 - val_accuracy: 0.7011\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 48s 93ms/step - loss: 0.4506 - accuracy: 0.8329 - val_loss: 0.8366 - val_accuracy: 0.7154\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.4191 - accuracy: 0.8475 - val_loss: 0.8673 - val_accuracy: 0.7126\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.3890 - accuracy: 0.8561 - val_loss: 0.9181 - val_accuracy: 0.6957\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.3661 - accuracy: 0.8660 - val_loss: 1.0152 - val_accuracy: 0.6722\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.3376 - accuracy: 0.8736 - val_loss: 0.9264 - val_accuracy: 0.7293\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 48s 95ms/step - loss: 0.3131 - accuracy: 0.8833 - val_loss: 0.9352 - val_accuracy: 0.7204\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.3034 - accuracy: 0.8876 - val_loss: 0.9813 - val_accuracy: 0.7259\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.2817 - accuracy: 0.8969 - val_loss: 0.9325 - val_accuracy: 0.7330\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.2588 - accuracy: 0.9065 - val_loss: 0.9800 - val_accuracy: 0.7289\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.2514 - accuracy: 0.9083 - val_loss: 0.9238 - val_accuracy: 0.7422\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.2377 - accuracy: 0.9122 - val_loss: 0.9832 - val_accuracy: 0.7435\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.2328 - accuracy: 0.9141 - val_loss: 1.1434 - val_accuracy: 0.7075\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.2164 - accuracy: 0.9218 - val_loss: 1.2294 - val_accuracy: 0.6970\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.2052 - accuracy: 0.9247 - val_loss: 1.0455 - val_accuracy: 0.7418\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.2011 - accuracy: 0.9260 - val_loss: 1.1221 - val_accuracy: 0.7147\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.1851 - accuracy: 0.9309 - val_loss: 1.3160 - val_accuracy: 0.6950\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.1910 - accuracy: 0.9293 - val_loss: 1.1872 - val_accuracy: 0.7279\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.1797 - accuracy: 0.9348 - val_loss: 1.0558 - val_accuracy: 0.7435\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.1661 - accuracy: 0.9401 - val_loss: 1.0160 - val_accuracy: 0.7558\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 49s 97ms/step - loss: 0.1537 - accuracy: 0.9435 - val_loss: 1.3034 - val_accuracy: 0.7150\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.1537 - accuracy: 0.9449 - val_loss: 1.1921 - val_accuracy: 0.7221\n",
      "CNN Model 2: Epochs=30, Training accuracy=0.94493, Validation accuracy=0.75577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 199.67it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1454.60it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1537.01it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1341.28it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1454.05it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 213.22it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1370.39it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1466.92it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1363.07it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 207.17it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:01<00:00, 1509.45it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1499.95it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 215.84it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1430.40it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1625.93it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1470.43it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1505.99it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1489.81it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 251.73it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1385.54it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1472.85it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 618.26it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1694.53it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1683.58it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1536.76it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1551.82it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1419.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32736 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 22:36:33.852308: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3405 - accuracy: 0.4667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 22:37:09.223804: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 49s 94ms/step - loss: 1.3405 - accuracy: 0.4667 - val_loss: 1.2980 - val_accuracy: 0.5333\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 1.0425 - accuracy: 0.6001 - val_loss: 1.0964 - val_accuracy: 0.5988\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 48s 95ms/step - loss: 0.8997 - accuracy: 0.6589 - val_loss: 0.9158 - val_accuracy: 0.6664\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 48s 95ms/step - loss: 0.8166 - accuracy: 0.6926 - val_loss: 0.9921 - val_accuracy: 0.6518\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.7244 - accuracy: 0.7297 - val_loss: 0.8154 - val_accuracy: 0.6834\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6603 - accuracy: 0.7532 - val_loss: 0.9553 - val_accuracy: 0.6596\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6256 - accuracy: 0.7659 - val_loss: 0.8233 - val_accuracy: 0.7011\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5604 - accuracy: 0.7934 - val_loss: 0.8139 - val_accuracy: 0.7218\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.5099 - accuracy: 0.8103 - val_loss: 0.8416 - val_accuracy: 0.6963\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.4780 - accuracy: 0.8235 - val_loss: 0.8070 - val_accuracy: 0.7198\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.4356 - accuracy: 0.8396 - val_loss: 0.8632 - val_accuracy: 0.7123\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.4061 - accuracy: 0.8492 - val_loss: 0.8933 - val_accuracy: 0.7035\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.3880 - accuracy: 0.8554 - val_loss: 0.9068 - val_accuracy: 0.7075\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.3528 - accuracy: 0.8678 - val_loss: 0.9790 - val_accuracy: 0.7021\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.3431 - accuracy: 0.8739 - val_loss: 0.8625 - val_accuracy: 0.7408\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.3027 - accuracy: 0.8893 - val_loss: 0.9278 - val_accuracy: 0.7442\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.3063 - accuracy: 0.8860 - val_loss: 0.8959 - val_accuracy: 0.7327\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.2765 - accuracy: 0.8986 - val_loss: 1.0304 - val_accuracy: 0.7289\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.2674 - accuracy: 0.9019 - val_loss: 0.9470 - val_accuracy: 0.7276\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.2453 - accuracy: 0.9094 - val_loss: 0.8958 - val_accuracy: 0.7425\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.2340 - accuracy: 0.9149 - val_loss: 1.0163 - val_accuracy: 0.7418\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.2201 - accuracy: 0.9201 - val_loss: 0.9848 - val_accuracy: 0.7395\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.2216 - accuracy: 0.9190 - val_loss: 0.9895 - val_accuracy: 0.7561\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.2095 - accuracy: 0.9245 - val_loss: 1.1060 - val_accuracy: 0.7204\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.1898 - accuracy: 0.9308 - val_loss: 1.0557 - val_accuracy: 0.7449\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.1942 - accuracy: 0.9279 - val_loss: 1.2020 - val_accuracy: 0.7103\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.1804 - accuracy: 0.9325 - val_loss: 1.0458 - val_accuracy: 0.7395\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.1676 - accuracy: 0.9387 - val_loss: 1.0478 - val_accuracy: 0.7554\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.1677 - accuracy: 0.9396 - val_loss: 1.3091 - val_accuracy: 0.7143\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.1625 - accuracy: 0.9408 - val_loss: 1.1852 - val_accuracy: 0.7368\n",
      "CNN Model 3: Epochs=30, Training accuracy=0.94077, Validation accuracy=0.75611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 199.03it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1534.36it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1295.12it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1259.42it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1383.67it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 205.15it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1595.07it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1631.81it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1534.20it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 208.78it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1618.49it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1504.98it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 219.30it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1629.61it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1662.57it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1475.08it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1477.74it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1495.11it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 249.03it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1338.84it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1316.46it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 719.55it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1715.06it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1743.74it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1561.48it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1575.58it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1454.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32743 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 23:02:15.032227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3397 - accuracy: 0.4743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 23:02:54.353035: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 52s 102ms/step - loss: 1.3397 - accuracy: 0.4743 - val_loss: 1.0725 - val_accuracy: 0.5904\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 1.0241 - accuracy: 0.6081 - val_loss: 1.0353 - val_accuracy: 0.6274\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.8840 - accuracy: 0.6630 - val_loss: 0.9943 - val_accuracy: 0.6294\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.7813 - accuracy: 0.7017 - val_loss: 0.8347 - val_accuracy: 0.6899\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.6885 - accuracy: 0.7397 - val_loss: 0.9308 - val_accuracy: 0.6532\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.6334 - accuracy: 0.7605 - val_loss: 0.8925 - val_accuracy: 0.6749\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5729 - accuracy: 0.7854 - val_loss: 0.8527 - val_accuracy: 0.6974\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.5103 - accuracy: 0.8096 - val_loss: 0.8697 - val_accuracy: 0.7052\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.4828 - accuracy: 0.8199 - val_loss: 0.8607 - val_accuracy: 0.7035\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.4441 - accuracy: 0.8359 - val_loss: 0.9375 - val_accuracy: 0.6923\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.4098 - accuracy: 0.8480 - val_loss: 0.8519 - val_accuracy: 0.7188\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3815 - accuracy: 0.8579 - val_loss: 0.9523 - val_accuracy: 0.7062\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3486 - accuracy: 0.8709 - val_loss: 0.9500 - val_accuracy: 0.7242\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3338 - accuracy: 0.8779 - val_loss: 1.0656 - val_accuracy: 0.6892\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 55s 107ms/step - loss: 0.3132 - accuracy: 0.8841 - val_loss: 0.9887 - val_accuracy: 0.7262\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.2890 - accuracy: 0.8943 - val_loss: 1.1001 - val_accuracy: 0.7018\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 57s 111ms/step - loss: 0.2754 - accuracy: 0.8987 - val_loss: 0.9586 - val_accuracy: 0.7361\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 59s 115ms/step - loss: 0.2632 - accuracy: 0.9035 - val_loss: 1.1096 - val_accuracy: 0.6980\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 55s 107ms/step - loss: 0.2425 - accuracy: 0.9102 - val_loss: 1.1871 - val_accuracy: 0.7137\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 55s 107ms/step - loss: 0.2334 - accuracy: 0.9155 - val_loss: 1.1247 - val_accuracy: 0.7092\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 55s 107ms/step - loss: 0.2235 - accuracy: 0.9169 - val_loss: 1.0549 - val_accuracy: 0.7391\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2131 - accuracy: 0.9216 - val_loss: 1.0512 - val_accuracy: 0.7524\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2015 - accuracy: 0.9257 - val_loss: 1.0997 - val_accuracy: 0.7194\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2023 - accuracy: 0.9256 - val_loss: 1.1640 - val_accuracy: 0.7429\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.1824 - accuracy: 0.9326 - val_loss: 1.1551 - val_accuracy: 0.7395\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.1753 - accuracy: 0.9364 - val_loss: 1.2463 - val_accuracy: 0.7245\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.1817 - accuracy: 0.9348 - val_loss: 1.2361 - val_accuracy: 0.7289\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.1700 - accuracy: 0.9374 - val_loss: 1.2815 - val_accuracy: 0.7296\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.1590 - accuracy: 0.9439 - val_loss: 1.2944 - val_accuracy: 0.7381\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.1565 - accuracy: 0.9440 - val_loss: 1.2876 - val_accuracy: 0.7259\n",
      "CNN Model 4: Epochs=30, Training accuracy=0.94397, Validation accuracy=0.75238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 201.14it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1479.92it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1574.00it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1379.60it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1313.70it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 211.41it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1605.20it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1606.88it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1336.87it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 207.24it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:01<00:00, 1528.94it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1506.39it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 220.28it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1649.40it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1651.76it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1480.57it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1528.94it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1475.77it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 248.33it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1407.33it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1523.18it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 714.49it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1715.27it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1715.50it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1549.27it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1559.09it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1555.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32743 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 23:29:22.535096: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3474 - accuracy: 0.4714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 23:30:02.683849: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 53s 103ms/step - loss: 1.3474 - accuracy: 0.4714 - val_loss: 1.3171 - val_accuracy: 0.5272\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 1.0552 - accuracy: 0.5938 - val_loss: 0.9528 - val_accuracy: 0.6318\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.9042 - accuracy: 0.6558 - val_loss: 0.8074 - val_accuracy: 0.6987\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.7979 - accuracy: 0.6970 - val_loss: 0.8309 - val_accuracy: 0.6889\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 55s 108ms/step - loss: 0.7111 - accuracy: 0.7301 - val_loss: 0.9037 - val_accuracy: 0.6644\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.6470 - accuracy: 0.7579 - val_loss: 0.8045 - val_accuracy: 0.7007\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.5885 - accuracy: 0.7819 - val_loss: 0.7712 - val_accuracy: 0.7174\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 53s 105ms/step - loss: 0.5373 - accuracy: 0.8015 - val_loss: 0.7624 - val_accuracy: 0.7035\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.4843 - accuracy: 0.8203 - val_loss: 0.8351 - val_accuracy: 0.7079\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4459 - accuracy: 0.8345 - val_loss: 0.7659 - val_accuracy: 0.7323\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4139 - accuracy: 0.8494 - val_loss: 0.7990 - val_accuracy: 0.7137\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3856 - accuracy: 0.8576 - val_loss: 0.8679 - val_accuracy: 0.7167\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3609 - accuracy: 0.8672 - val_loss: 1.0275 - val_accuracy: 0.6454\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3386 - accuracy: 0.8762 - val_loss: 0.8630 - val_accuracy: 0.7171\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 56s 109ms/step - loss: 0.3091 - accuracy: 0.8864 - val_loss: 0.9882 - val_accuracy: 0.6950\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 55s 107ms/step - loss: 0.2876 - accuracy: 0.8951 - val_loss: 0.8806 - val_accuracy: 0.7327\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 59s 114ms/step - loss: 0.2814 - accuracy: 0.8985 - val_loss: 0.8955 - val_accuracy: 0.7255\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 55s 108ms/step - loss: 0.2610 - accuracy: 0.9030 - val_loss: 0.9188 - val_accuracy: 0.7293\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2511 - accuracy: 0.9075 - val_loss: 1.0021 - val_accuracy: 0.7069\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2375 - accuracy: 0.9135 - val_loss: 0.9244 - val_accuracy: 0.7300\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2213 - accuracy: 0.9195 - val_loss: 1.0050 - val_accuracy: 0.7235\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2187 - accuracy: 0.9191 - val_loss: 0.9795 - val_accuracy: 0.7266\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.1979 - accuracy: 0.9265 - val_loss: 1.0313 - val_accuracy: 0.7327\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2057 - accuracy: 0.9244 - val_loss: 0.9628 - val_accuracy: 0.7429\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.1837 - accuracy: 0.9326 - val_loss: 1.0214 - val_accuracy: 0.7340\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.1742 - accuracy: 0.9375 - val_loss: 1.0039 - val_accuracy: 0.7490\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.1761 - accuracy: 0.9357 - val_loss: 1.0326 - val_accuracy: 0.7425\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.1603 - accuracy: 0.9419 - val_loss: 1.1448 - val_accuracy: 0.7249\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.1713 - accuracy: 0.9391 - val_loss: 1.3390 - val_accuracy: 0.7038\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.1536 - accuracy: 0.9460 - val_loss: 1.1733 - val_accuracy: 0.7262\n",
      "CNN Model 5: Epochs=30, Training accuracy=0.94599, Validation accuracy=0.74898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 205.26it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1599.43it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1372.56it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1457.31it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1493.29it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 216.64it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1633.11it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1555.71it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1532.73it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 210.64it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1624.23it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1494.53it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 223.86it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1632.50it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1633.96it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1506.69it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1464.48it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1453.50it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 243.13it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1335.67it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1533.29it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 655.06it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1730.10it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1752.53it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1574.86it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1570.96it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1584.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32740 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 23:56:39.498624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3388 - accuracy: 0.4633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-10 23:57:20.238518: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 54s 105ms/step - loss: 1.3388 - accuracy: 0.4633 - val_loss: 1.1359 - val_accuracy: 0.5700\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 1.0444 - accuracy: 0.5968 - val_loss: 0.8733 - val_accuracy: 0.6508\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.8953 - accuracy: 0.6607 - val_loss: 0.8882 - val_accuracy: 0.6556\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.7954 - accuracy: 0.6994 - val_loss: 0.9105 - val_accuracy: 0.6454\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.7155 - accuracy: 0.7296 - val_loss: 0.9580 - val_accuracy: 0.6260\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.6578 - accuracy: 0.7540 - val_loss: 0.9229 - val_accuracy: 0.6406\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.6110 - accuracy: 0.7735 - val_loss: 0.9813 - val_accuracy: 0.6308\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5752 - accuracy: 0.7853 - val_loss: 0.9005 - val_accuracy: 0.6756\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.5176 - accuracy: 0.8081 - val_loss: 0.7591 - val_accuracy: 0.7238\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.4951 - accuracy: 0.8145 - val_loss: 0.9281 - val_accuracy: 0.6729\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.4492 - accuracy: 0.8305 - val_loss: 0.9397 - val_accuracy: 0.6875\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4275 - accuracy: 0.8406 - val_loss: 0.7919 - val_accuracy: 0.7238\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.3889 - accuracy: 0.8577 - val_loss: 1.0497 - val_accuracy: 0.6576\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.3773 - accuracy: 0.8597 - val_loss: 0.8441 - val_accuracy: 0.7099\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3497 - accuracy: 0.8687 - val_loss: 0.9872 - val_accuracy: 0.6824\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3315 - accuracy: 0.8765 - val_loss: 1.1511 - val_accuracy: 0.6471\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3067 - accuracy: 0.8859 - val_loss: 0.9884 - val_accuracy: 0.6957\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2834 - accuracy: 0.8956 - val_loss: 0.9305 - val_accuracy: 0.7317\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2870 - accuracy: 0.8924 - val_loss: 1.0191 - val_accuracy: 0.7310\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2578 - accuracy: 0.9049 - val_loss: 0.9402 - val_accuracy: 0.7334\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.2476 - accuracy: 0.9098 - val_loss: 0.9853 - val_accuracy: 0.7181\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2377 - accuracy: 0.9115 - val_loss: 1.0038 - val_accuracy: 0.7208\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 53s 105ms/step - loss: 0.2273 - accuracy: 0.9181 - val_loss: 1.0355 - val_accuracy: 0.7184\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.2119 - accuracy: 0.9214 - val_loss: 1.0316 - val_accuracy: 0.7252\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 53s 105ms/step - loss: 0.2026 - accuracy: 0.9255 - val_loss: 1.0208 - val_accuracy: 0.7405\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2047 - accuracy: 0.9248 - val_loss: 1.1214 - val_accuracy: 0.7232\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.1916 - accuracy: 0.9285 - val_loss: 1.2981 - val_accuracy: 0.6997\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.1774 - accuracy: 0.9350 - val_loss: 1.2666 - val_accuracy: 0.7130\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.1694 - accuracy: 0.9377 - val_loss: 1.2427 - val_accuracy: 0.7021\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.1781 - accuracy: 0.9341 - val_loss: 1.1644 - val_accuracy: 0.7378\n",
      "CNN Model 6: Epochs=30, Training accuracy=0.93769, Validation accuracy=0.74049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 201.22it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1610.96it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1585.57it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1466.52it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1486.52it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 208.20it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1287.60it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1645.14it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1474.15it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 203.85it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1632.34it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1509.57it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 211.98it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1631.17it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1643.37it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1485.36it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1532.35it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1481.43it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 244.11it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1512.49it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1480.80it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 598.39it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1684.59it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1699.35it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1530.53it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1517.96it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1541.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32740 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 00:23:25.808861: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3421 - accuracy: 0.4719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 00:24:06.995698: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 54s 105ms/step - loss: 1.3421 - accuracy: 0.4719 - val_loss: 0.9988 - val_accuracy: 0.6213\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 1.0332 - accuracy: 0.6027 - val_loss: 0.8192 - val_accuracy: 0.6810\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.8910 - accuracy: 0.6633 - val_loss: 0.9045 - val_accuracy: 0.6423\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.7969 - accuracy: 0.6995 - val_loss: 0.8159 - val_accuracy: 0.6933\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.7135 - accuracy: 0.7330 - val_loss: 0.8853 - val_accuracy: 0.6613\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.6499 - accuracy: 0.7578 - val_loss: 0.8032 - val_accuracy: 0.7035\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.6023 - accuracy: 0.7763 - val_loss: 0.7617 - val_accuracy: 0.7283\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.5496 - accuracy: 0.7956 - val_loss: 0.8411 - val_accuracy: 0.7031\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 55s 107ms/step - loss: 0.5048 - accuracy: 0.8110 - val_loss: 0.7626 - val_accuracy: 0.7306\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.4659 - accuracy: 0.8260 - val_loss: 0.8111 - val_accuracy: 0.7296\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.4388 - accuracy: 0.8365 - val_loss: 0.8011 - val_accuracy: 0.7259\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.3981 - accuracy: 0.8531 - val_loss: 0.8320 - val_accuracy: 0.7245\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.3780 - accuracy: 0.8602 - val_loss: 0.8097 - val_accuracy: 0.7255\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.3582 - accuracy: 0.8660 - val_loss: 0.9592 - val_accuracy: 0.6977\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.3275 - accuracy: 0.8801 - val_loss: 0.9165 - val_accuracy: 0.7296\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.3103 - accuracy: 0.8843 - val_loss: 0.8923 - val_accuracy: 0.7150\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.2949 - accuracy: 0.8900 - val_loss: 1.0883 - val_accuracy: 0.6698\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.2796 - accuracy: 0.8965 - val_loss: 0.9911 - val_accuracy: 0.6963\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.2616 - accuracy: 0.9030 - val_loss: 0.8688 - val_accuracy: 0.7463\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.2401 - accuracy: 0.9117 - val_loss: 1.0247 - val_accuracy: 0.7113\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.2246 - accuracy: 0.9159 - val_loss: 1.0115 - val_accuracy: 0.7357\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.2202 - accuracy: 0.9174 - val_loss: 1.0058 - val_accuracy: 0.7435\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.2120 - accuracy: 0.9218 - val_loss: 1.0466 - val_accuracy: 0.7249\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.1998 - accuracy: 0.9267 - val_loss: 1.0093 - val_accuracy: 0.7588\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.1967 - accuracy: 0.9279 - val_loss: 0.9615 - val_accuracy: 0.7626\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.1884 - accuracy: 0.9305 - val_loss: 1.0329 - val_accuracy: 0.7442\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.1733 - accuracy: 0.9353 - val_loss: 1.0957 - val_accuracy: 0.7317\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.1888 - accuracy: 0.9324 - val_loss: 1.0863 - val_accuracy: 0.7531\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.1597 - accuracy: 0.9413 - val_loss: 1.1871 - val_accuracy: 0.7368\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.1512 - accuracy: 0.9457 - val_loss: 1.1425 - val_accuracy: 0.7592\n",
      "CNN Model 7: Epochs=30, Training accuracy=0.94568, Validation accuracy=0.76257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 195.66it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1525.16it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1519.24it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1306.25it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1439.26it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 198.40it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1608.52it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1634.78it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1449.22it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 211.62it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1575.36it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1404.35it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 221.01it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1633.55it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1651.41it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1474.54it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1500.98it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1482.47it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 246.61it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1506.18it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1530.86it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 712.24it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1728.52it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1742.19it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1332.62it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1488.41it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1442.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32744 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 00:49:52.232659: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3559 - accuracy: 0.4563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 00:50:31.128428: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 52s 101ms/step - loss: 1.3559 - accuracy: 0.4563 - val_loss: 0.9598 - val_accuracy: 0.6352\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 1.0486 - accuracy: 0.5974 - val_loss: 1.0581 - val_accuracy: 0.5992\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.9107 - accuracy: 0.6544 - val_loss: 1.0349 - val_accuracy: 0.6209\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.8160 - accuracy: 0.6955 - val_loss: 1.0352 - val_accuracy: 0.6151\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.7377 - accuracy: 0.7250 - val_loss: 0.9599 - val_accuracy: 0.6410\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.6648 - accuracy: 0.7514 - val_loss: 0.7841 - val_accuracy: 0.7011\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.6118 - accuracy: 0.7732 - val_loss: 1.0210 - val_accuracy: 0.6372\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.5659 - accuracy: 0.7886 - val_loss: 0.9497 - val_accuracy: 0.6651\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.5082 - accuracy: 0.8100 - val_loss: 0.9720 - val_accuracy: 0.6722\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.4769 - accuracy: 0.8241 - val_loss: 0.9485 - val_accuracy: 0.6793\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4366 - accuracy: 0.8399 - val_loss: 0.9181 - val_accuracy: 0.7072\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.4037 - accuracy: 0.8519 - val_loss: 1.0119 - val_accuracy: 0.6793\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.3838 - accuracy: 0.8578 - val_loss: 0.9755 - val_accuracy: 0.7106\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.3542 - accuracy: 0.8714 - val_loss: 0.9680 - val_accuracy: 0.7014\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3320 - accuracy: 0.8764 - val_loss: 1.0467 - val_accuracy: 0.6906\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.3188 - accuracy: 0.8816 - val_loss: 1.0213 - val_accuracy: 0.6943\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2933 - accuracy: 0.8931 - val_loss: 0.9209 - val_accuracy: 0.7381\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2793 - accuracy: 0.8976 - val_loss: 1.0709 - val_accuracy: 0.7004\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2718 - accuracy: 0.9000 - val_loss: 1.0151 - val_accuracy: 0.7018\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.2527 - accuracy: 0.9079 - val_loss: 1.0579 - val_accuracy: 0.7313\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.2547 - accuracy: 0.9080 - val_loss: 1.0193 - val_accuracy: 0.7344\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.2239 - accuracy: 0.9190 - val_loss: 1.1130 - val_accuracy: 0.7262\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2110 - accuracy: 0.9214 - val_loss: 1.1522 - val_accuracy: 0.7215\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.2136 - accuracy: 0.9211 - val_loss: 1.3297 - val_accuracy: 0.6980\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.2005 - accuracy: 0.9270 - val_loss: 1.2283 - val_accuracy: 0.7086\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.2062 - accuracy: 0.9265 - val_loss: 1.1286 - val_accuracy: 0.7245\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.1903 - accuracy: 0.9312 - val_loss: 1.2839 - val_accuracy: 0.6953\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.1769 - accuracy: 0.9343 - val_loss: 1.2923 - val_accuracy: 0.7058\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.1669 - accuracy: 0.9394 - val_loss: 1.4307 - val_accuracy: 0.6780\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.1794 - accuracy: 0.9353 - val_loss: 1.3090 - val_accuracy: 0.7347\n",
      "CNN Model 8: Epochs=30, Training accuracy=0.93938, Validation accuracy=0.73811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 165.03it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1256.18it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1545.65it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1391.26it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1453.21it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 211.58it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1565.10it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1653.97it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1507.83it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 206.52it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1543.14it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1494.11it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 185.80it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1604.86it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1669.51it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1525.43it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1437.59it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1508.69it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 239.03it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1310.89it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1444.66it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 620.20it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1593.90it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1584.84it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1516.38it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1437.32it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1541.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32742 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 01:16:10.540723: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3560 - accuracy: 0.4596"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 01:16:50.480477: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 53s 103ms/step - loss: 1.3560 - accuracy: 0.4596 - val_loss: 1.0300 - val_accuracy: 0.6114\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 1.0467 - accuracy: 0.5945 - val_loss: 1.0672 - val_accuracy: 0.5982\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.9049 - accuracy: 0.6551 - val_loss: 1.0128 - val_accuracy: 0.6274\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.8153 - accuracy: 0.6915 - val_loss: 0.8579 - val_accuracy: 0.6709\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.7431 - accuracy: 0.7188 - val_loss: 0.8110 - val_accuracy: 0.6980\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.6706 - accuracy: 0.7484 - val_loss: 0.8057 - val_accuracy: 0.7055\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.6066 - accuracy: 0.7756 - val_loss: 0.9261 - val_accuracy: 0.6596\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.5717 - accuracy: 0.7882 - val_loss: 0.9061 - val_accuracy: 0.6787\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.5166 - accuracy: 0.8057 - val_loss: 0.8892 - val_accuracy: 0.6997\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.4835 - accuracy: 0.8191 - val_loss: 0.8372 - val_accuracy: 0.7072\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.4566 - accuracy: 0.8305 - val_loss: 0.9533 - val_accuracy: 0.6790\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4121 - accuracy: 0.8460 - val_loss: 0.8906 - val_accuracy: 0.7181\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.3926 - accuracy: 0.8539 - val_loss: 0.9221 - val_accuracy: 0.7130\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.3623 - accuracy: 0.8654 - val_loss: 0.8695 - val_accuracy: 0.7249\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.3414 - accuracy: 0.8713 - val_loss: 0.9184 - val_accuracy: 0.7160\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.3170 - accuracy: 0.8825 - val_loss: 0.8608 - val_accuracy: 0.7306\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.2969 - accuracy: 0.8925 - val_loss: 0.9351 - val_accuracy: 0.7157\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.2844 - accuracy: 0.8955 - val_loss: 0.9359 - val_accuracy: 0.7334\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.2648 - accuracy: 0.9033 - val_loss: 1.0858 - val_accuracy: 0.7055\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.2601 - accuracy: 0.9028 - val_loss: 0.9970 - val_accuracy: 0.7191\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.2449 - accuracy: 0.9099 - val_loss: 0.9496 - val_accuracy: 0.7405\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.2200 - accuracy: 0.9188 - val_loss: 1.0741 - val_accuracy: 0.7167\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.2235 - accuracy: 0.9181 - val_loss: 1.0487 - val_accuracy: 0.7313\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.2084 - accuracy: 0.9228 - val_loss: 1.0046 - val_accuracy: 0.7446\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.2031 - accuracy: 0.9262 - val_loss: 1.1384 - val_accuracy: 0.7201\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.1903 - accuracy: 0.9298 - val_loss: 1.1129 - val_accuracy: 0.7238\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.1710 - accuracy: 0.9383 - val_loss: 1.1634 - val_accuracy: 0.7262\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.1884 - accuracy: 0.9319 - val_loss: 1.2912 - val_accuracy: 0.7123\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.1766 - accuracy: 0.9355 - val_loss: 1.1724 - val_accuracy: 0.7313\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.1732 - accuracy: 0.9382 - val_loss: 1.0982 - val_accuracy: 0.7446\n",
      "CNN Model 9: Epochs=30, Training accuracy=0.93834, Validation accuracy=0.74457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 198.95it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1597.79it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1444.38it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1431.21it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1471.85it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 210.12it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1635.29it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1480.82it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1519.13it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 212.34it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1621.91it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1328.47it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 204.88it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1639.90it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1620.53it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1491.92it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1521.55it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1381.92it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 247.87it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1298.75it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1457.21it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 628.24it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1654.16it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1679.36it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1538.02it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:00<00:00, 1598.58it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1522.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32736 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 01:42:09.787005: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3378 - accuracy: 0.4708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 01:42:47.745736: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 51s 99ms/step - loss: 1.3378 - accuracy: 0.4708 - val_loss: 0.9874 - val_accuracy: 0.6253\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 1.0442 - accuracy: 0.6016 - val_loss: 0.9282 - val_accuracy: 0.6430\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.9101 - accuracy: 0.6576 - val_loss: 0.9005 - val_accuracy: 0.6491\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.8195 - accuracy: 0.6928 - val_loss: 0.8014 - val_accuracy: 0.7086\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.7357 - accuracy: 0.7227 - val_loss: 0.8159 - val_accuracy: 0.6967\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.6671 - accuracy: 0.7517 - val_loss: 0.8213 - val_accuracy: 0.7007\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.6039 - accuracy: 0.7770 - val_loss: 0.9377 - val_accuracy: 0.6634\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 49s 97ms/step - loss: 0.5475 - accuracy: 0.7987 - val_loss: 0.8145 - val_accuracy: 0.7116\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.5012 - accuracy: 0.8172 - val_loss: 0.9646 - val_accuracy: 0.6644\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.4613 - accuracy: 0.8311 - val_loss: 0.7879 - val_accuracy: 0.7255\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4252 - accuracy: 0.8443 - val_loss: 0.9535 - val_accuracy: 0.6753\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.3961 - accuracy: 0.8539 - val_loss: 0.9421 - val_accuracy: 0.6940\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.3612 - accuracy: 0.8665 - val_loss: 1.0056 - val_accuracy: 0.6743\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.3457 - accuracy: 0.8750 - val_loss: 1.0360 - val_accuracy: 0.6814\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.3089 - accuracy: 0.8878 - val_loss: 0.9434 - val_accuracy: 0.7075\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.2971 - accuracy: 0.8923 - val_loss: 0.9557 - val_accuracy: 0.7198\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.2849 - accuracy: 0.8957 - val_loss: 0.9570 - val_accuracy: 0.7296\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 49s 97ms/step - loss: 0.2517 - accuracy: 0.9073 - val_loss: 1.0153 - val_accuracy: 0.7330\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.2497 - accuracy: 0.9084 - val_loss: 1.0656 - val_accuracy: 0.7038\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.2322 - accuracy: 0.9148 - val_loss: 1.0260 - val_accuracy: 0.7279\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.2230 - accuracy: 0.9171 - val_loss: 0.9339 - val_accuracy: 0.7432\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 49s 97ms/step - loss: 0.2130 - accuracy: 0.9209 - val_loss: 1.0730 - val_accuracy: 0.7463\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.1971 - accuracy: 0.9293 - val_loss: 1.1576 - val_accuracy: 0.7255\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.1944 - accuracy: 0.9286 - val_loss: 1.1432 - val_accuracy: 0.7452\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 50s 99ms/step - loss: 0.1826 - accuracy: 0.9341 - val_loss: 1.2025 - val_accuracy: 0.7208\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.1639 - accuracy: 0.9413 - val_loss: 1.1019 - val_accuracy: 0.7520\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.1753 - accuracy: 0.9369 - val_loss: 1.2006 - val_accuracy: 0.7171\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.1662 - accuracy: 0.9399 - val_loss: 1.3733 - val_accuracy: 0.7014\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.1572 - accuracy: 0.9418 - val_loss: 1.2332 - val_accuracy: 0.7357\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.1480 - accuracy: 0.9469 - val_loss: 1.2532 - val_accuracy: 0.7354\n",
      "CNN Model 10: Epochs=30, Training accuracy=0.94690, Validation accuracy=0.75204\n"
     ]
    }
   ],
   "source": [
    "# Augment, Split and Train\n",
    "classes = ['akiec','bcc','bkl','df','nv','mel','vasc']\n",
    "\n",
    "TRAIN_DIR = 'Processed_Data/train'\n",
    "model_train = [0] * n\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "for j in range(n):\n",
    "    # Train test Split\n",
    "    rs = np.random.randint(100,150)*(j+1)\n",
    "    for clas in classes:\n",
    "        os.makedirs(f'augmented/{clas}')\n",
    "    for cl in classes:\n",
    "        r_images = glob(f'{TRAIN_DIR}/{cl}/*')\n",
    "        r_images_shuf = shuffling_tt(r_images,rs)\n",
    "        train = int(0.7*len(r_images))\n",
    "        r_train = r_images_shuf[0:train]\n",
    "        r_test = r_images_shuf[train:]\n",
    "        if cl == 'akiec':\n",
    "            augment_akiec(r_train)\n",
    "        elif cl == 'bcc':\n",
    "            augment_bcc(r_train)\n",
    "        elif cl == 'bkl':\n",
    "            augment_bkl(r_train)\n",
    "        elif cl == 'df':\n",
    "            augment_df(r_train)\n",
    "        elif cl == 'mel':\n",
    "            augment_mel(r_train)\n",
    "        elif cl == 'vasc':\n",
    "            augment_vasc(r_train)\n",
    "        else:\n",
    "            augment_nv(r_train)\n",
    "        if not os.path.isdir(f'test/{cl}'):\n",
    "            os.makedirs(f'test/{cl}')\n",
    "        for image in r_test:\n",
    "            shutil.copyfile(image, f'test/{cl}/{image.split(\"/\")[-1]}')\n",
    "    # Model Training\n",
    "\n",
    "    train_dir = 'augmented'\n",
    "    test_dir = 'test'\n",
    "    datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical') # set as training data\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    model_train[j] = ensemble[j].fit_generator(train_generator,\n",
    "                                               steps_per_epoch=train_generator.samples//batch_size,\n",
    "                                               validation_steps=validation_generator.samples//batch_size,\n",
    "                                               validation_data = validation_generator,\n",
    "                                               epochs = epochs)\n",
    "    print(\"CNN Model {0:d}: Epochs={1:d}, Training accuracy={2:.5f}, Validation accuracy={3:.5f}\".\n",
    "          format(j+1,epochs,\n",
    "                 max(model_train[j].history['accuracy']),\n",
    "                 max(model_train[j].history['val_accuracy']) ))\n",
    "    if j != 9:\n",
    "        shutil.rmtree('augmented')\n",
    "        shutil.rmtree('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c6a5a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "#Result\n",
    "results = np.zeros( (validation_generator.samples,7) ) \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61e59540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3007 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generating generator for Validation Images\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41735f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 02:19:21.194461: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 02:19:33.846620: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 02:19:46.575704: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 02:19:59.376326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 02:20:12.390119: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 02:20:25.146918: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 02:20:37.977862: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 02:20:50.810878: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 02:21:03.632151: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Predicting classes for vlaidation images\n",
    "for j in range(n):\n",
    "    results = results + ensemble[j].predict_generator(validation_generator,\n",
    "                                                      validation_generator.samples // batch_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4441235d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 6, 6, 6])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Max Voting\n",
    "results = np.argmax(results,axis = 1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c827e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[  98    0    0    0    0    1    0]\n",
      " [   0  151    0    1    1    2    0]\n",
      " [   1    3  314    0    5    6    0]\n",
      " [   0    0    0   35    0    0    0]\n",
      " [   0    1    2    0  326    5    0]\n",
      " [   1    9   21    2   14 1964    1]\n",
      " [   0    0    0    0    0    0   43]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.98      0.99      0.98        99\n",
      "         bcc       0.92      0.97      0.95       155\n",
      "         bkl       0.93      0.95      0.94       329\n",
      "          df       0.92      1.00      0.96        35\n",
      "         mel       0.94      0.98      0.96       334\n",
      "          nv       0.99      0.98      0.98      2012\n",
      "        vasc       0.98      1.00      0.99        43\n",
      "\n",
      "    accuracy                           0.97      3007\n",
      "   macro avg       0.95      0.98      0.97      3007\n",
      "weighted avg       0.98      0.97      0.97      3007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, results))\n",
    "print('Classification Report')\n",
    "target_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "print(classification_report(validation_generator.classes, results, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4bfa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63561e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6cd49fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 15:41:05.792358: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Ensemble2_model0/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble2_model1/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble2_model2/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble2_model3/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble2_model4/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble2_model5/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble2_model6/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble2_model7/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble2_model8/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble2_model9/assets\n"
     ]
    }
   ],
   "source": [
    "# Sving Model in Keras Default Format\n",
    "for k in range(n):\n",
    "    ensemble[k].save(f'Ensemble2_model{k}')\n",
    "# Saving Model in H5 Format\n",
    "for k in range(n):\n",
    "    ensemble[k].save(f'Ensemble2_model{k}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a249bb4d",
   "metadata": {},
   "source": [
    "## Loading Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Load the model\n",
    "# It can be used to reconstruct the model identically.\n",
    "# reconstructed_ensemble = [0]*n\n",
    "# for k in range(n):\n",
    "#     reconstructed_ensemble[k] = keras.models.load_model(f\"Saved Models/Ensemble2/Ensemble2_model{k}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
