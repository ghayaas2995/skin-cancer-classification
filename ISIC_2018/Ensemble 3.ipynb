{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2782da35",
   "metadata": {},
   "source": [
    "# Ensemble of Modified Base Model : Model 7\n",
    "(Dropout 40%, 1 extra CNN Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b90d05",
   "metadata": {},
   "source": [
    "## Approach\n",
    "- Create a List of Base Models\n",
    "- Take all the Preprocessed Images from each Class\n",
    "- Split Training data into Train and Validation with 0.7 traim-test ratio\n",
    "- Perform this splitting for each model in a loop with a different random state so that shuffling of images is different for each model.\n",
    "- Perform Augmentation on each class of training data splitted above \n",
    "- Train the models on augmented data validating on 30% validation data\n",
    "- Once all models in list are trained, use max voting to find predction of validation image set\n",
    "\n",
    "Before running make sure there is no augmented & test folder in the directory of notebook since it is created in this file itself. If it exists delete them. A caveat here is that if you wish to run Model_1_2_3_4.ipynb file again, you need to run Preprocessing Notebook again to form required folders.\n",
    "\n",
    "Also, if required change the path seperator to run code smoothly on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1405c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "# For missing libraries\n",
    "# pip install -U package_name --user\n",
    "from skimage import io\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import albumentations\n",
    "from albumentations import ShiftScaleRotate, HorizontalFlip, VerticalFlip, RandomBrightnessContrast\n",
    "import warnings\n",
    "import shutil\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from functools import partial\n",
    "from sklearn.utils import shuffle\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266d7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Augmentation Functions\n",
    "# Shifting, Scaling & Rotations\n",
    "def shiftscalerotate(images, save_path,\n",
    "                     augment = True,\n",
    "                     resize = [256,256],\n",
    "                     random=1.0,\n",
    "                     rotation=0,\n",
    "                     shift=0,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     always=True,\n",
    "                     call=1):\n",
    "    H, W = resize\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "\n",
    "        # Now that we have the names, we have to read the image\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if augment ==True:\n",
    "            aug = ShiftScaleRotate(p=random, rotate_limit=(-30,30), interpolation=interpolation,\n",
    "                                  always_apply=always)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "            save_images = [x, x1] # save original image and the augmented image\n",
    "        # If the augment paramter is set to False, The function only saves the original image and mask to the defined save_path\n",
    "        else:\n",
    "            save_images = [x] \n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "            if idx == 0:\n",
    "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            else:\n",
    "                aug_ext = '_ssr'*call\n",
    "                tmp_img_name = f\"{image_name}{aug_ext}.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)\n",
    "            idx +=1\n",
    "# Horizontal Flipping\n",
    "def horizontalflip(images, save_path,\n",
    "                   augment = True,\n",
    "                   resize = [256,256],\n",
    "                   random=1.0,\n",
    "                   always=True):\n",
    "    H, W = resize\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "        # Now that we have the names, we have to read the image and the masks \n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        if augment ==True:\n",
    "            aug = HorizontalFlip(always_apply=always, p=random)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "            save_images = [x, x1] # make sure only x1. If x is given in 2nd augmentation onwards, then duplicate images will be saved\n",
    "        # If the augment paramter is set to False, The function only saves the original image and mask to the defined save_path\n",
    "        else:\n",
    "            save_images = [x]\n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "            if idx == 0:\n",
    "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            else:\n",
    "                tmp_img_name = f\"{image_name}_hf.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)\n",
    "            idx +=1\n",
    "#vertical flipping\n",
    "def verticalflip(images,\n",
    "                 save_path,\n",
    "                 augment = True,\n",
    "                 resize=[256,256],\n",
    "                 random=1.0,\n",
    "                 always=True):\n",
    "    H, W = resize\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "        # Now that we have the names, we have to read the image\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        if augment ==True:\n",
    "            aug = VerticalFlip(always_apply=always, p=random)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "            save_images = [x, x1]\n",
    "        # If the augment paramter is set to False, The function only saves the original image and mask to the defined save_path\n",
    "        else:\n",
    "            save_images = [x]\n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "            if idx == 0:\n",
    "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            else:\n",
    "                tmp_img_name = f\"{image_name}_vf.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)\n",
    "            idx +=1\n",
    "def brightness_contrast(images,\n",
    "                        save_path,\n",
    "                        augment = True,\n",
    "                        resize=[256,256],\n",
    "                        random=1.0,\n",
    "                        brightness=0.2, \n",
    "                        contrast=0.2,\n",
    "                        by_max=False,\n",
    "                        always=True):\n",
    "    H, W = resize\n",
    "    for x in tqdm(images, total= len(images)):\n",
    "        # First, we have to extract the image name, image extention.\n",
    "        name = x.split(\"/\")[-1].split(\".\")\n",
    "        image_name = name[0]\n",
    "        image_extn = name[1]\n",
    "        # Now that we have the names, we have to read the image\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        if augment ==True:\n",
    "            aug = RandomBrightnessContrast(brightness_limit=brightness,\n",
    "                                           contrast_limit=contrast,\n",
    "                                           brightness_by_max=by_max,\n",
    "                                           always_apply=always,\n",
    "                                           p=random)\n",
    "            augmented = aug(image=x)\n",
    "            x1 = augmented[\"image\"]\n",
    "            save_images = [x, x1]\n",
    "        # If the augment paramter is set to False, The function only saves the original image and mask to the defined save_path\n",
    "        else:\n",
    "            save_images = [x]\n",
    "        idx = 0\n",
    "        for i in save_images:\n",
    "            i = cv2.resize(i, (W,H))\n",
    "            if idx == 0:\n",
    "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
    "            else:\n",
    "                tmp_img_name = f\"{image_name}_bc.{image_extn}\"\n",
    "            image_path = os.path.join(save_path, tmp_img_name)\n",
    "            cv2.imwrite(image_path, i)\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fd727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ensemble of 10 models\n",
    "n = 10\n",
    "ensemble = [0]* n\n",
    "def shuffling_tt(X, rs):\n",
    "    X= shuffle(X, random_state=rs)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d83d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 02:42:21.549156: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-11 02:42:21.549341: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "# Create & Complie Ensemble\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu',\n",
    "                        padding=\"SAME\")\n",
    "for k in range(n):\n",
    "    ensemble[k] = keras.models.Sequential([\n",
    "                    DefaultConv2D(filters=16, input_shape=[128, 128, 3]),\n",
    "                    keras.layers.AveragePooling2D(pool_size=2),\n",
    "                    DefaultConv2D(filters=32),\n",
    "                    keras.layers.MaxPooling2D(pool_size=2),\n",
    "                    DefaultConv2D(filters=64),\n",
    "                    keras.layers.MaxPooling2D(pool_size=2),\n",
    "                    DefaultConv2D(filters=128),\n",
    "                    keras.layers.MaxPooling2D(pool_size=2),\n",
    "                    keras.layers.Dropout(0.4),\n",
    "                    keras.layers.Flatten(),\n",
    "                    keras.layers.Dense(units=7, activation='softmax'),\n",
    "                    ])\n",
    "    ensemble[k].compile(loss='categorical_crossentropy',\n",
    "                        optimizer='adam',\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "886831b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffling(X):\n",
    "    X= shuffle(X, random_state=42)\n",
    "    return X\n",
    "out_path = 'augmented/'\n",
    "# Performing Augmentations Class-Wise\n",
    "# AKIEC\n",
    "def augment_akiec(image_data):\n",
    "    out_data = out_path+'akiec'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST)\n",
    "    ssr_images = glob('augmented/akiec/*')\n",
    "    horizontalflip(ssr_images, out_data,\n",
    "                       augment = True,\n",
    "                       resize = [128,128],\n",
    "                       random=1.0)\n",
    "    hf_images = glob('augmented/akiec/*')\n",
    "    verticalflip(hf_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    df_images = glob('augmented/akiec/*')\n",
    "    brightness_contrast(df_images,\n",
    "                            out_data,\n",
    "                            augment = True,\n",
    "                            resize=[128,128],\n",
    "                            random=1.0,\n",
    "                            brightness=0.2, \n",
    "                            contrast=0.2,\n",
    "                            by_max=False)\n",
    "    # Selecting remaining images by shuffling all and selecting required\n",
    "    bc_images = glob('augmented/akiec/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    bc_images_shuf = shuffling(bc_images)\n",
    "    target = 4693\n",
    "    available = len(bc_images)\n",
    "    bc_selected = bc_images_shuf[0:target-available]\n",
    "    shiftscalerotate(bc_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=0,\n",
    "                     shift=0,\n",
    "                     scale=0.3,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "    # DF\n",
    "def augment_df(image_data):\n",
    "    out_data = out_path+'df'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    ssr_images = glob('augmented/df/*')\n",
    "    horizontalflip(ssr_images, out_data,\n",
    "                       augment = True,\n",
    "                       resize = [128,128],\n",
    "                       random=1.0)\n",
    "    hf_images = glob('augmented/df/*')\n",
    "    verticalflip(hf_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    df_images = glob('augmented/df/*')\n",
    "    brightness_contrast(df_images,\n",
    "                            out_data,\n",
    "                            augment = True,\n",
    "                            resize=[128,128],\n",
    "                            random=1.0,\n",
    "                            brightness=0.2, \n",
    "                            contrast=0.2,\n",
    "                            by_max=False)\n",
    "    bc_images = glob('augmented/df/*')\n",
    "    shiftscalerotate(bc_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "    r_images = glob('augmented/df/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=3)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------\n",
    "# VASC\n",
    "def augment_vasc(image_data):\n",
    "    out_data = out_path+'vasc'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    ssr_images = glob('augmented/vasc/*')\n",
    "    horizontalflip(ssr_images, out_data,\n",
    "                       augment = True,\n",
    "                       resize = [128,128],\n",
    "                       random=1.0)\n",
    "    hf_images = glob('augmented/vasc/*')\n",
    "    verticalflip(hf_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    df_images = glob('augmented/vasc/*')\n",
    "    brightness_contrast(df_images,\n",
    "                            out_data,\n",
    "                            augment = True,\n",
    "                            resize=[128,128],\n",
    "                            random=1.0,\n",
    "                            brightness=0.2, \n",
    "                            contrast=0.2,\n",
    "                            by_max=False)\n",
    "    bc_images = glob('augmented/vasc/*')\n",
    "    shiftscalerotate(bc_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "    r_images = glob('augmented/vasc/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=3)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "# BCC\n",
    "def augment_bcc(image_data):\n",
    "    out_data = out_path+'bcc'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    ssr_images = glob('augmented/bcc/*')\n",
    "    horizontalflip(ssr_images, out_data,\n",
    "                       augment = True,\n",
    "                       resize = [128,128],\n",
    "                       random=1.0)\n",
    "    hf_images = glob('augmented/bcc/*')\n",
    "    verticalflip(hf_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    r_images = glob('augmented/bcc/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "# BKL\n",
    "def augment_bkl(image_data):\n",
    "    out_data = out_path+'bkl'\n",
    "    shiftscalerotate(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=40,\n",
    "                     shift=0.0625,\n",
    "                     scale=0.2,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    ssr_images = glob('augmented/bkl/*')\n",
    "    verticalflip(ssr_images,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    r_images = glob('augmented/bkl/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=2)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------\n",
    "# MEL\n",
    "def augment_mel(image_data):\n",
    "    out_data = out_path+'mel'\n",
    "    verticalflip(image_data,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize=[128,128],\n",
    "                     random=1.0)\n",
    "    vf_images = glob('augmented/mel/*')\n",
    "    brightness_contrast(vf_images,\n",
    "                            out_data,\n",
    "                            augment = True,\n",
    "                            resize=[128,128],\n",
    "                            random=1.0,\n",
    "                            brightness=0.2, \n",
    "                            contrast=0.2,\n",
    "                            by_max=False)\n",
    "    r_images = glob('augmented/mel/*')\n",
    "    # shuffle and take only required number of images to perform next augmentation:\n",
    "    r_images_shuf = shuffling(r_images)\n",
    "    target = 4693\n",
    "    available = len(r_images)\n",
    "    r_selected = r_images_shuf[0:target-available]\n",
    "    shiftscalerotate(r_selected,\n",
    "                     out_data,\n",
    "                     augment = True,\n",
    "                     resize = [128,128],\n",
    "                     random=1.0,\n",
    "                     rotation=80,\n",
    "                     shift=0.2,\n",
    "                     scale=1,\n",
    "                     interpolation=cv2.INTER_NEAREST,\n",
    "                     call=1)\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------\n",
    "# NV\n",
    "# Selecting remaining images by shuffling all and selecting required\n",
    "def augment_nv(image_data):\n",
    "    for image in image_data:\n",
    "        shutil.copyfile(image, f'augmented/nv/{image.split(\"/\")[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f7c1973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 207.00it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1568.27it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1597.65it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1447.90it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1461.45it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 214.66it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1585.87it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1589.93it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1502.67it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 205.96it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1607.46it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1488.70it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 220.01it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1454.37it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1613.98it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1464.38it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1478.92it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1511.94it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 249.71it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1373.73it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1319.82it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 634.10it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1216.96it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1640.31it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1388.89it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:00<00:00, 1588.49it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1510.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32740 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 02:43:08.529329: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-11 02:43:08.768602: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3561 - accuracy: 0.4660"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 02:43:47.192907: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 51s 94ms/step - loss: 1.3561 - accuracy: 0.4660 - val_loss: 1.3360 - val_accuracy: 0.5156\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 48s 93ms/step - loss: 1.0506 - accuracy: 0.6025 - val_loss: 0.9142 - val_accuracy: 0.6267\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 47s 93ms/step - loss: 0.9227 - accuracy: 0.6529 - val_loss: 0.9065 - val_accuracy: 0.6447\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.8200 - accuracy: 0.6894 - val_loss: 0.8716 - val_accuracy: 0.6637\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 48s 93ms/step - loss: 0.7524 - accuracy: 0.7177 - val_loss: 0.7699 - val_accuracy: 0.6912\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 47s 93ms/step - loss: 0.6945 - accuracy: 0.7379 - val_loss: 0.7492 - val_accuracy: 0.7215\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.6395 - accuracy: 0.7617 - val_loss: 0.7886 - val_accuracy: 0.7062\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.5910 - accuracy: 0.7793 - val_loss: 0.8357 - val_accuracy: 0.6810\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.5465 - accuracy: 0.7974 - val_loss: 0.7904 - val_accuracy: 0.7031\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.5150 - accuracy: 0.8060 - val_loss: 0.8851 - val_accuracy: 0.6821\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 48s 93ms/step - loss: 0.4881 - accuracy: 0.8175 - val_loss: 0.7777 - val_accuracy: 0.7245\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.4505 - accuracy: 0.8307 - val_loss: 0.7524 - val_accuracy: 0.7320\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 48s 94ms/step - loss: 0.4261 - accuracy: 0.8410 - val_loss: 0.8209 - val_accuracy: 0.7221\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 48s 95ms/step - loss: 0.4102 - accuracy: 0.8466 - val_loss: 0.9321 - val_accuracy: 0.7075\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 48s 95ms/step - loss: 0.3841 - accuracy: 0.8584 - val_loss: 0.7808 - val_accuracy: 0.7442\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.3621 - accuracy: 0.8635 - val_loss: 0.9385 - val_accuracy: 0.7031\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 48s 95ms/step - loss: 0.3461 - accuracy: 0.8722 - val_loss: 0.7785 - val_accuracy: 0.7575\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 49s 95ms/step - loss: 0.3335 - accuracy: 0.8774 - val_loss: 0.8578 - val_accuracy: 0.7293\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 48s 95ms/step - loss: 0.3217 - accuracy: 0.8795 - val_loss: 0.8609 - val_accuracy: 0.7303\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.2980 - accuracy: 0.8903 - val_loss: 0.8257 - val_accuracy: 0.7490\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.2921 - accuracy: 0.8915 - val_loss: 0.9119 - val_accuracy: 0.7228\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.2812 - accuracy: 0.8973 - val_loss: 0.9275 - val_accuracy: 0.7249\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.2717 - accuracy: 0.8985 - val_loss: 0.8612 - val_accuracy: 0.7531\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 49s 97ms/step - loss: 0.2525 - accuracy: 0.9066 - val_loss: 0.9010 - val_accuracy: 0.7405\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 49s 97ms/step - loss: 0.2525 - accuracy: 0.9063 - val_loss: 0.9812 - val_accuracy: 0.7184\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.2358 - accuracy: 0.9115 - val_loss: 0.9168 - val_accuracy: 0.7561\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 49s 96ms/step - loss: 0.2258 - accuracy: 0.9165 - val_loss: 0.9607 - val_accuracy: 0.7503\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.2224 - accuracy: 0.9177 - val_loss: 0.9269 - val_accuracy: 0.7612\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.2149 - accuracy: 0.9210 - val_loss: 1.0174 - val_accuracy: 0.7276\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 49s 97ms/step - loss: 0.2038 - accuracy: 0.9266 - val_loss: 1.1598 - val_accuracy: 0.7082\n",
      "CNN Model 1: Epochs=30, Training accuracy=0.92655, Validation accuracy=0.76121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 196.75it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1481.23it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1373.46it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1364.67it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1478.22it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 218.37it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1630.53it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1573.72it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1495.19it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 209.25it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1591.34it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1505.06it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 222.18it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1669.02it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1694.84it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1533.20it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1556.58it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1523.56it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 249.14it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1396.70it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1397.25it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 617.81it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1709.15it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1695.54it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1492.68it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1428.56it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1381.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32736 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 03:08:03.395947: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3285 - accuracy: 0.4717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 03:08:39.512283: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 49s 96ms/step - loss: 1.3285 - accuracy: 0.4717 - val_loss: 1.0039 - val_accuracy: 0.6063\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 1.0277 - accuracy: 0.6074 - val_loss: 1.2555 - val_accuracy: 0.5465\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 49s 97ms/step - loss: 0.8964 - accuracy: 0.6606 - val_loss: 0.9306 - val_accuracy: 0.6372\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.8150 - accuracy: 0.6909 - val_loss: 0.9940 - val_accuracy: 0.6260\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.7322 - accuracy: 0.7247 - val_loss: 1.0249 - val_accuracy: 0.6277\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.6774 - accuracy: 0.7459 - val_loss: 0.8212 - val_accuracy: 0.6865\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.6306 - accuracy: 0.7648 - val_loss: 0.9619 - val_accuracy: 0.6450\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5840 - accuracy: 0.7824 - val_loss: 0.8624 - val_accuracy: 0.6814\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.5542 - accuracy: 0.7942 - val_loss: 0.7885 - val_accuracy: 0.7208\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.5130 - accuracy: 0.8102 - val_loss: 0.8597 - val_accuracy: 0.7041\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.4847 - accuracy: 0.8189 - val_loss: 0.8904 - val_accuracy: 0.6933\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 50s 97ms/step - loss: 0.4505 - accuracy: 0.8310 - val_loss: 0.8760 - val_accuracy: 0.7021\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.4247 - accuracy: 0.8437 - val_loss: 0.8535 - val_accuracy: 0.7096\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.4016 - accuracy: 0.8544 - val_loss: 0.8417 - val_accuracy: 0.7249\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 50s 98ms/step - loss: 0.3911 - accuracy: 0.8566 - val_loss: 0.9995 - val_accuracy: 0.6814\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 51s 99ms/step - loss: 0.3682 - accuracy: 0.8625 - val_loss: 1.0372 - val_accuracy: 0.6644\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.3496 - accuracy: 0.8681 - val_loss: 0.9068 - val_accuracy: 0.7323\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.3356 - accuracy: 0.8756 - val_loss: 0.8908 - val_accuracy: 0.7255\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.3165 - accuracy: 0.8846 - val_loss: 0.9705 - val_accuracy: 0.7096\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.3099 - accuracy: 0.8852 - val_loss: 1.0137 - val_accuracy: 0.7072\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2887 - accuracy: 0.8939 - val_loss: 0.9647 - val_accuracy: 0.7262\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2880 - accuracy: 0.8943 - val_loss: 0.9797 - val_accuracy: 0.7109\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2750 - accuracy: 0.8991 - val_loss: 0.9826 - val_accuracy: 0.7323\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2609 - accuracy: 0.9043 - val_loss: 1.0432 - val_accuracy: 0.7035\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2519 - accuracy: 0.9068 - val_loss: 1.0579 - val_accuracy: 0.7021\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2430 - accuracy: 0.9105 - val_loss: 0.9847 - val_accuracy: 0.7385\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2374 - accuracy: 0.9130 - val_loss: 1.0337 - val_accuracy: 0.7497\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2336 - accuracy: 0.9141 - val_loss: 1.0962 - val_accuracy: 0.7157\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2213 - accuracy: 0.9180 - val_loss: 1.0737 - val_accuracy: 0.7171\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2191 - accuracy: 0.9206 - val_loss: 1.0544 - val_accuracy: 0.7432\n",
      "CNN Model 2: Epochs=30, Training accuracy=0.92060, Validation accuracy=0.74966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 199.06it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1622.85it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1605.96it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1429.68it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1360.12it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 205.24it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1572.18it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1654.03it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1381.33it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 197.83it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1615.10it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1497.61it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 217.17it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1678.89it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1639.17it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1524.23it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1485.44it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1541.30it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 248.79it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1455.36it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1454.85it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 648.98it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1738.74it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1737.16it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1550.44it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:00<00:00, 1589.33it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1540.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32748 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 03:34:09.929864: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3348 - accuracy: 0.4742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 03:34:50.921996: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 54s 105ms/step - loss: 1.3348 - accuracy: 0.4742 - val_loss: 0.9347 - val_accuracy: 0.6512\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 1.0699 - accuracy: 0.5936 - val_loss: 0.9599 - val_accuracy: 0.6260\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.9329 - accuracy: 0.6446 - val_loss: 1.0403 - val_accuracy: 0.6022\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.8344 - accuracy: 0.6857 - val_loss: 0.9017 - val_accuracy: 0.6644\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.7623 - accuracy: 0.7127 - val_loss: 0.7612 - val_accuracy: 0.7021\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.6961 - accuracy: 0.7379 - val_loss: 0.7670 - val_accuracy: 0.7130\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.6421 - accuracy: 0.7580 - val_loss: 0.8054 - val_accuracy: 0.7106\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.5971 - accuracy: 0.7772 - val_loss: 0.9642 - val_accuracy: 0.6488\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.5591 - accuracy: 0.7902 - val_loss: 0.8113 - val_accuracy: 0.6977\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.5159 - accuracy: 0.8098 - val_loss: 0.8043 - val_accuracy: 0.6950\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.4812 - accuracy: 0.8211 - val_loss: 0.9011 - val_accuracy: 0.6967\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.4641 - accuracy: 0.8279 - val_loss: 0.8051 - val_accuracy: 0.7120\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.4273 - accuracy: 0.8405 - val_loss: 0.7790 - val_accuracy: 0.7415\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.4080 - accuracy: 0.8477 - val_loss: 0.8537 - val_accuracy: 0.7245\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3870 - accuracy: 0.8584 - val_loss: 0.8314 - val_accuracy: 0.7320\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3627 - accuracy: 0.8673 - val_loss: 0.8233 - val_accuracy: 0.7283\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3500 - accuracy: 0.8702 - val_loss: 0.8414 - val_accuracy: 0.7218\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3346 - accuracy: 0.8759 - val_loss: 0.8116 - val_accuracy: 0.7422\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3140 - accuracy: 0.8828 - val_loss: 0.8019 - val_accuracy: 0.7446\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2960 - accuracy: 0.8906 - val_loss: 0.8308 - val_accuracy: 0.7578\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2901 - accuracy: 0.8938 - val_loss: 0.8819 - val_accuracy: 0.7503\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2790 - accuracy: 0.8960 - val_loss: 0.9144 - val_accuracy: 0.7198\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2744 - accuracy: 0.8990 - val_loss: 0.9117 - val_accuracy: 0.7259\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2618 - accuracy: 0.9029 - val_loss: 0.9836 - val_accuracy: 0.7255\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2495 - accuracy: 0.9076 - val_loss: 0.9203 - val_accuracy: 0.7368\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.2464 - accuracy: 0.9086 - val_loss: 0.9370 - val_accuracy: 0.7425\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2264 - accuracy: 0.9167 - val_loss: 0.9774 - val_accuracy: 0.7323\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2332 - accuracy: 0.9136 - val_loss: 1.0086 - val_accuracy: 0.7249\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2220 - accuracy: 0.9191 - val_loss: 0.9837 - val_accuracy: 0.7330\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2125 - accuracy: 0.9227 - val_loss: 0.9465 - val_accuracy: 0.7534\n",
      "CNN Model 3: Epochs=30, Training accuracy=0.92275, Validation accuracy=0.75781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 199.88it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1463.06it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1380.58it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1447.57it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1472.35it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 220.55it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1637.95it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1621.15it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1369.10it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 205.69it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1612.20it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1496.75it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 203.79it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1615.42it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1632.03it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1187.30it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1444.41it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1489.96it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 251.22it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1464.48it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1412.85it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 662.45it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1706.12it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1719.71it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1416.47it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1485.38it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1411.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32739 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 04:01:09.705624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3657 - accuracy: 0.4598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 04:01:50.013473: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 53s 104ms/step - loss: 1.3657 - accuracy: 0.4598 - val_loss: 1.1120 - val_accuracy: 0.5788\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 1.0537 - accuracy: 0.5952 - val_loss: 0.9272 - val_accuracy: 0.6281\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.9215 - accuracy: 0.6504 - val_loss: 0.9593 - val_accuracy: 0.6386\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.8306 - accuracy: 0.6899 - val_loss: 0.8220 - val_accuracy: 0.6967\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.7567 - accuracy: 0.7138 - val_loss: 0.8894 - val_accuracy: 0.6729\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.7036 - accuracy: 0.7363 - val_loss: 0.7481 - val_accuracy: 0.7228\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.6490 - accuracy: 0.7562 - val_loss: 0.8849 - val_accuracy: 0.6702\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.6053 - accuracy: 0.7741 - val_loss: 0.8243 - val_accuracy: 0.7058\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5757 - accuracy: 0.7850 - val_loss: 0.7581 - val_accuracy: 0.7296\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.5320 - accuracy: 0.8017 - val_loss: 0.8581 - val_accuracy: 0.6838\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.5013 - accuracy: 0.8163 - val_loss: 0.8510 - val_accuracy: 0.7113\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4704 - accuracy: 0.8271 - val_loss: 0.7708 - val_accuracy: 0.7283\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4485 - accuracy: 0.8362 - val_loss: 0.8767 - val_accuracy: 0.7031\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.4226 - accuracy: 0.8427 - val_loss: 0.8364 - val_accuracy: 0.7201\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.4065 - accuracy: 0.8491 - val_loss: 0.7913 - val_accuracy: 0.7317\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.3793 - accuracy: 0.8606 - val_loss: 0.9192 - val_accuracy: 0.7011\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.3623 - accuracy: 0.8659 - val_loss: 0.8944 - val_accuracy: 0.7204\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.3544 - accuracy: 0.8698 - val_loss: 0.8631 - val_accuracy: 0.7204\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.3375 - accuracy: 0.8764 - val_loss: 0.8189 - val_accuracy: 0.7442\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 0.3275 - accuracy: 0.8802 - val_loss: 0.8150 - val_accuracy: 0.7459\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.3058 - accuracy: 0.8866 - val_loss: 0.9626 - val_accuracy: 0.7232\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.3006 - accuracy: 0.8881 - val_loss: 0.8804 - val_accuracy: 0.7412\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.2836 - accuracy: 0.8938 - val_loss: 0.8775 - val_accuracy: 0.7473\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.2743 - accuracy: 0.8991 - val_loss: 0.8341 - val_accuracy: 0.7663\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 51s 101ms/step - loss: 0.2629 - accuracy: 0.9046 - val_loss: 0.9424 - val_accuracy: 0.7486\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.2584 - accuracy: 0.9065 - val_loss: 0.8376 - val_accuracy: 0.7599\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2474 - accuracy: 0.9084 - val_loss: 0.9985 - val_accuracy: 0.7181\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2364 - accuracy: 0.9134 - val_loss: 1.0127 - val_accuracy: 0.7388\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.2373 - accuracy: 0.9134 - val_loss: 1.0083 - val_accuracy: 0.7449\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2280 - accuracy: 0.9179 - val_loss: 0.9352 - val_accuracy: 0.7568\n",
      "CNN Model 4: Epochs=30, Training accuracy=0.91786, Validation accuracy=0.76630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 199.00it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1567.11it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1614.29it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1437.26it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1500.14it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 218.78it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1647.51it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1593.65it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1504.19it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 199.93it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1545.48it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1504.33it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 227.20it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1674.55it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1615.01it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1434.87it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1472.68it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1424.84it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 240.40it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1503.84it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1533.07it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 548.50it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1728.38it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1729.99it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1273.49it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1465.65it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1381.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32738 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 04:27:42.526274: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3438 - accuracy: 0.4664"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 04:28:23.031518: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 54s 104ms/step - loss: 1.3438 - accuracy: 0.4664 - val_loss: 1.0522 - val_accuracy: 0.6213\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 1.0323 - accuracy: 0.6028 - val_loss: 1.0603 - val_accuracy: 0.6002\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.9224 - accuracy: 0.6494 - val_loss: 0.9603 - val_accuracy: 0.6382\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.8257 - accuracy: 0.6858 - val_loss: 0.9273 - val_accuracy: 0.6495\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.7552 - accuracy: 0.7165 - val_loss: 0.7672 - val_accuracy: 0.7120\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.6997 - accuracy: 0.7362 - val_loss: 0.8266 - val_accuracy: 0.6834\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.6368 - accuracy: 0.7621 - val_loss: 0.8079 - val_accuracy: 0.7079\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.5956 - accuracy: 0.7794 - val_loss: 0.8333 - val_accuracy: 0.6906\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.5546 - accuracy: 0.7918 - val_loss: 0.8199 - val_accuracy: 0.7021\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.5238 - accuracy: 0.8058 - val_loss: 0.8772 - val_accuracy: 0.6855\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.4860 - accuracy: 0.8196 - val_loss: 0.9030 - val_accuracy: 0.6974\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.4638 - accuracy: 0.8311 - val_loss: 0.9293 - val_accuracy: 0.7001\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 53s 105ms/step - loss: 0.4360 - accuracy: 0.8409 - val_loss: 0.8268 - val_accuracy: 0.7317\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.4148 - accuracy: 0.8468 - val_loss: 0.8251 - val_accuracy: 0.7300\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.4006 - accuracy: 0.8526 - val_loss: 0.7965 - val_accuracy: 0.7388\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3758 - accuracy: 0.8618 - val_loss: 0.7903 - val_accuracy: 0.7398\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3570 - accuracy: 0.8681 - val_loss: 0.8360 - val_accuracy: 0.7446\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3306 - accuracy: 0.8777 - val_loss: 0.8926 - val_accuracy: 0.7208\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3220 - accuracy: 0.8802 - val_loss: 0.8622 - val_accuracy: 0.7337\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.3218 - accuracy: 0.8821 - val_loss: 0.9704 - val_accuracy: 0.6990\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3014 - accuracy: 0.8886 - val_loss: 0.9026 - val_accuracy: 0.7306\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.2850 - accuracy: 0.8966 - val_loss: 0.9037 - val_accuracy: 0.7310\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.2624 - accuracy: 0.9046 - val_loss: 0.9174 - val_accuracy: 0.7378\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2611 - accuracy: 0.9039 - val_loss: 1.0322 - val_accuracy: 0.7211\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.2628 - accuracy: 0.9038 - val_loss: 0.9197 - val_accuracy: 0.7446\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.2343 - accuracy: 0.9158 - val_loss: 0.9927 - val_accuracy: 0.7398\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.2400 - accuracy: 0.9123 - val_loss: 0.9840 - val_accuracy: 0.7320\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.2335 - accuracy: 0.9139 - val_loss: 0.9694 - val_accuracy: 0.7466\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2318 - accuracy: 0.9151 - val_loss: 1.0020 - val_accuracy: 0.7391\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.2136 - accuracy: 0.9231 - val_loss: 0.9839 - val_accuracy: 0.7412\n",
      "CNN Model 5: Epochs=30, Training accuracy=0.92309, Validation accuracy=0.74660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 197.18it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1492.80it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1421.32it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1425.96it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1464.36it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 209.09it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1608.87it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1597.87it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1481.31it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 206.40it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1580.97it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1445.36it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 220.72it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1615.57it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1501.03it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1360.23it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1496.74it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1505.15it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 247.23it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1492.54it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1453.96it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 613.57it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1701.63it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1718.12it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1422.25it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1578.30it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1419.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32738 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 04:55:01.347110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3108 - accuracy: 0.4833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 04:55:43.329127: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 55s 107ms/step - loss: 1.3108 - accuracy: 0.4833 - val_loss: 1.1327 - val_accuracy: 0.5849\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 1.0514 - accuracy: 0.6003 - val_loss: 1.0646 - val_accuracy: 0.5951\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.9259 - accuracy: 0.6532 - val_loss: 0.9083 - val_accuracy: 0.6630\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.8313 - accuracy: 0.6855 - val_loss: 1.0385 - val_accuracy: 0.6138\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.7530 - accuracy: 0.7186 - val_loss: 0.8403 - val_accuracy: 0.6926\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.6980 - accuracy: 0.7411 - val_loss: 0.8929 - val_accuracy: 0.6661\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.6475 - accuracy: 0.7571 - val_loss: 0.9264 - val_accuracy: 0.6413\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.5927 - accuracy: 0.7790 - val_loss: 0.7379 - val_accuracy: 0.7272\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.5644 - accuracy: 0.7896 - val_loss: 0.7649 - val_accuracy: 0.7238\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.5232 - accuracy: 0.8069 - val_loss: 0.8698 - val_accuracy: 0.6834\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.4965 - accuracy: 0.8149 - val_loss: 0.7994 - val_accuracy: 0.7181\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.4706 - accuracy: 0.8232 - val_loss: 0.7734 - val_accuracy: 0.7286\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.4393 - accuracy: 0.8378 - val_loss: 0.8524 - val_accuracy: 0.7079\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.4322 - accuracy: 0.8412 - val_loss: 0.8320 - val_accuracy: 0.7255\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3983 - accuracy: 0.8525 - val_loss: 0.8289 - val_accuracy: 0.7140\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3809 - accuracy: 0.8568 - val_loss: 0.9327 - val_accuracy: 0.6824\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3623 - accuracy: 0.8656 - val_loss: 0.7925 - val_accuracy: 0.7497\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3502 - accuracy: 0.8709 - val_loss: 0.8434 - val_accuracy: 0.7252\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3414 - accuracy: 0.8732 - val_loss: 0.9175 - val_accuracy: 0.7225\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3168 - accuracy: 0.8828 - val_loss: 0.8789 - val_accuracy: 0.7215\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3084 - accuracy: 0.8857 - val_loss: 0.8797 - val_accuracy: 0.7429\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3023 - accuracy: 0.8874 - val_loss: 0.9520 - val_accuracy: 0.7198\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 53s 105ms/step - loss: 0.2946 - accuracy: 0.8932 - val_loss: 0.8825 - val_accuracy: 0.7320\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2754 - accuracy: 0.8984 - val_loss: 0.9530 - val_accuracy: 0.7296\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2685 - accuracy: 0.9006 - val_loss: 0.9703 - val_accuracy: 0.7232\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2682 - accuracy: 0.9021 - val_loss: 0.9734 - val_accuracy: 0.7262\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2547 - accuracy: 0.9059 - val_loss: 0.9159 - val_accuracy: 0.7439\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2381 - accuracy: 0.9127 - val_loss: 0.9068 - val_accuracy: 0.7588\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2439 - accuracy: 0.9117 - val_loss: 0.9701 - val_accuracy: 0.7340\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2288 - accuracy: 0.9174 - val_loss: 0.9845 - val_accuracy: 0.7371\n",
      "CNN Model 6: Epochs=30, Training accuracy=0.91740, Validation accuracy=0.75883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 194.65it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1554.55it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1392.45it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1370.53it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1358.08it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 208.92it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1624.63it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1634.07it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1328.12it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 207.97it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1628.17it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1460.38it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 226.99it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1655.87it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1577.47it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1510.65it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1489.27it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1368.39it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 242.22it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1496.72it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1534.98it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 549.50it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1327.40it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1394.95it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1538.68it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1315.38it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1564.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32741 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 05:22:19.251462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3703 - accuracy: 0.4581"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 05:22:59.662225: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 53s 104ms/step - loss: 1.3703 - accuracy: 0.4581 - val_loss: 0.9958 - val_accuracy: 0.6223\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 1.0877 - accuracy: 0.5815 - val_loss: 0.9257 - val_accuracy: 0.6267\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.9426 - accuracy: 0.6416 - val_loss: 0.9610 - val_accuracy: 0.6338\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.8482 - accuracy: 0.6803 - val_loss: 0.9367 - val_accuracy: 0.6270\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.7710 - accuracy: 0.7078 - val_loss: 0.7718 - val_accuracy: 0.7048\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.7069 - accuracy: 0.7330 - val_loss: 0.8787 - val_accuracy: 0.6549\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.6594 - accuracy: 0.7519 - val_loss: 0.8415 - val_accuracy: 0.6834\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.6098 - accuracy: 0.7723 - val_loss: 0.8097 - val_accuracy: 0.7011\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.5675 - accuracy: 0.7905 - val_loss: 0.8211 - val_accuracy: 0.6831\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5337 - accuracy: 0.8018 - val_loss: 0.7869 - val_accuracy: 0.7079\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.4917 - accuracy: 0.8175 - val_loss: 0.7929 - val_accuracy: 0.7018\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.4719 - accuracy: 0.8262 - val_loss: 0.8420 - val_accuracy: 0.7167\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4347 - accuracy: 0.8377 - val_loss: 0.8180 - val_accuracy: 0.7164\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4189 - accuracy: 0.8437 - val_loss: 0.9072 - val_accuracy: 0.6817\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4034 - accuracy: 0.8506 - val_loss: 0.7888 - val_accuracy: 0.7242\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.3818 - accuracy: 0.8579 - val_loss: 0.8658 - val_accuracy: 0.7062\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.3625 - accuracy: 0.8667 - val_loss: 0.7793 - val_accuracy: 0.7408\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.3520 - accuracy: 0.8691 - val_loss: 0.9008 - val_accuracy: 0.7058\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.3236 - accuracy: 0.8796 - val_loss: 0.9796 - val_accuracy: 0.6844\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.3187 - accuracy: 0.8834 - val_loss: 0.8585 - val_accuracy: 0.7167\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.3040 - accuracy: 0.8897 - val_loss: 0.8794 - val_accuracy: 0.7177\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.2899 - accuracy: 0.8928 - val_loss: 0.9309 - val_accuracy: 0.7242\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.2865 - accuracy: 0.8940 - val_loss: 0.8759 - val_accuracy: 0.7432\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2667 - accuracy: 0.9014 - val_loss: 0.8824 - val_accuracy: 0.7503\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2561 - accuracy: 0.9071 - val_loss: 0.8731 - val_accuracy: 0.7551\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2597 - accuracy: 0.9025 - val_loss: 0.8879 - val_accuracy: 0.7388\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2426 - accuracy: 0.9113 - val_loss: 0.8708 - val_accuracy: 0.7483\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2367 - accuracy: 0.9140 - val_loss: 0.9531 - val_accuracy: 0.7143\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2311 - accuracy: 0.9130 - val_loss: 0.9343 - val_accuracy: 0.7531\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2215 - accuracy: 0.9187 - val_loss: 0.9743 - val_accuracy: 0.7449\n",
      "CNN Model 7: Epochs=30, Training accuracy=0.91872, Validation accuracy=0.75510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 195.72it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1521.53it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1607.09it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1459.86it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1461.85it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 215.57it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1612.05it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1649.74it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1349.48it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 199.57it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1639.89it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1510.24it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 221.31it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1663.62it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1686.81it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1272.78it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1436.45it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1530.75it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 250.95it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1437.32it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1482.70it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 569.38it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1679.56it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1652.17it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1522.70it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1548.60it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1501.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32735 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 05:48:57.118577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3456 - accuracy: 0.4775"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 05:49:37.980990: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 54s 105ms/step - loss: 1.3456 - accuracy: 0.4775 - val_loss: 1.0898 - val_accuracy: 0.5761\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 1.0333 - accuracy: 0.6082 - val_loss: 0.9475 - val_accuracy: 0.6338\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.9049 - accuracy: 0.6565 - val_loss: 0.9556 - val_accuracy: 0.6416\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.8183 - accuracy: 0.6881 - val_loss: 0.9797 - val_accuracy: 0.6162\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.7551 - accuracy: 0.7143 - val_loss: 0.8033 - val_accuracy: 0.6882\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.7015 - accuracy: 0.7351 - val_loss: 0.8273 - val_accuracy: 0.6984\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.6522 - accuracy: 0.7558 - val_loss: 0.7452 - val_accuracy: 0.7303\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.6162 - accuracy: 0.7649 - val_loss: 0.7870 - val_accuracy: 0.7184\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.5715 - accuracy: 0.7850 - val_loss: 0.8315 - val_accuracy: 0.7082\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.5459 - accuracy: 0.7928 - val_loss: 0.9572 - val_accuracy: 0.6525\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.5129 - accuracy: 0.8054 - val_loss: 0.8375 - val_accuracy: 0.7133\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 53s 105ms/step - loss: 0.4837 - accuracy: 0.8172 - val_loss: 0.7970 - val_accuracy: 0.7188\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.4585 - accuracy: 0.8271 - val_loss: 0.8151 - val_accuracy: 0.7225\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.4399 - accuracy: 0.8370 - val_loss: 0.7895 - val_accuracy: 0.7418\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.4163 - accuracy: 0.8431 - val_loss: 0.8273 - val_accuracy: 0.7252\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.4034 - accuracy: 0.8510 - val_loss: 0.8438 - val_accuracy: 0.7293\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3841 - accuracy: 0.8556 - val_loss: 0.8449 - val_accuracy: 0.7204\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3671 - accuracy: 0.8635 - val_loss: 0.8291 - val_accuracy: 0.7439\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.3576 - accuracy: 0.8662 - val_loss: 0.8903 - val_accuracy: 0.7286\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3383 - accuracy: 0.8750 - val_loss: 0.9180 - val_accuracy: 0.7232\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3240 - accuracy: 0.8804 - val_loss: 0.8062 - val_accuracy: 0.7463\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3222 - accuracy: 0.8804 - val_loss: 1.0233 - val_accuracy: 0.6902\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.3039 - accuracy: 0.8889 - val_loss: 0.9536 - val_accuracy: 0.7208\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2948 - accuracy: 0.8936 - val_loss: 0.8932 - val_accuracy: 0.7334\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.2884 - accuracy: 0.8953 - val_loss: 0.9296 - val_accuracy: 0.7401\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2701 - accuracy: 0.8999 - val_loss: 1.0427 - val_accuracy: 0.7255\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2597 - accuracy: 0.9046 - val_loss: 0.9928 - val_accuracy: 0.7198\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 54s 106ms/step - loss: 0.2677 - accuracy: 0.9010 - val_loss: 0.9512 - val_accuracy: 0.7381\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2479 - accuracy: 0.9088 - val_loss: 0.9296 - val_accuracy: 0.7449\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 55s 107ms/step - loss: 0.2461 - accuracy: 0.9102 - val_loss: 0.9119 - val_accuracy: 0.7334\n",
      "CNN Model 8: Epochs=30, Training accuracy=0.91017, Validation accuracy=0.74626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 200.13it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1533.72it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1616.09it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1462.95it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1460.14it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 212.62it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1642.72it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1630.31it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1372.06it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 205.65it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:01<00:00, 1420.72it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1538.10it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 221.61it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1639.11it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1677.41it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1535.42it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1556.59it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1515.39it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 241.04it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1483.19it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1515.97it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 658.11it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1277.82it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1708.35it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1552.58it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1566.42it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:00<00:00, 1580.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32740 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 06:16:18.027021: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3357 - accuracy: 0.4699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 06:17:00.384462: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 55s 108ms/step - loss: 1.3357 - accuracy: 0.4699 - val_loss: 1.0756 - val_accuracy: 0.6029\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 1.0644 - accuracy: 0.5885 - val_loss: 1.0656 - val_accuracy: 0.6012\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.9479 - accuracy: 0.6381 - val_loss: 0.9313 - val_accuracy: 0.6376\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 53s 105ms/step - loss: 0.8599 - accuracy: 0.6710 - val_loss: 0.9360 - val_accuracy: 0.6376\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.7820 - accuracy: 0.7040 - val_loss: 0.8271 - val_accuracy: 0.7048\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.7212 - accuracy: 0.7292 - val_loss: 0.7945 - val_accuracy: 0.7225\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.6644 - accuracy: 0.7504 - val_loss: 0.7740 - val_accuracy: 0.7123\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.6215 - accuracy: 0.7677 - val_loss: 0.8388 - val_accuracy: 0.6946\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.5780 - accuracy: 0.7857 - val_loss: 0.7807 - val_accuracy: 0.7221\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.5406 - accuracy: 0.7982 - val_loss: 0.7919 - val_accuracy: 0.7215\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.5068 - accuracy: 0.8122 - val_loss: 0.7877 - val_accuracy: 0.7147\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.4746 - accuracy: 0.8235 - val_loss: 0.8128 - val_accuracy: 0.7137\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.4487 - accuracy: 0.8338 - val_loss: 0.7665 - val_accuracy: 0.7374\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.4302 - accuracy: 0.8394 - val_loss: 0.7615 - val_accuracy: 0.7497\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.4110 - accuracy: 0.8465 - val_loss: 0.7896 - val_accuracy: 0.7385\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3705 - accuracy: 0.8649 - val_loss: 0.8853 - val_accuracy: 0.7232\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.3524 - accuracy: 0.8698 - val_loss: 0.8851 - val_accuracy: 0.7266\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3396 - accuracy: 0.8743 - val_loss: 0.8419 - val_accuracy: 0.7378\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3278 - accuracy: 0.8784 - val_loss: 0.7616 - val_accuracy: 0.7663\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3191 - accuracy: 0.8811 - val_loss: 0.8876 - val_accuracy: 0.7381\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3016 - accuracy: 0.8896 - val_loss: 0.9098 - val_accuracy: 0.7242\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.2831 - accuracy: 0.8954 - val_loss: 0.8444 - val_accuracy: 0.7493\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2747 - accuracy: 0.8985 - val_loss: 0.8069 - val_accuracy: 0.7541\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2612 - accuracy: 0.9041 - val_loss: 0.8744 - val_accuracy: 0.7439\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2681 - accuracy: 0.9027 - val_loss: 0.9002 - val_accuracy: 0.7317\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2419 - accuracy: 0.9118 - val_loss: 0.8950 - val_accuracy: 0.7605\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2348 - accuracy: 0.9146 - val_loss: 0.9466 - val_accuracy: 0.7592\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2334 - accuracy: 0.9147 - val_loss: 0.8934 - val_accuracy: 0.7636\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2138 - accuracy: 0.9211 - val_loss: 0.9561 - val_accuracy: 0.7435\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.2155 - accuracy: 0.9214 - val_loss: 0.9581 - val_accuracy: 0.7449\n",
      "CNN Model 9: Epochs=30, Training accuracy=0.92141, Validation accuracy=0.76630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 228/228 [00:01<00:00, 198.69it/s]\n",
      "100%|███████████████████████████████████████| 456/456 [00:00<00:00, 1603.08it/s]\n",
      "100%|███████████████████████████████████████| 912/912 [00:00<00:00, 1613.62it/s]\n",
      "100%|█████████████████████████████████████| 1824/1824 [00:01<00:00, 1344.08it/s]\n",
      "100%|█████████████████████████████████████| 1045/1045 [00:00<00:00, 1462.25it/s]\n",
      "100%|████████████████████████████████████████| 354/354 [00:01<00:00, 217.69it/s]\n",
      "100%|███████████████████████████████████████| 708/708 [00:00<00:00, 1621.48it/s]\n",
      "100%|█████████████████████████████████████| 1416/1416 [00:00<00:00, 1647.29it/s]\n",
      "100%|█████████████████████████████████████| 1861/1861 [00:01<00:00, 1444.06it/s]\n",
      "100%|████████████████████████████████████████| 768/768 [00:03<00:00, 204.83it/s]\n",
      "100%|█████████████████████████████████████| 1536/1536 [00:00<00:00, 1574.45it/s]\n",
      "100%|█████████████████████████████████████| 1621/1621 [00:01<00:00, 1494.45it/s]\n",
      "100%|██████████████████████████████████████████| 80/80 [00:00<00:00, 228.89it/s]\n",
      "100%|███████████████████████████████████████| 160/160 [00:00<00:00, 1670.97it/s]\n",
      "100%|███████████████████████████████████████| 320/320 [00:00<00:00, 1641.58it/s]\n",
      "100%|███████████████████████████████████████| 640/640 [00:00<00:00, 1486.17it/s]\n",
      "100%|█████████████████████████████████████| 1280/1280 [00:00<00:00, 1524.23it/s]\n",
      "100%|█████████████████████████████████████| 2133/2133 [00:01<00:00, 1510.15it/s]\n",
      "100%|████████████████████████████████████████| 778/778 [00:03<00:00, 247.06it/s]\n",
      "100%|█████████████████████████████████████| 1556/1556 [00:01<00:00, 1469.35it/s]\n",
      "100%|█████████████████████████████████████| 1581/1581 [00:01<00:00, 1541.54it/s]\n",
      "100%|██████████████████████████████████████████| 99/99 [00:00<00:00, 578.61it/s]\n",
      "100%|███████████████████████████████████████| 198/198 [00:00<00:00, 1738.44it/s]\n",
      "100%|███████████████████████████████████████| 396/396 [00:00<00:00, 1752.02it/s]\n",
      "100%|███████████████████████████████████████| 792/792 [00:00<00:00, 1590.31it/s]\n",
      "100%|█████████████████████████████████████| 1584/1584 [00:01<00:00, 1539.90it/s]\n",
      "100%|█████████████████████████████████████| 1525/1525 [00:01<00:00, 1373.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32743 images belonging to 7 classes.\n",
      "Found 3006 images belonging to 7 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 06:43:16.205541: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - ETA: 0s - loss: 1.3476 - accuracy: 0.4641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 06:43:55.845641: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 53s 102ms/step - loss: 1.3476 - accuracy: 0.4641 - val_loss: 1.0276 - val_accuracy: 0.6087\n",
      "Epoch 2/30\n",
      "511/511 [==============================] - 51s 100ms/step - loss: 1.0891 - accuracy: 0.5800 - val_loss: 0.8857 - val_accuracy: 0.6624\n",
      "Epoch 3/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.9705 - accuracy: 0.6280 - val_loss: 0.9422 - val_accuracy: 0.6369\n",
      "Epoch 4/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.8611 - accuracy: 0.6762 - val_loss: 0.9283 - val_accuracy: 0.6450\n",
      "Epoch 5/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.7951 - accuracy: 0.7001 - val_loss: 0.9132 - val_accuracy: 0.6440\n",
      "Epoch 6/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.7315 - accuracy: 0.7271 - val_loss: 0.8169 - val_accuracy: 0.6838\n",
      "Epoch 7/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.6798 - accuracy: 0.7465 - val_loss: 0.9294 - val_accuracy: 0.6641\n",
      "Epoch 8/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.6262 - accuracy: 0.7661 - val_loss: 0.7784 - val_accuracy: 0.7221\n",
      "Epoch 9/30\n",
      "511/511 [==============================] - 52s 103ms/step - loss: 0.5874 - accuracy: 0.7811 - val_loss: 0.8279 - val_accuracy: 0.6923\n",
      "Epoch 10/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5467 - accuracy: 0.7976 - val_loss: 0.9402 - val_accuracy: 0.6641\n",
      "Epoch 11/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.5103 - accuracy: 0.8109 - val_loss: 0.7684 - val_accuracy: 0.7191\n",
      "Epoch 12/30\n",
      "511/511 [==============================] - 52s 101ms/step - loss: 0.4804 - accuracy: 0.8210 - val_loss: 0.7610 - val_accuracy: 0.7374\n",
      "Epoch 13/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4634 - accuracy: 0.8274 - val_loss: 0.8614 - val_accuracy: 0.6912\n",
      "Epoch 14/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4361 - accuracy: 0.8371 - val_loss: 0.7404 - val_accuracy: 0.7514\n",
      "Epoch 15/30\n",
      "511/511 [==============================] - 52s 102ms/step - loss: 0.4181 - accuracy: 0.8422 - val_loss: 0.8953 - val_accuracy: 0.7004\n",
      "Epoch 16/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.4003 - accuracy: 0.8525 - val_loss: 0.8159 - val_accuracy: 0.7334\n",
      "Epoch 17/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3713 - accuracy: 0.8630 - val_loss: 0.8032 - val_accuracy: 0.7344\n",
      "Epoch 18/30\n",
      "511/511 [==============================] - 53s 103ms/step - loss: 0.3521 - accuracy: 0.8686 - val_loss: 0.7991 - val_accuracy: 0.7473\n",
      "Epoch 19/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3428 - accuracy: 0.8730 - val_loss: 0.8042 - val_accuracy: 0.7425\n",
      "Epoch 20/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3233 - accuracy: 0.8796 - val_loss: 0.8988 - val_accuracy: 0.7337\n",
      "Epoch 21/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3067 - accuracy: 0.8871 - val_loss: 0.9802 - val_accuracy: 0.7024\n",
      "Epoch 22/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.3039 - accuracy: 0.8873 - val_loss: 0.8729 - val_accuracy: 0.7313\n",
      "Epoch 23/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2932 - accuracy: 0.8902 - val_loss: 0.8756 - val_accuracy: 0.7330\n",
      "Epoch 24/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2753 - accuracy: 0.8973 - val_loss: 0.8835 - val_accuracy: 0.7480\n",
      "Epoch 25/30\n",
      "511/511 [==============================] - 53s 104ms/step - loss: 0.2618 - accuracy: 0.9032 - val_loss: 0.8913 - val_accuracy: 0.7310\n",
      "Epoch 26/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2577 - accuracy: 0.9066 - val_loss: 0.9093 - val_accuracy: 0.7201\n",
      "Epoch 27/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2427 - accuracy: 0.9106 - val_loss: 0.9706 - val_accuracy: 0.7354\n",
      "Epoch 28/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2451 - accuracy: 0.9091 - val_loss: 0.9951 - val_accuracy: 0.7303\n",
      "Epoch 29/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2267 - accuracy: 0.9169 - val_loss: 1.0565 - val_accuracy: 0.7177\n",
      "Epoch 30/30\n",
      "511/511 [==============================] - 54s 105ms/step - loss: 0.2345 - accuracy: 0.9146 - val_loss: 1.0471 - val_accuracy: 0.7228\n",
      "CNN Model 10: Epochs=30, Training accuracy=0.91689, Validation accuracy=0.75136\n"
     ]
    }
   ],
   "source": [
    "# Augment, Split and Train\n",
    "classes = ['akiec','bcc','bkl','df','nv','mel','vasc']\n",
    "\n",
    "TRAIN_DIR = 'Processed_Data/train'\n",
    "model_train = [0] * n\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "for j in range(n):\n",
    "    # Train test Split\n",
    "    rs = np.random.randint(100,150)*(j+1)\n",
    "    for clas in classes:\n",
    "        os.makedirs(f'augmented/{clas}')\n",
    "    for cl in classes:\n",
    "        r_images = glob(f'{TRAIN_DIR}/{cl}/*')\n",
    "        r_images_shuf = shuffling_tt(r_images,rs)\n",
    "        train = int(0.7*len(r_images))\n",
    "        r_train = r_images_shuf[0:train]\n",
    "        r_test = r_images_shuf[train:]\n",
    "        if cl == 'akiec':\n",
    "            augment_akiec(r_train)\n",
    "        elif cl == 'bcc':\n",
    "            augment_bcc(r_train)\n",
    "        elif cl == 'bkl':\n",
    "            augment_bkl(r_train)\n",
    "        elif cl == 'df':\n",
    "            augment_df(r_train)\n",
    "        elif cl == 'mel':\n",
    "            augment_mel(r_train)\n",
    "        elif cl == 'vasc':\n",
    "            augment_vasc(r_train)\n",
    "        else:\n",
    "            augment_nv(r_train)\n",
    "        if not os.path.isdir(f'test/{cl}'):\n",
    "            os.makedirs(f'test/{cl}')\n",
    "        for image in r_test:\n",
    "            shutil.copyfile(image, f'test/{cl}/{image.split(\"/\")[-1]}')\n",
    "    # Model Training\n",
    "\n",
    "    train_dir = 'augmented'\n",
    "    test_dir = 'test'\n",
    "    datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical') # set as training data\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    model_train[j] = ensemble[j].fit_generator(train_generator,\n",
    "                                               steps_per_epoch=train_generator.samples//batch_size,\n",
    "                                               validation_steps=validation_generator.samples//batch_size,\n",
    "                                               validation_data = validation_generator,\n",
    "                                               epochs = epochs)\n",
    "    print(\"CNN Model {0:d}: Epochs={1:d}, Training accuracy={2:.5f}, Validation accuracy={3:.5f}\".\n",
    "          format(j+1,epochs,\n",
    "                 max(model_train[j].history['accuracy']),\n",
    "                 max(model_train[j].history['val_accuracy']) ))\n",
    "    shutil.rmtree('augmented')\n",
    "    shutil.rmtree('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c6a5a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "#Result\n",
    "results = np.zeros( (validation_generator.samples,7) ) \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61e59540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3007 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41735f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 07:42:44.493517: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:42:57.326416: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:43:10.082066: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:43:22.875017: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:43:35.685206: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:43:48.512547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:44:01.322831: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:44:14.049766: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:44:26.899904: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-03-11 07:44:39.643801: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "for j in range(n):\n",
    "    results = results + ensemble[j].predict_generator(validation_generator,\n",
    "                                                      validation_generator.samples // batch_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4441235d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 6, 6, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.argmax(results,axis = 1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c827e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[  98    0    0    0    1    0    0]\n",
      " [   1  151    1    0    0    2    0]\n",
      " [   5    6  301    0    3   14    0]\n",
      " [   0    0    0   35    0    0    0]\n",
      " [   1    0    2    0  323    8    0]\n",
      " [   7   13   36    5   30 1921    0]\n",
      " [   0    0    0    0    0    0   43]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       akiec       0.88      0.99      0.93        99\n",
      "         bcc       0.89      0.97      0.93       155\n",
      "         bkl       0.89      0.91      0.90       329\n",
      "          df       0.88      1.00      0.93        35\n",
      "         mel       0.90      0.97      0.93       334\n",
      "          nv       0.99      0.95      0.97      2012\n",
      "        vasc       1.00      1.00      1.00        43\n",
      "\n",
      "    accuracy                           0.96      3007\n",
      "   macro avg       0.92      0.97      0.94      3007\n",
      "weighted avg       0.96      0.96      0.96      3007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Y_pred = model.predict_generator(validation_generator, validation_generator.samples // batch_size+1)\n",
    "# y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, results))\n",
    "print('Classification Report')\n",
    "target_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
    "print(classification_report(validation_generator.classes, results, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4f2d563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 15:33:07.916761: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Ensemble3_model0/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble3_model1/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble3_model2/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble3_model3/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble3_model4/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble3_model5/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble3_model6/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble3_model7/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble3_model8/assets\n",
      "INFO:tensorflow:Assets written to: Ensemble3_model9/assets\n"
     ]
    }
   ],
   "source": [
    "# Saving Model in Keras Default Format\n",
    "for k in range(n):\n",
    "    ensemble[k].save(f'Ensemble3_model{k}')\n",
    "# Saving Model in H5 Format\n",
    "for k in range(n):\n",
    "    ensemble[k].save(f'Ensemble3_model{k}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bab6b0",
   "metadata": {},
   "source": [
    "## Loading Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b6ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Load the model\n",
    "# It can be used to reconstruct the model identically.\n",
    "# reconstructed_ensemble = [0]*n\n",
    "# for k in range(n):\n",
    "#     reconstructed_ensemble[k] = keras.models.load_model(f\"Saved Models/Ensemble3/Ensemble3_model{k}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
